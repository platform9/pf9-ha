hamgr/bin/hamgr-manage.py:16:1: I001 [*] Import block is un-sorted or un-formatted
   |
14 |   # limitations under the License.
15 |
16 | / import argparse
17 | |
18 | | from migrate.exceptions import DatabaseAlreadyControlledError
19 | | from migrate.versioning.api import upgrade
20 | | from migrate.versioning.api import version_control
21 | |
22 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
   |
   = help: Organize imports

hamgr/bin/hamgr-paste.py:16:1: I001 [*] Import block is un-sorted or un-formatted
   |
16 | / import os.path
17 | | import paste.httpserver
   | |_______________________^ I001
18 |
19 |   # startup script for paste server testing
   |
   = help: Organize imports

hamgr/container/liveness_probe.py:1:1: I001 [*] Import block is un-sorted or un-formatted
  |
1 | / from keystoneauth1 import session 
2 | | from keystoneauth1.identity import v3
3 | | from six.moves.configparser import ConfigParser
4 | | import logging
5 | | import requests
6 | | import subprocess
7 | | import sys
  | |__________^ I001
8 |
9 |   # configure logging
  |
  = help: Organize imports

hamgr/container/liveness_probe.py:6:8: F401 [*] `subprocess` imported but unused
  |
4 | import logging
5 | import requests
6 | import subprocess
  |        ^^^^^^^^^^ F401
7 | import sys
  |
  = help: Remove unused import: `subprocess`

hamgr/container/liveness_probe.py:39:89: E501 Line too long (168 > 88)
   |
37 | …
38 | …
39 | …e='hamgr', interface='internal',region_name=config.get('DEFAULT', 'region_name'), service_name='hamgr' )
   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
40 | …
41 | …
   |

hamgr/container/liveness_probe.py:49:89: E501 Line too long (107 > 88)
   |
47 |         logger.info("response received")
48 |         #if data["status"] == None:
49 |         #    result = subprocess.run(['supervisorctl', 'restart', 'hamgr'], capture_output=True, text=True)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
50 |         #    logger.info(result.stdout)
51 |     else: 
   |

hamgr/container/y2j.py:1:1: I001 [*] Import block is un-sorted or un-formatted
  |
1 | / import yaml
2 | | import json
3 | | import sys
  | |__________^ I001
4 |
5 |   fname = sys.argv[1]
  |
  = help: Organize imports

hamgr/hamgr/common/key_helper.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import base64
17 | | import os
18 | | import datetime
19 | | import shlex
20 | | from cryptography import x509
21 | | from cryptography.hazmat.backends import default_backend
22 | | from subprocess import Popen, PIPE
23 | | from shared.constants import LOGGER_PREFIX
24 | |
25 | | from six import iteritems
26 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
27 |
28 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/common/key_helper.py:138:89: E501 Line too long (102 > 88)
    |
136 |             not configs['region_name']:
137 |         raise Exception('missing configuration values in file %s for '
138 |                         'du_fqdn , customer_shortname , customer_fullname, region_name', hamgr_config)
    |                                                                                         ^^^^^^^^^^^^^^ E501
139 |
140 |     return configs
    |

hamgr/hamgr/common/masakari.py:175:89: E501 Line too long (111 > 88)
    |
173 |     headers = {'X-Auth-Token': token['id'], 'Content-Type': 'application/json'}
174 |     url = '/'.join([_URL, 'segments'])
175 |     data = dict(name=name, service_type='COMPUTE', recovery_method='auto', description='Created by HA Manager')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
176 |     if existing_segment:
177 |         LOG.warning('Segment %s already exists, now try to update it if needed : %s', name, str(existing_segment))
    |

hamgr/hamgr/common/masakari.py:177:89: E501 Line too long (114 > 88)
    |
175 |     data = dict(name=name, service_type='COMPUTE', recovery_method='auto', description='Created by HA Manager')
176 |     if existing_segment:
177 |         LOG.warning('Segment %s already exists, now try to update it if needed : %s', name, str(existing_segment))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
178 |         # update it rather than delete then re-create
179 |         if existing_segment['service_type'] != data['service_type'] or \
    |

hamgr/hamgr/common/masakari.py:182:89: E501 Line too long (89 > 88)
    |
180 |                 existing_segment['recovery_method'] != data['recovery_method'] or \
181 |                 existing_segment['description'] != data['description']:
182 |             resp = requests.put(url + "/" + str(existing_segment['id']), headers=headers,
    |                                                                                         ^ E501
183 |                                 data=json.dumps(dict(segment=data)))
184 |             resp.raise_for_status()
    |

hamgr/hamgr/common/masakari.py:185:89: E501 Line too long (99 > 88)
    |
183 |                                 data=json.dumps(dict(segment=data)))
184 |             resp.raise_for_status()
185 |             LOG.debug('Updated existing masakari segment %s with properties : %s', name, str(data))
    |                                                                                         ^^^^^^^^^^^ E501
186 |
187 |         # now update hosts
    |

hamgr/hamgr/common/masakari.py:194:89: E501 Line too long (100 > 88)
    |
192 |         hosts_added = set(hosts) - set(common)
193 |         if len(hosts_deleted):
194 |             LOG.info('Remove hosts for existing masakari segment %s : %s', name, str(hosts_deleted))
    |                                                                                         ^^^^^^^^^^^^ E501
195 |             delete_hosts_from_failover_segment(token, name, list(hosts_deleted))
196 |         if len(hosts_added):
    |

hamgr/hamgr/common/masakari.py:197:89: E501 Line too long (96 > 88)
    |
195 |             delete_hosts_from_failover_segment(token, name, list(hosts_deleted))
196 |         if len(hosts_added):
197 |             LOG.debug('Add hosts for existing masakari segment %s : %s', name, str(hosts_added))
    |                                                                                         ^^^^^^^^ E501
198 |             add_hosts_to_failover_segment(token, name, list(hosts_added))
199 |     else:
    |

hamgr/hamgr/common/masakari.py:267:5: F841 Local variable `target_segment` is assigned to but never used
    |
265 | def is_host_on_maintenance(token, host_id, segment_name):
266 |     # confirm the given segment_id eixist
267 |     target_segment = get_failover_segment(token, segment_name)
    |     ^^^^^^^^^^^^^^ F841
268 |     # confirm host exist in target segment
269 |     hosts = get_nodes_in_segment(token, segment_name)
    |
    = help: Remove assignment to unused variable `target_segment`

hamgr/hamgr/common/masakari.py:278:89: E501 Line too long (105 > 88)
    |
276 |     host_uuid = xhosts[0]['uuid']
277 |     on_maintenance = xhosts[0]['on_maintenance']
278 |     LOG.debug('uuid of host %s : %s , on_maintenance : %s', host_id, str(host_uuid), str(on_maintenance))
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
279 |     return on_maintenance
    |

hamgr/hamgr/common/masakari.py:327:89: E501 Line too long (106 > 88)
    |
325 |         existing_hosts = get_nodes_in_segment(token, str(segment_name))
326 |     except exceptions.SegmentNotFound:
327 |         LOG.warning('masakari segment %s does not exist for adding hosts %s', segment_name, str(host_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
328 |         return
    |

hamgr/hamgr/common/masakari.py:338:89: E501 Line too long (96 > 88)
    |
336 |     for hid in host_ids:
337 |         # check whether the host has already been added to avoid conflict
338 |         if len(existing_hosts) > 0 and len([x for x in existing_hosts if x['name'] == hid]) > 0:
    |                                                                                         ^^^^^^^^ E501
339 |             LOG.debug('ignore adding host %s as it already exist in segment %s', hid, segment_name)
340 |             continue
    |

hamgr/hamgr/common/masakari.py:339:89: E501 Line too long (99 > 88)
    |
337 |         # check whether the host has already been added to avoid conflict
338 |         if len(existing_hosts) > 0 and len([x for x in existing_hosts if x['name'] == hid]) > 0:
339 |             LOG.debug('ignore adding host %s as it already exist in segment %s', hid, segment_name)
    |                                                                                         ^^^^^^^^^^^ E501
340 |             continue
341 |         data = dict(host=dict(name=hid,
    |

hamgr/hamgr/common/masakari.py:355:89: E501 Line too long (108 > 88)
    |
353 |         segment = get_failover_segment(token, str(segment_name))
354 |     except exceptions.SegmentNotFound:
355 |         LOG.warning('masakari segment %s does not exist for deleting hosts %s', segment_name, str(host_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
356 |         return
    |

hamgr/hamgr/common/utils.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import time
17 | | # import _striptime to avoid deadlock when call time.striptime
18 | | # in multiple thread environment
19 | | import _strptime
20 | | from keystoneclient.v3 import client as v3client
21 | | from keystoneclient.v3.tokens import TokenManager
22 | | from keystoneauth1.identity import v3
23 | | from keystoneauth1 import session
24 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
25 |
26 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/common/utils.py:19:8: F401 [*] `_strptime` imported but unused
   |
17 | # import _striptime to avoid deadlock when call time.striptime
18 | # in multiple thread environment
19 | import _strptime
   |        ^^^^^^^^^ F401
20 | from keystoneclient.v3 import client as v3client
21 | from keystoneclient.v3.tokens import TokenManager
   |
   = help: Remove unused import: `_strptime`

hamgr/hamgr/common/utils.py:39:89: E501 Line too long (91 > 88)
   |
37 |     sess = session.Session(auth=auth)
38 |     raw = sess.get_token()
39 |     keystone = v3client.Client(session=sess, region_name=region_name, interface='internal')
   |                                                                                         ^^^ E501
40 |     mgr = TokenManager(keystone)
41 |     data = mgr.get_token_data(raw)
   |

hamgr/hamgr/context.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import functools
16 | | import sys
17 | | import traceback
18 | |
19 | | from flask import jsonify
20 | | from flask import request
21 | | from sqlalchemy.exc import IntegrityError
   | |_________________________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/db/api.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | |
17 | | from contextlib import contextmanager
18 | |
19 | | import datetime
20 | | from shared.exceptions import ha_exceptions as exceptions
21 | | from shared import constants
22 | | from sqlalchemy import Boolean
23 | | from sqlalchemy import Column
24 | | from sqlalchemy import create_engine
25 | | from sqlalchemy import DateTime
26 | | from sqlalchemy.exc import SQLAlchemyError
27 | | from sqlalchemy.ext.declarative import declarative_base
28 | | from sqlalchemy import Integer
29 | | from sqlalchemy.orm import sessionmaker
30 | | from sqlalchemy import String
31 | | from sqlalchemy import Text
32 | | from sqlalchemy import LargeBinary
33 | | from sqlalchemy import or_
34 | | from uuid import uuid4
35 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
36 |
37 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/db/api.py:62:89: E501 Line too long (139 > 88)
   |
61 | …
62 | …self.id}, status: {self.status}, enabled: {self.enabled}, task_state: {self.task_state}>"
   |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
   |

hamgr/hamgr/db/api.py:290:89: E501 Line too long (92 > 88)
    |
288 |         db_cluster = _get_cluster(session, cluster_id)
289 |         if not db_cluster:
290 |             LOG.debug('update_request_status: no cluster found with id %s', str(cluster_id))
    |                                                                                         ^^^^ E501
291 |             return
292 |         db_cluster.status = status
    |

hamgr/hamgr/db/api.py:337:89: E501 Line too long (113 > 88)
    |
335 |         db_cluster = _get_cluster(session, cluster_id)
336 |         if not db_cluster:
337 |             LOG.debug('update_cluster: no cluster found with id %s for action %s', str(cluster_id), str(enabled))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
338 |             return
339 |         db_cluster.updated_at = datetime.datetime.utcnow()
    |

hamgr/hamgr/db/api.py:353:89: E501 Line too long (101 > 88)
    |
351 |         db_cluster = _get_cluster(session, cluster_id)
352 |         if not db_cluster:
353 |             LOG.debug('update_cluster_task_state: no cluster found with id %s for new task state %s',
    |                                                                                         ^^^^^^^^^^^^^ E501
354 |                      str(cluster_id), str(state))
355 |             return
    |

hamgr/hamgr/db/api.py:402:89: E501 Line too long (92 > 88)
    |
400 |             return result
401 |         except Exception:
402 |             LOG.error('failed to get the host in masakari DB  %s', str(name), exc_info=True)
    |                                                                                         ^^^^ E501
403 |     return None
    |

hamgr/hamgr/db/api.py:448:89: E501 Line too long (109 > 88)
    |
446 |                 ChangeEvents.timestamp <= end_time
447 |             )
448 |             #LOG.debug('SQL query: %s', str(query.statement.compile(compile_kwargs={"literal_binds": True})))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
449 |             return query.all()
450 |         except SQLAlchemyError as se:
    |

hamgr/hamgr/db/api.py:455:89: E501 Line too long (117 > 88)
    |
454 | # create event, return event created to caller
455 | def create_processing_event(event_uuid, event_type, host_name, cluster_id, notification_status = '', error_state=''):
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
456 |     if event_type not in constants.VALID_EVENT_TYPES:
457 |         raise exceptions.ArgumentException('event_type not in %s' %
    |

hamgr/hamgr/db/api.py:486:57: E711 Comparison to `None` should be `cond is None`
    |
484 |             query = session.query(EventsProcessing)
485 |             query = query.filter(or_(
486 |                 EventsProcessing.notification_status == None,
    |                                                         ^^^^ E711
487 |                 ~EventsProcessing.notification_status.in_(
488 |                     constants.HANDLED_STATES)))
    |
    = help: Replace with `cond is None`

hamgr/hamgr/db/api.py:533:89: E501 Line too long (105 > 88)
    |
531 |                                  EventsProcessing.event_time <= end_time)
532 |             if unhandled_only:
533 |                 query = query.filter(~EventsProcessing.notification_status.in_(constants.HANDLED_STATES))
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
534 |             return query.all()
535 |         except Exception:
    |

hamgr/hamgr/db/api.py:652:89: E501 Line too long (93 > 88)
    |
650 |             record.last_updated = datetime.datetime.utcnow()
651 |             session.add(record)
652 |             LOG.debug('successfully commited consul role rebalance record : %s', str(record))
    |                                                                                         ^^^^^ E501
653 |             return record.uuid
654 |         except SQLAlchemyError as se:
    |

hamgr/hamgr/db/api.py:667:89: E501 Line too long (102 > 88)
    |
665 |             return record
666 |         except SQLAlchemyError as se:
667 |             LOG.error('DB error when getting consul role rebalance record for uuid %s : %s', uuid, se)
    |                                                                                         ^^^^^^^^^^^^^^ E501
668 |         return None
    |

hamgr/hamgr/db/api.py:680:89: E501 Line too long (112 > 88)
    |
678 |             return records
679 |         except SQLAlchemyError as se:
680 |             LOG.error('DB error when getting consul role rebalance records for action %s : %s', str(action), se)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
681 |         return None
    |

hamgr/hamgr/db/api.py:692:89: E501 Line too long (111 > 88)
    |
690 |             return records
691 |         except SQLAlchemyError as se:
692 |             LOG.error('DB error when getting consul role rebalance records for event  %s : %s', event_uuid, se)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
693 |         return None
    |

hamgr/hamgr/db/api.py:700:89: E501 Line too long (107 > 88)
    |
698 |         try:
699 |             query = session.query(ConsulRoleRebalanceRecord)
700 |             # only return records whose status are not set, ignore 'running', 'aborted', 'finished' records
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
701 |             query = query.filter_by(action_status=None)
702 |             records = query.all()
    |

hamgr/hamgr/db/api.py:705:89: E501 Line too long (96 > 88)
    |
703 |             return records
704 |         except SQLAlchemyError as se:
705 |             LOG.error('DB error when getting unhandled consul role rebalance requests : %s', se)
    |                                                                                         ^^^^^^^^ E501
706 |         return None
    |

hamgr/hamgr/db/api.py:735:89: E501 Line too long (94 > 88)
    |
733 |             return record
734 |         except SQLAlchemyError as se:
735 |             LOG.error('DB error when getting consul role rebalance record  %s : %s', uuid, se)
    |                                                                                         ^^^^^^ E501
736 |         return None
    |

hamgr/hamgr/db/api.py:740:89: E501 Line too long (110 > 88)
    |
739 | # create cinder processing event, return event created to caller
740 | def create_cinder_processing_event(event_uuid, event_type, host_name, notification_status='', error_state=''):
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
741 |     """Create a new cinder processing event.
    |

hamgr/hamgr/db/versions/001_add_initial_tables.py:16:1: I001 [*] Import block is un-sorted or un-formatted
   |
16 | / from sqlalchemy import Boolean
17 | | from sqlalchemy import Column
18 | | from sqlalchemy import DateTime
19 | | from sqlalchemy import Integer
20 | | from sqlalchemy import MetaData
21 | | from sqlalchemy import String
22 | | from sqlalchemy import Table
   | |____________________________^ I001
23 |
24 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/002_add_task_state_to_clusters.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import MetaData
17 | | from sqlalchemy import String
18 | | from sqlalchemy import Table
   | |____________________________^ I001
19 |
20 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/003_add_change_events_table.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import datetime
16 | |
17 | | from sqlalchemy import Column
18 | | from sqlalchemy import DateTime
19 | | from sqlalchemy import Integer
20 | | from sqlalchemy import MetaData
21 | | from sqlalchemy import Table
22 | | from sqlalchemy import Text
   | |___________________________^ I001
23 |
24 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/004_add_events_processing_table.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import DateTime
17 | | from sqlalchemy import Integer
18 | | from sqlalchemy import MetaData
19 | | from sqlalchemy import Table
20 | | from sqlalchemy import Text
   | |___________________________^ I001
21 |
22 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/005_add_error_state_to_events_processing.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import MetaData
17 | | from sqlalchemy import Text
18 | | from sqlalchemy import Table
   | |____________________________^ I001
19 |
20 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/006_add_consul_status_table.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import DateTime
17 | | from sqlalchemy import Integer
18 | | from sqlalchemy import MetaData
19 | | from sqlalchemy import Table
20 | | from sqlalchemy import Text
   | |___________________________^ I001
21 |
22 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import DateTime
17 | | from sqlalchemy import Integer
18 | | from sqlalchemy import MetaData
19 | | from sqlalchemy import Table
20 | | from sqlalchemy import Text
   | |___________________________^ I001
21 |
22 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:24:89: E501 Line too long (97 > 88)
   |
22 | meta = MetaData()
23 |
24 | # table used to track consul member auto rebalance processing, it will be triggered when there is
   |                                                                                         ^^^^^^^^^ E501
25 | # host-up or host-down event received by hamgr, and the event has been handled with 'finished' status.
26 | # it should looks like
   |

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:25:89: E501 Line too long (102 > 88)
   |
24 | # table used to track consul member auto rebalance processing, it will be triggered when there is
25 | # host-up or host-down event received by hamgr, and the event has been handled with 'finished' status.
   |                                                                                         ^^^^^^^^^^^^^^ E501
26 | # it should looks like
27 | #  {
   |

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:31:89: E501 Line too long (97 > 88)
   |
29 | #   'uuid': '' , # identifier of the rebalance action
30 | #   'event_name':'host-up',
31 | #   'event_uuid' : '',   # foreign key to 'events_processing' table for full picture of the event
   |                                                                                         ^^^^^^^^^ E501
32 | #                        # also foreign key to 'consul_status' table for full picture of the consul status
33 | #   'before_rebalance': {}, # the consul status before rebalance
   |

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:32:89: E501 Line too long (106 > 88)
   |
30 | #   'event_name':'host-up',
31 | #   'event_uuid' : '',   # foreign key to 'events_processing' table for full picture of the event
32 | #                        # also foreign key to 'consul_status' table for full picture of the consul status
   |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
33 | #   'before_rebalance': {}, # the consul status before rebalance
34 | #   'rebalance_action' : {'host':'x', 'old_role':'server', 'new_role':'agent', 'joins':''},
   |

hamgr/hamgr/db/versions/007_add_consul_role_rebalance_table.py:34:89: E501 Line too long (91 > 88)
   |
32 | #                        # also foreign key to 'consul_status' table for full picture of the consul status
33 | #   'before_rebalance': {}, # the consul status before rebalance
34 | #   'rebalance_action' : {'host':'x', 'old_role':'server', 'new_role':'agent', 'joins':''},
   |                                                                                         ^^^ E501
35 | #   'after_rebalance': {} , # the consul status after rebalance
36 | #   'action_started': '2018-11-10 12:00:00',
   |

hamgr/hamgr/db/versions/008_alter_text_fileds_to_largebinary.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from sqlalchemy import Column
16 | | from sqlalchemy import MetaData
17 | | from sqlalchemy import String
18 | | from sqlalchemy import Table
19 | | from sqlalchemy import Text
20 | | from sqlalchemy import LargeBinary
   | |__________________________________^ I001
21 |
22 |   meta = MetaData()
   |
   = help: Organize imports

hamgr/hamgr/db/versions/008_alter_text_fileds_to_largebinary.py:15:24: F401 [*] `sqlalchemy.Column` imported but unused
   |
13 | # limitations under the License.
14 |
15 | from sqlalchemy import Column
   |                        ^^^^^^ F401
16 | from sqlalchemy import MetaData
17 | from sqlalchemy import String
   |
   = help: Remove unused import: `sqlalchemy.Column`

hamgr/hamgr/db/versions/008_alter_text_fileds_to_largebinary.py:17:24: F401 [*] `sqlalchemy.String` imported but unused
   |
15 | from sqlalchemy import Column
16 | from sqlalchemy import MetaData
17 | from sqlalchemy import String
   |                        ^^^^^^ F401
18 | from sqlalchemy import Table
19 | from sqlalchemy import Text
   |
   = help: Remove unused import: `sqlalchemy.String`

hamgr/hamgr/db/versions/009_add_cinder_events_processing_table.py:4:61: F401 [*] `sqlalchemy.String` imported but unused
  |
4 | from sqlalchemy import Column, DateTime, Integer, MetaData, String, Table, Text
  |                                                             ^^^^^^ F401
5 |
6 | meta = MetaData()
  |
  = help: Remove unused import: `sqlalchemy.String`

hamgr/hamgr/logger.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import logging.config
17 | | import logging.handlers
18 | | import hamgr
19 | | from os.path import exists
20 | | from os.path import dirname
21 | | from os import makedirs
22 | | from shared.constants import ROOT_LOGGER
23 | |
24 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/notification.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import traceback
17 | |
18 | | from shared.exceptions.ha_exceptions import ConfigException
19 | | from shared.rpc.rpc_manager import RpcManager
20 | | from shared.messages.cluster_event import ClusterEvent
21 | | from shared.messages import message_types as message_types
22 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
23 |
24 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/notification.py:129:89: E501 Line too long (102 > 88)
    |
128 |         LOG.debug('publishing notification : %s', str(notification))
129 |         self._rpc_manager.send_rpc_message(notification, message_type=message_types.MSG_CLUSTER_EVENT)
    |                                                                                         ^^^^^^^^^^^^^^ E501
    |

hamgr/hamgr/periodic_task.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | |
17 | | from datetime import datetime
18 | | from datetime import timedelta
19 | |
20 | | import threading
21 | | import time
22 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
23 |
24 |   PERIODIC_TASK = None
   |
   = help: Organize imports

hamgr/hamgr/provider_factory.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | from hamgr import app
17 | | from flask import g
18 | | from shared.constants import LOGGER_PREFIX
19 | | from hamgr.providers import get_provider_for_service
20 | |
21 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
22 |
23 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/providers/__init__.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
17 |
18 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/providers/cinder.py:4:1: I001 [*] Import block is un-sorted or un-formatted
   |
 4 | / import json
 5 | | import logging
 6 | | import random
 7 | | import subprocess
 8 | | import threading
 9 | | import time
10 | | import os
11 | | import uuid
12 | | from datetime import datetime
13 | | from datetime import timedelta
14 | | import tempfile
15 | | import shlex
16 | |
17 | | import requests
18 | | from keystoneauth1 import loading
19 | | from keystoneauth1 import session
20 | | from cinderclient import client as cinder_client
21 | |
22 | | import hamgr
23 | | from hamgr.common import utils
24 | | from hamgr.db import api as db_api
25 | | from hamgr.providers.provider import Provider
26 | | from shared import constants
27 | | from shared.exceptions import ha_exceptions
28 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
29 |
30 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/providers/cinder.py:4:8: F401 [*] `json` imported but unused
  |
4 | import json
  |        ^^^^ F401
5 | import logging
6 | import random
  |
  = help: Remove unused import: `json`

hamgr/hamgr/providers/cinder.py:14:8: F401 [*] `tempfile` imported but unused
   |
12 | from datetime import datetime
13 | from datetime import timedelta
14 | import tempfile
   |        ^^^^^^^^ F401
15 | import shlex
   |
   = help: Remove unused import: `tempfile`

hamgr/hamgr/providers/cinder.py:17:8: F401 [*] `requests` imported but unused
   |
15 | import shlex
16 |
17 | import requests
   |        ^^^^^^^^ F401
18 | from keystoneauth1 import loading
19 | from keystoneauth1 import session
   |
   = help: Remove unused import: `requests`

hamgr/hamgr/providers/cinder.py:22:8: F401 [*] `hamgr` imported but unused
   |
20 | from cinderclient import client as cinder_client
21 |
22 | import hamgr
   |        ^^^^^ F401
23 | from hamgr.common import utils
24 | from hamgr.db import api as db_api
   |
   = help: Remove unused import: `hamgr`

hamgr/hamgr/providers/cinder.py:46:22: F541 [*] f-string without any placeholders
   |
44 |         try:
45 |             self._cinder_db_connection = config.get('cinder', 'sqlconnectURI')
46 |             LOG.info(f"Found cinder database connection in configuration")
   |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
47 |         except Exception as e:
48 |             LOG.warning(f"Cinder database connection not found in configuration: {str(e)}")
   |
   = help: Remove extraneous `f` prefix

hamgr/hamgr/providers/cinder.py:48:89: E501 Line too long (91 > 88)
   |
46 |             LOG.info(f"Found cinder database connection in configuration")
47 |         except Exception as e:
48 |             LOG.warning(f"Cinder database connection not found in configuration: {str(e)}")
   |                                                                                         ^^^ E501
49 |             self._cinder_db_connection = None
   |

hamgr/hamgr/providers/cinder.py:57:89: E501 Line too long (90 > 88)
   |
55 |         setting_seconds = config.getint('DEFAULT', 'event_report_threshold_seconds')
56 |         if setting_seconds <= 0:
57 |             raise ha_exceptions.ConfigException('invalid setting in configuration file : '
   |                                                                                         ^^ E501
58 |                                               'event_report_threshold_seconds '
59 |                                               'should be bigger than 0')
   |

hamgr/hamgr/providers/cinder.py:82:89: E501 Line too long (102 > 88)
   |
80 |         )
81 |         sess = session.Session(auth=auth)
82 |         return cinder_client.Client('3', session=sess, region_name=self._region, interface='internal')
   |                                                                                         ^^^^^^^^^^^^^^ E501
83 |
84 |     def _get_cinder_hosts(self):
   |

hamgr/hamgr/providers/cinder.py:124:89: E501 Line too long (92 > 88)
    |
122 |             return backends
123 |         except Exception as e:
124 |             LOG.exception(f"Error getting cinder backends for host {cinder_host}: {str(e)}")
    |                                                                                         ^^^^ E501
125 |             return []
    |

hamgr/hamgr/providers/cinder.py:147:89: E501 Line too long (93 > 88)
    |
145 |             return other_hosts
146 |         except Exception as e:
147 |             LOG.exception(f"Error finding other hosts with backend {backend_name}: {str(e)}")
    |                                                                                         ^^^^^ E501
148 |             return []
    |

hamgr/hamgr/providers/cinder.py:160:89: E501 Line too long (111 > 88)
    |
158 |             host_volumes = []
159 |             for vol in all_volumes:
160 |                 if hasattr(vol, 'os-vol-host-attr:host') and cinder_host in vol._info['os-vol-host-attr:host']:
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
161 |                     host_volumes.append(vol)
162 |                     LOG.debug(f"Found volume {vol.id} on host {vol._info['os-vol-host-attr:host']}")
    |

hamgr/hamgr/providers/cinder.py:162:89: E501 Line too long (100 > 88)
    |
160 |                 if hasattr(vol, 'os-vol-host-attr:host') and cinder_host in vol._info['os-vol-host-attr:host']:
161 |                     host_volumes.append(vol)
162 |                     LOG.debug(f"Found volume {vol.id} on host {vol._info['os-vol-host-attr:host']}")
    |                                                                                         ^^^^^^^^^^^^ E501
163 |             
164 |             LOG.debug(f"Found {len(host_volumes)} volumes on host {cinder_host}")
    |

hamgr/hamgr/providers/cinder.py:199:89: E501 Line too long (98 > 88)
    |
197 |                         'project_id': services_project
198 |                     }
199 |                     LOG.debug(f"Searching for glance volumes in services project: {service_opts}")
    |                                                                                         ^^^^^^^^^^ E501
200 |                     service_volumes = client.volumes.list(detailed=True, search_opts=service_opts)
    |

hamgr/hamgr/providers/cinder.py:200:89: E501 Line too long (98 > 88)
    |
198 |                     }
199 |                     LOG.debug(f"Searching for glance volumes in services project: {service_opts}")
200 |                     service_volumes = client.volumes.list(detailed=True, search_opts=service_opts)
    |                                                                                         ^^^^^^^^^^ E501
201 |                     
202 |                     # Filter volumes that match our cinder_host
    |

hamgr/hamgr/providers/cinder.py:209:89: E501 Line too long (135 > 88)
    |
207 | …ng_ids):
208 | …ol)
209 | …nce volume: {vol.id} on host {vol._info['os-vol-host-attr:host']} in services project")
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
210 | …
211 | …for volumes in services project: {str(e)}")
    |

hamgr/hamgr/providers/cinder.py:211:89: E501 Line too long (91 > 88)
    |
209 | …                     LOG.info(f"Found glance volume: {vol.id} on host {vol._info['os-vol-host-attr:host']} in services project")
210 | …     except Exception as e:
211 | …         LOG.exception(f"Error searching for volumes in services project: {str(e)}")
    |                                                                                   ^^^ E501
212 | …     
213 | …     return all_volumes
    |

hamgr/hamgr/providers/cinder.py:230:89: E501 Line too long (98 > 88)
    |
229 |     def _find_pool_for_migration(self, backend_name, backend_config, pool_names):
230 |         LOG.info(f"Looking for pools with backend '{backend_name}' and config '{backend_config}'")
    |                                                                                         ^^^^^^^^^^ E501
231 |         
232 |         # Find pools that match both the backend name and configuration
    |

hamgr/hamgr/providers/cinder.py:239:89: E501 Line too long (114 > 88)
    |
237 |                          and pool.split('@')[1].split('#')[0] == backend_name]
238 |         
239 |         LOG.info(f"Found {len(matching_pools)} pools with backend '{backend_name}' and config '{backend_config}'")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
240 |         
241 |         if not matching_pools:
    |

hamgr/hamgr/providers/cinder.py:247:89: E501 Line too long (109 > 88)
    |
245 |         # Select a random pool from the matching pools to distribute volumes
246 |         target_pool = random.choice(matching_pools)
247 |         LOG.info(f"Selected migration target pool: {target_pool} from {len(matching_pools)} available pools")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
248 |         return target_pool
    |

hamgr/hamgr/providers/cinder.py:252:89: E501 Line too long (105 > 88)
    |
250 |     def _migrate_volumes(self, cinder_host, backend_name, new_host):
251 |         try:
252 |             LOG.info(f"Migrating volumes from {cinder_host}@{backend_name} to {new_host}@{backend_name}")
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
253 |             
254 |             volumes = self._get_volumes_for_migration(cinder_host)
    |

hamgr/hamgr/providers/cinder.py:256:89: E501 Line too long (90 > 88)
    |
254 |             volumes = self._get_volumes_for_migration(cinder_host)
255 |             if not volumes:
256 |                 LOG.info(f"No volumes found to migrate from {cinder_host}@{backend_name}")
    |                                                                                         ^^ E501
257 |                 return True
    |

hamgr/hamgr/providers/cinder.py:260:89: E501 Line too long (89 > 88)
    |
259 |             volume_ids = [v.id for v in volumes]
260 |             LOG.info(f"Found {len(volumes)} volumes to migrate: {', '.join(volume_ids)}")
    |                                                                                         ^ E501
261 |             
262 |             # Get the current host format from the volumes
    |

hamgr/hamgr/providers/cinder.py:277:89: E501 Line too long (102 > 88)
    |
275 |             if '@' in source_host_format and '#' in source_host_format:
276 |                 source_config = source_host_format.split('@')[1].split('#')[1]
277 |                 LOG.info(f"Extracted backend configuration '{source_config}' from source host format")
    |                                                                                         ^^^^^^^^^^^^^^ E501
278 |             else:
279 |                 LOG.error(f"Could not extract backend configuration from source host format: {source_host_format}")
    |

hamgr/hamgr/providers/cinder.py:279:89: E501 Line too long (115 > 88)
    |
277 |                 LOG.info(f"Extracted backend configuration '{source_config}' from source host format")
278 |             else:
279 |                 LOG.error(f"Could not extract backend configuration from source host format: {source_host_format}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
280 |                 return False
    |

hamgr/hamgr/providers/cinder.py:283:89: E501 Line too long (96 > 88)
    |
282 |             # Find a pool to migrate to
283 |             target_pool = self._find_pool_for_migration(backend_name, source_config, pool_names)
    |                                                                                         ^^^^^^^^ E501
284 |             
285 |             # Define source and target formats based on pool availability
    |

hamgr/hamgr/providers/cinder.py:293:89: E501 Line too long (111 > 88)
    |
291 |             else:
292 |                 # If we can't find a suitable pool, we can't proceed with migration
293 |                 LOG.error(f"No suitable pool found for backend {backend_name}. Cannot proceed with migration.")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
294 |                 return False
    |

hamgr/hamgr/providers/cinder.py:296:89: E501 Line too long (91 > 88)
    |
294 |                 return False
295 |             
296 |             LOG.info(f"Using cinder-manage to migrate volumes to {target_host_formats[0]}")
    |                                                                                         ^^^ E501
297 |             
298 |             os_auth_url = self._auth_url
    |

hamgr/hamgr/providers/cinder.py:337:89: E501 Line too long (146 > 88)
    |
335 | …
336 | …:
337 | …e {cinder_conf_path} volume update_host --currenthost {source_host} --newhost {target_host}"
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
338 | …}")
    |

hamgr/hamgr/providers/cinder.py:341:89: E501 Line too long (94 > 88)
    |
340 |                     cmd_args = shlex.split(cmd)
341 |                     result = subprocess.run(cmd_args, env=env, capture_output=True, text=True)
    |                                                                                         ^^^^^^ E501
342 |                     
343 |                     if result.returncode == 0:
    |

hamgr/hamgr/providers/cinder.py:344:89: E501 Line too long (112 > 88)
    |
343 |                     if result.returncode == 0:
344 |                         LOG.info(f"Database update for migration from {source_host} to {target_host} completed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
345 |                         LOG.debug(f"cinder-manage output: {result.stdout}")
    |

hamgr/hamgr/providers/cinder.py:350:89: E501 Line too long (98 > 88)
    |
348 |                         time.sleep(2)
349 |                         
350 |                         verification_success = self._verify_volume_migration(volumes, target_host)
    |                                                                                         ^^^^^^^^^^ E501
351 |                         
352 |                         if verification_success:
    |

hamgr/hamgr/providers/cinder.py:353:89: E501 Line too long (108 > 88)
    |
352 |                         if verification_success:
353 |                             LOG.info(f"Successfully verified migration from {source_host} to {target_host}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
354 |                             success = True
355 |                             break
    |

hamgr/hamgr/providers/cinder.py:357:89: E501 Line too long (182 > 88)
    |
355 | …
356 | …
357 | …volumes still show old host with format {source_host}->{target_host}. Trying other host format combinations.")
    |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
358 | …
359 | …t format {source_host} to {target_host}: {result.stderr}")
    |

hamgr/hamgr/providers/cinder.py:359:89: E501 Line too long (130 > 88)
    |
357 | …                 LOG.warning(f"Database update succeeded but volumes still show old host with format {source_host}->{target_host}. T…
358 | …         else:
359 | …             LOG.warning(f"Failed to migrate volumes with host format {source_host} to {target_host}: {result.stderr}")
    |                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
360 | …     
361 | …     if success:
    |

hamgr/hamgr/providers/cinder.py:365:89: E501 Line too long (160 > 88)
    |
364 | …
365 | …inder_host}@{backend_name} to {new_host}@{backend_name} after trying all host format combinations")
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
366 | …
367 | …
    |

hamgr/hamgr/providers/cinder.py:376:27: F541 [*] f-string without any placeholders
    |
374 |         try:
375 |             if hasattr(self, '_cinder_db_connection') and self._cinder_db_connection:
376 |                 LOG.debug(f"Using cinder database connection from configuration")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ F541
377 |                 return self._cinder_db_connection
    |
    = help: Remove extraneous `f` prefix

hamgr/hamgr/providers/cinder.py:397:89: E501 Line too long (94 > 88)
    |
395 |                 host_attr = getattr(current_vol, 'os-vol-host-attr:host', None)
396 |                 
397 |                 base_target = target_host.split('#')[0] if '#' in target_host else target_host
    |                                                                                         ^^^^^^ E501
398 |                 
399 |                 LOG.info(f"Checking volume {volume.id} migration: current host = {host_attr}, target = {target_host}")
    |

hamgr/hamgr/providers/cinder.py:399:89: E501 Line too long (118 > 88)
    |
397 |                 base_target = target_host.split('#')[0] if '#' in target_host else target_host
398 |                 
399 |                 LOG.info(f"Checking volume {volume.id} migration: current host = {host_attr}, target = {target_host}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
400 |                 
401 |                 if host_attr and (host_attr == target_host or host_attr.startswith(base_target)):
    |

hamgr/hamgr/providers/cinder.py:401:89: E501 Line too long (97 > 88)
    |
399 |                 LOG.info(f"Checking volume {volume.id} migration: current host = {host_attr}, target = {target_host}")
400 |                 
401 |                 if host_attr and (host_attr == target_host or host_attr.startswith(base_target)):
    |                                                                                         ^^^^^^^^^ E501
402 |                     LOG.info(f"Volume {volume.id} successfully migrated to {host_attr}")
403 |                 else:
    |

hamgr/hamgr/providers/cinder.py:404:89: E501 Line too long (109 > 88)
    |
402 |                     LOG.info(f"Volume {volume.id} successfully migrated to {host_attr}")
403 |                 else:
404 |                     LOG.warning(f"Volume {volume.id} not migrated to target host. Current host: {host_attr}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
405 |                     all_migrated = False
    |

hamgr/hamgr/providers/cinder.py:447:89: E501 Line too long (95 > 88)
    |
445 |                 LOG.debug('Checking for standalone cinder hosts that might be down')
446 |                 cinder_hosts = self._get_cinder_hosts()
447 |                 LOG.debug(f"Found {len(cinder_hosts)} cinder hosts: {', '.join(cinder_hosts)}")
    |                                                                                         ^^^^^^^ E501
448 |                 
449 |                 for host in cinder_hosts:
    |

hamgr/hamgr/providers/cinder.py:454:89: E501 Line too long (111 > 88)
    |
452 |                         LOG.info(f"Detected standalone cinder host down: {host}")
453 |                         event_uuid = str(uuid.uuid4())
454 |                         LOG.info(f"Creating new cinder host down event with UUID {event_uuid} for host {host}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
455 |                         db_api.create_cinder_processing_event(
456 |                             event_uuid,
    |

hamgr/hamgr/providers/cinder.py:463:89: E501 Line too long (98 > 88)
    |
461 |                 unhandled_events = db_api.get_all_unhandled_cinder_processing_events()
462 |                 if not unhandled_events:
463 |                     LOG.debug('Still no cinder host events found after checking standalone hosts')
    |                                                                                         ^^^^^^^^^^ E501
464 |                     return
    |

hamgr/hamgr/providers/cinder.py:473:89: E501 Line too long (89 > 88)
    |
471 |             event_descriptions = []
472 |             for event in events:
473 |                 event_desc = (f"Event[uuid={event.event_uuid}, type={event.event_type}, "
    |                                                                                         ^ E501
474 |                              f"host={event.host_name}, time={event.event_time}, "
475 |                              f"status={event.notification_status}]")
    |

hamgr/hamgr/providers/cinder.py:486:89: E501 Line too long (103 > 88)
    |
484 |             for event in events:
485 |                 LOG.debug('Processing cinder event %s', 
486 |                          f"[uuid={event.event_uuid}, type={event.event_type}, host={event.host_name}]")
    |                                                                                         ^^^^^^^^^^^^^^^ E501
487 |                 event_uuid = event.event_uuid
488 |                 event_type = event.event_type
    |

hamgr/hamgr/providers/cinder.py:493:89: E501 Line too long (97 > 88)
    |
492 |                 if datetime.utcnow() - event_time > time_out:
493 |                     LOG.warning('Aborting stale cinder event %s from %s (older than %d minutes)',
    |                                                                                         ^^^^^^^^^ E501
494 |                               event_uuid, event_time, time_out.total_seconds() / 60)
495 |                     db_api.update_cinder_processing_event(
    |

hamgr/hamgr/providers/cinder.py:510:89: E501 Line too long (113 > 88)
    |
508 |                     backends = self._get_cinder_backends(host_name)
509 |                     if not backends:
510 |                         LOG.warning('No backends found for cinder host %s, aborting event processing', host_name)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
511 |                         db_api.update_cinder_processing_event(
512 |                             event_uuid, None, None,
    |

hamgr/hamgr/providers/cinder.py:518:89: E501 Line too long (107 > 88)
    |
516 |                         continue
517 |                     
518 |                     LOG.info(f"Found {len(backends)} backends for host {host_name}: {', '.join(backends)}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
519 |                     
520 |                     cinder_azs = self._get_cinder_availability_zones()
    |

hamgr/hamgr/providers/cinder.py:521:89: E501 Line too long (111 > 88)
    |
520 |                     cinder_azs = self._get_cinder_availability_zones()
521 |                     LOG.info(f"Cinder host {host_name} is part of availability zones: {', '.join(cinder_azs)}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
522 |                     
523 |                     success = True
    |

hamgr/hamgr/providers/cinder.py:525:89: E501 Line too long (90 > 88)
    |
523 |                     success = True
524 |                     for backend_name in backends:
525 |                         LOG.info(f"Processing backend {backend_name} on host {host_name}")
    |                                                                                         ^^ E501
526 |                         
527 |                         other_hosts = self._get_other_hosts_with_same_backend(host_name, backend_name)
    |

hamgr/hamgr/providers/cinder.py:527:89: E501 Line too long (102 > 88)
    |
525 | …     LOG.info(f"Processing backend {backend_name} on host {host_name}")
526 | …     
527 | …     other_hosts = self._get_other_hosts_with_same_backend(host_name, backend_name)
    |                                                                       ^^^^^^^^^^^^^^ E501
528 | …     if not other_hosts:
529 | …         LOG.warning(f"No other hosts found with backend {backend_name} in up state, skipping volume migration for this backend")
    |

hamgr/hamgr/providers/cinder.py:529:89: E501 Line too long (148 > 88)
    |
527 | …osts_with_same_backend(host_name, backend_name)
528 | …
529 | …s found with backend {backend_name} in up state, skipping volume migration for this backend")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
530 | …
    |

hamgr/hamgr/providers/cinder.py:532:89: E501 Line too long (127 > 88)
    |
530 |                             continue
531 |                         
532 |                         LOG.info(f"Found {len(other_hosts)} other hosts with backend {backend_name}: {', '.join(other_hosts)}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
533 |                         
534 |                         # Get volumes across all projects for cross-AZ attachments and glance backend
    |

hamgr/hamgr/providers/cinder.py:534:89: E501 Line too long (101 > 88)
    |
532 |                         LOG.info(f"Found {len(other_hosts)} other hosts with backend {backend_name}: {', '.join(other_hosts)}")
533 |                         
534 |                         # Get volumes across all projects for cross-AZ attachments and glance backend
    |                                                                                         ^^^^^^^^^^^^^ E501
535 |                         volumes = self._get_volumes_for_migration(host_name)
536 |                         if not volumes:
    |

hamgr/hamgr/providers/cinder.py:537:89: E501 Line too long (124 > 88)
    |
535 |                         volumes = self._get_volumes_for_migration(host_name)
536 |                         if not volumes:
537 |                             LOG.info(f"No volumes found on {host_name}@{backend_name}, skipping migration for this backend")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
538 |                             continue
    |

hamgr/hamgr/providers/cinder.py:541:89: E501 Line too long (131 > 88)
    |
540 |                         volume_ids = [v.id for v in volumes]
541 |                         LOG.info(f"Found {len(volumes)} volumes on {host_name}@{backend_name} to migrate: {', '.join(volume_ids)}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
542 |                         
543 |                         new_host = other_hosts[0]
    |

hamgr/hamgr/providers/cinder.py:544:89: E501 Line too long (125 > 88)
    |
543 |                         new_host = other_hosts[0]
544 |                         LOG.info(f"Selected host {new_host} as migration target for volumes from {host_name}@{backend_name}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
545 |                         
546 |                         migration_success = self._migrate_volumes(host_name, backend_name, new_host)
    |

hamgr/hamgr/providers/cinder.py:546:89: E501 Line too long (100 > 88)
    |
544 |                         LOG.info(f"Selected host {new_host} as migration target for volumes from {host_name}@{backend_name}")
545 |                         
546 |                         migration_success = self._migrate_volumes(host_name, backend_name, new_host)
    |                                                                                         ^^^^^^^^^^^^ E501
547 |                         if not migration_success:
548 |                             success = False
    |

hamgr/hamgr/providers/cinder.py:549:89: E501 Line too long (128 > 88)
    |
547 |                         if not migration_success:
548 |                             success = False
549 |                             LOG.error(f"Failed to migrate volumes from {host_name}@{backend_name} to {new_host}@{backend_name}")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
550 |                     
551 |                     if success:
    |

hamgr/hamgr/providers/cinder.py:552:89: E501 Line too long (133 > 88)
    |
551 |                     if success:
552 |                         LOG.info(f"Successfully processed all backends for host {host_name}, marking event {event_uuid} as finished")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
553 |                         db_api.update_cinder_processing_event(
554 |                             event_uuid, None, None,
    |

hamgr/hamgr/providers/cinder.py:559:89: E501 Line too long (128 > 88)
    |
557 |                         )
558 |                     else:
559 |                         LOG.error(f"Failed to process some backends for host {host_name}, marking event {event_uuid} as failed")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
560 |                         db_api.update_cinder_processing_event(
561 |                             event_uuid, None, None,
    |

hamgr/hamgr/providers/cinder.py:568:89: E501 Line too long (114 > 88)
    |
566 |                 elif event_type == constants.EVENT_HOST_UP:
567 |                     if is_active:
568 |                         LOG.info('Cinder host %s is back up, marking event %s as finished', host_name, event_uuid)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
569 |                         db_api.update_cinder_processing_event(
570 |                             event_uuid, None, None,
    |

hamgr/hamgr/providers/cinder.py:575:89: E501 Line too long (115 > 88)
    |
573 |                         )
574 |                     else:
575 |                         LOG.warning('Cinder host %s is still down, keeping event %s active', host_name, event_uuid)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
576 |                 
577 |                 else:
    |

hamgr/hamgr/providers/cinder.py:578:89: E501 Line too long (95 > 88)
    |
577 |                 else:
578 |                     LOG.warning('Unknown cinder event type %s for host %s, aborting event %s', 
    |                                                                                         ^^^^^^^ E501
579 |                               event_type, host_name, event_uuid)
580 |                     db_api.update_cinder_processing_event(
    |

hamgr/hamgr/providers/cinder.py:588:89: E501 Line too long (91 > 88)
    |
586 |             LOG.debug('Finished processing cinder host events')
587 |         except Exception as ex:
588 |             LOG.exception('Unhandled exception in process_cinder_host_events: %s', str(ex))
    |                                                                                         ^^^ E501
589 |         finally:
590 |             with self.cinder_events_processing_lock:
    |

hamgr/hamgr/providers/nova.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import json
16 | | import logging
17 | | import threading
18 | | import time
19 | | from random import randint
20 | | from itertools import combinations
21 | | from collections import defaultdict
22 | | from datetime import datetime
23 | | from datetime import timedelta
24 | | from uuid import uuid4
25 | |
26 | | import requests
27 | | from keystoneauth1 import loading
28 | | from keystoneauth1 import session
29 | | from novaclient import client
30 | | from novaclient import exceptions
31 | |
32 | | import hamgr
33 | | from hamgr.common import masakari
34 | | from hamgr.common import utils
35 | | from hamgr.db import api as db_api
36 | | from hamgr.notification import get_notification_manager
37 | | from hamgr.providers.provider import Provider
38 | | from hamgr.rebalance import get_rebalance_controller
39 | | from shared import constants
40 | | from shared.exceptions import ha_exceptions
41 | | from shared.messages.rebalance_request import ConsulRoleRebalanceRequest
42 | | from shared.messages.cluster_event import ClusterEvent
43 | | from shared.messages.consul_request import ConsulRefreshRequest
44 | | from hamgr.common import key_helper as keyhelper
45 | | from hamgr.resmgr_client import ResmgrClient
46 | | from shared.constants import LOGGER_PREFIX
47 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
48 |
49 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/providers/nova.py:20:23: F401 [*] `itertools.combinations` imported but unused
   |
18 | import time
19 | from random import randint
20 | from itertools import combinations
   |                       ^^^^^^^^^^^^ F401
21 | from collections import defaultdict
22 | from datetime import datetime
   |
   = help: Remove unused import: `itertools.combinations`

hamgr/hamgr/providers/nova.py:30:24: F401 [*] `novaclient.exceptions` imported but unused
   |
28 | from keystoneauth1 import session
29 | from novaclient import client
30 | from novaclient import exceptions
   |                        ^^^^^^^^^^ F401
31 |
32 | import hamgr
   |
   = help: Remove unused import: `novaclient.exceptions`

hamgr/hamgr/providers/nova.py:96:89: E501 Line too long (96 > 88)
   |
94 |                     self._db_pwd = self._db_pwd[idx+1:]
95 |         try:
96 |             self._max_auth_wait_seconds = config.getint('DEFAULT', 'max_role_auth_wait_seconds')
   |                                                                                         ^^^^^^^^ E501
97 |         except:
98 |             LOG.warning("'max_role_auth_wait_seconds' not exist in config file " \
   |

hamgr/hamgr/providers/nova.py:97:9: E722 Do not use bare `except`
   |
95 |         try:
96 |             self._max_auth_wait_seconds = config.getint('DEFAULT', 'max_role_auth_wait_seconds')
97 |         except:
   |         ^^^^^^ E722
98 |             LOG.warning("'max_role_auth_wait_seconds' not exist in config file " \
99 |                      "or its value not integer, use default 300")
   |

hamgr/hamgr/providers/nova.py:104:89: E501 Line too long (111 > 88)
    |
102 |         self._max_role_converged_wait_seconds = 900
103 |         try:
104 |             self._max_role_converged_wait_seconds = config.getint('DEFAULT', 'max_role_converged_wait_seconds')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
105 |         except:
106 |             LOG.warning("'max_role_converged_wait_seconds' not exist in config file " \
    |

hamgr/hamgr/providers/nova.py:105:9: E722 Do not use bare `except`
    |
103 |         try:
104 |             self._max_role_converged_wait_seconds = config.getint('DEFAULT', 'max_role_converged_wait_seconds')
105 |         except:
    |         ^^^^^^ E722
106 |             LOG.warning("'max_role_converged_wait_seconds' not exist in config file " \
107 |                      "or its value not integer, use default 900")
    |

hamgr/hamgr/providers/nova.py:139:89: E501 Line too long (90 > 88)
    |
137 |                                         'event_report_threshold_seconds')
138 |         if setting_seconds <= 0:
139 |             raise ha_exceptions.ConfigException('invalid setting in configuration file : '
    |                                                                                         ^^ E501
140 |                                                 'event_report_threshold_seconds '
141 |                                                 'should be bigger than 0')
    |

hamgr/hamgr/providers/nova.py:183:89: E501 Line too long (109 > 88)
    |
181 |         azInfo = {}
182 |         headers = {"X-AUTH-TOKEN": token}
183 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-availability-zone/detail'
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
184 |         response = requests.get(url, headers=headers)
185 |         if response.status_code == 200:
    |

hamgr/hamgr/providers/nova.py:196:89: E501 Line too long (93 > 88)
    |
194 |         nova_hosts = []
195 |         headers = {"X-AUTH-TOKEN": token}
196 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-services'
    |                                                                                         ^^^^^ E501
197 |         response = requests.get(url, headers=headers)
198 |         if response.status_code == 200:
    |

hamgr/hamgr/providers/nova.py:266:89: E501 Line too long (90 > 88)
    |
264 |                 # if cluster of this event is disabled, no need to handle it
265 |                 if not cluster or not cluster.enabled:
266 |                     LOG.warning('cluster %s in event %s is not enabled or does not exist',
    |                                                                                         ^^ E501
267 |                                 event.cluster_id, str(event_uuid))
268 |                     db_api.update_processing_event_with_notification(
    |

hamgr/hamgr/providers/nova.py:280:24: E713 [*] Test for membership should be `not in`
    |
278 |                     return
279 |                 # if no such availability zone, no need to handle it
280 |                 if not cluster.name in nova_active_azs:
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E713
281 |                     LOG.warning('no availability zone found with name %s for event %s',
282 |                                 str(cluster.name), str(event_uuid))
    |
    = help: Convert to `not in`

hamgr/hamgr/providers/nova.py:288:89: E501 Line too long (102 > 88)
    |
286 |                 nova_hosts = self._get_nova_hosts(self._token['id'], cluster.name)
287 |                 if not nova_hosts:
288 |                     LOG.error('Error getting hosts in availability zone %s, will retry', cluster.name)
    |                                                                                         ^^^^^^^^^^^^^^ E501
289 |                     return
290 |                 if host_name not in nova_hosts:
    |

hamgr/hamgr/providers/nova.py:291:89: E501 Line too long (93 > 88)
    |
289 |                     return
290 |                 if host_name not in nova_hosts:
291 |                     LOG.warning('host %s in event %s does not exist in availability zone %s',
    |                                                                                         ^^^^^ E501
292 |                                 host_name, str(event_uuid), str(nova_hosts))
293 |                     db_api.update_processing_event_with_notification(
    |

hamgr/hamgr/providers/nova.py:307:89: E501 Line too long (95 > 88)
    |
305 |                 # so we do similar check to skip duplicated report.
306 |                 end_time = datetime.utcnow()
307 |                 start_time = end_time - timedelta(seconds=self._event_report_threshold_seconds)
    |                                                                                         ^^^^^^^ E501
308 |                 existing_events = db_api.get_processing_events_between_times(
309 |                         event_type,
    |

hamgr/hamgr/providers/nova.py:328:89: E501 Line too long (92 > 88)
    |
326 |                                 msg
327 |                         )
328 |                         LOG.warning('event %s is aborted, as %s', str(event_uuid), str(msg))
    |                                                                                         ^^^^ E501
329 |                         continue
    |

hamgr/hamgr/providers/nova.py:333:89: E501 Line too long (105 > 88)
    |
331 |                 # if the event happened long time ago, just abort
332 |                 if datetime.utcnow() - event_time > time_out:
333 |                     if event.notification_uuid and event.notification_status != constants.STATE_FINISHED:
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
334 |                         state = masakari.get_notification_status(self._token, event.notification_uuid)
335 |                         LOG.info('event %s is in state : %s , corresponding masakari notification state : %s',
    |

hamgr/hamgr/providers/nova.py:334:89: E501 Line too long (102 > 88)
    |
332 |                 if datetime.utcnow() - event_time > time_out:
333 |                     if event.notification_uuid and event.notification_status != constants.STATE_FINISHED:
334 |                         state = masakari.get_notification_status(self._token, event.notification_uuid)
    |                                                                                         ^^^^^^^^^^^^^^ E501
335 |                         LOG.info('event %s is in state : %s , corresponding masakari notification state : %s',
336 |                                  str(event_uuid), str(event.notification_status), str(state))
    |

hamgr/hamgr/providers/nova.py:335:89: E501 Line too long (110 > 88)
    |
333 |                     if event.notification_uuid and event.notification_status != constants.STATE_FINISHED:
334 |                         state = masakari.get_notification_status(self._token, event.notification_uuid)
335 |                         LOG.info('event %s is in state : %s , corresponding masakari notification state : %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
336 |                                  str(event_uuid), str(event.notification_status), str(state))
337 |                     db_api.update_processing_event_with_notification(
    |

hamgr/hamgr/providers/nova.py:336:89: E501 Line too long (93 > 88)
    |
334 |                         state = masakari.get_notification_status(self._token, event.notification_uuid)
335 |                         LOG.info('event %s is in state : %s , corresponding masakari notification state : %s',
336 |                                  str(event_uuid), str(event.notification_status), str(state))
    |                                                                                         ^^^^^ E501
337 |                     db_api.update_processing_event_with_notification(
338 |                         event_uuid, None, None,
    |

hamgr/hamgr/providers/nova.py:347:89: E501 Line too long (92 > 88)
    |
346 |                 # check whether host is active in nova
347 |                 LOG.debug('try to check whether host %s in nova is active ', str(host_name))
    |                                                                                         ^^^^ E501
348 |                 is_active = self._is_nova_service_active(host_name, nova_client=nova_client)
349 |                 LOG.debug('is host %s active in nova ? %s', host_name, str(is_active))
    |

hamgr/hamgr/providers/nova.py:348:89: E501 Line too long (92 > 88)
    |
346 |                 # check whether host is active in nova
347 |                 LOG.debug('try to check whether host %s in nova is active ', str(host_name))
348 |                 is_active = self._is_nova_service_active(host_name, nova_client=nova_client)
    |                                                                                         ^^^^ E501
349 |                 LOG.debug('is host %s active in nova ? %s', host_name, str(is_active))
    |

hamgr/hamgr/providers/nova.py:355:89: E501 Line too long (109 > 88)
    |
353 |                     if not event.notification_uuid:
354 |                         if is_active:
355 |                             LOG.info('Still reporting host_down event to masakari, host %s is alive in nova',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
356 |                                      host_name)
357 |                             #continue
    |

hamgr/hamgr/providers/nova.py:359:89: E501 Line too long (120 > 88)
    |
357 |                             #continue
358 |
359 |                         # when masakari received host-down notification, the host in masakari will be set on maintenance
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
360 |                         # if a host in masakari is marked as on maintenance, it will give 409 error if you try to
361 |                         # create another host-down notification for it. we have another task to reset the maintenance
    |

hamgr/hamgr/providers/nova.py:360:89: E501 Line too long (113 > 88)
    |
359 |                         # when masakari received host-down notification, the host in masakari will be set on maintenance
360 |                         # if a host in masakari is marked as on maintenance, it will give 409 error if you try to
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
361 |                         # create another host-down notification for it. we have another task to reset the maintenance
362 |                         # status when the masakari failover segment is not under recovery. so we can wait that complete
    |

hamgr/hamgr/providers/nova.py:361:89: E501 Line too long (117 > 88)
    |
359 |                         # when masakari received host-down notification, the host in masakari will be set on maintenance
360 |                         # if a host in masakari is marked as on maintenance, it will give 409 error if you try to
361 |                         # create another host-down notification for it. we have another task to reset the maintenance
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
362 |                         # status when the masakari failover segment is not under recovery. so we can wait that complete
363 |                         # here before trying to create another notification. this will avoid the 409 error.
    |

hamgr/hamgr/providers/nova.py:362:89: E501 Line too long (119 > 88)
    |
360 |                         # if a host in masakari is marked as on maintenance, it will give 409 error if you try to
361 |                         # create another host-down notification for it. we have another task to reset the maintenance
362 |                         # status when the masakari failover segment is not under recovery. so we can wait that complete
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
363 |                         # here before trying to create another notification. this will avoid the 409 error.
364 |                         #
    |

hamgr/hamgr/providers/nova.py:363:89: E501 Line too long (107 > 88)
    |
361 |                         # create another host-down notification for it. we have another task to reset the maintenance
362 |                         # status when the masakari failover segment is not under recovery. so we can wait that complete
363 |                         # here before trying to create another notification. this will avoid the 409 error.
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
364 |                         #
365 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
    |

hamgr/hamgr/providers/nova.py:365:89: E501 Line too long (102 > 88)
    |
363 |                         # here before trying to create another notification. this will avoid the 409 error.
364 |                         #
365 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
    |                                                                                         ^^^^^^^^^^^^^^ E501
366 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
367 |                                      'which is active in nova', event_type, event_uuid, host_name)
    |

hamgr/hamgr/providers/nova.py:366:89: E501 Line too long (110 > 88)
    |
364 |                         #
365 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
366 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
367 |                                      'which is active in nova', event_type, event_uuid, host_name)
368 |                             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster.name,
    |

hamgr/hamgr/providers/nova.py:367:89: E501 Line too long (98 > 88)
    |
365 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
366 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
367 |                                      'which is active in nova', event_type, event_uuid, host_name)
    |                                                                                         ^^^^^^^^^^ E501
368 |                             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster.name,
369 |                                                                            host_ids=[host_name],
    |

hamgr/hamgr/providers/nova.py:371:89: E501 Line too long (114 > 88)
    |
369 | …                                                                    host_ids=[host_name],
370 | …                                                                    ignore_status_in_nova=True)
371 | …                     masakari_host_on_maintenance = masakari.is_host_on_maintenance(self._token, host_name,
    |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
372 | …                                                                                    cluster.name)
373 | …                     if masakari_host_on_maintenance:
    |

hamgr/hamgr/providers/nova.py:374:89: E501 Line too long (103 > 88)
    |
372 | …                                                                                    cluster.name)
373 | …                     if masakari_host_on_maintenance:
374 | …                         LOG.warning('%s event %s for host %s, which is in masakari segment %s '
    |                                                                                   ^^^^^^^^^^^^^^^ E501
375 | …                                     'is on maintenance', event_type, event_uuid,
376 | …                                     host_name, cluster.name)
    |

hamgr/hamgr/providers/nova.py:381:89: E501 Line too long (114 > 88)
    |
379 |                         notification_obj = self._report_event_to_masakari(event)
380 |                         if notification_obj:
381 |                             LOG.info('Host-down event %s for host %s is reported to masakari, notification id %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
382 |                                      event_uuid, host_name, str(notification_obj))
383 |                             event.notification_uuid = notification_obj['notification']['notification_uuid']
    |

hamgr/hamgr/providers/nova.py:383:89: E501 Line too long (107 > 88)
    |
381 | …                     LOG.info('Host-down event %s for host %s is reported to masakari, notification id %s',
382 | …                              event_uuid, host_name, str(notification_obj))
383 | …                     event.notification_uuid = notification_obj['notification']['notification_uuid']
    |                                                                                   ^^^^^^^^^^^^^^^^^^^ E501
384 | …                     state = self._tracking_masakari_notification(event)
385 | …                     LOG.info('event %s for host %s is updated with notification state %s',
    |

hamgr/hamgr/providers/nova.py:385:89: E501 Line too long (98 > 88)
    |
383 |                             event.notification_uuid = notification_obj['notification']['notification_uuid']
384 |                             state = self._tracking_masakari_notification(event)
385 |                             LOG.info('event %s for host %s is updated with notification state %s',
    |                                                                                         ^^^^^^^^^^ E501
386 |                                      event_uuid, host_name, state)
387 |                         else:
    |

hamgr/hamgr/providers/nova.py:388:89: E501 Line too long (98 > 88)
    |
386 |                                      event_uuid, host_name, state)
387 |                         else:
388 |                             LOG.error('failed to report %s event %s for host %s to masakari : %s',
    |                                                                                         ^^^^^^^^^^ E501
389 |                                       event_type, event_uuid, host_name, str(event))
390 |                     else:
    |

hamgr/hamgr/providers/nova.py:392:89: E501 Line too long (104 > 88)
    |
390 |                     else:
391 |                         state = self._tracking_masakari_notification(event)
392 |                         LOG.info('Host-down event %s for host %s is updated with notification state %s',
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
393 |                                  event_uuid, host_name, state)
394 |                 elif event_type == constants.EVENT_HOST_UP:
    |

hamgr/hamgr/providers/nova.py:396:89: E501 Line too long (102 > 88)
    |
394 |                 elif event_type == constants.EVENT_HOST_UP:
395 |                     if is_active:
396 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
    |                                                                                         ^^^^^^^^^^^^^^ E501
397 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
398 |                                      'which is active in nova', event_type, event_uuid, host_name)
    |

hamgr/hamgr/providers/nova.py:397:89: E501 Line too long (110 > 88)
    |
395 |                     if is_active:
396 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
397 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
398 |                                      'which is active in nova', event_type, event_uuid, host_name)
399 |                             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster.name,
    |

hamgr/hamgr/providers/nova.py:398:89: E501 Line too long (98 > 88)
    |
396 |                         if not masakari.is_failover_segment_under_recovery(self._token, cluster.name):
397 |                             LOG.info('in event %s %s for host %s, try to reset maintenance state in masakari '
398 |                                      'which is active in nova', event_type, event_uuid, host_name)
    |                                                                                         ^^^^^^^^^^ E501
399 |                             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster.name,
400 |                                                                            host_ids=[host_name])
    |

hamgr/hamgr/providers/nova.py:402:89: E501 Line too long (109 > 88)
    |
400 |                                                                            host_ids=[host_name])
401 |                         else:
402 |                             LOG.info('retry toggle maintence state for host %s as cluster %s is in recovery',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
403 |                                      str(host_name), str(cluster.name))
    |

hamgr/hamgr/providers/nova.py:409:89: E501 Line too long (92 > 88)
    |
407 |                                                                          None,
408 |                                                                          constants.STATE_FINISHED)
409 |                         LOG.info('Host-up event %s for host %s is marked as %s', event_uuid,
    |                                                                                         ^^^^ E501
410 |                                  host_name, constants.STATE_FINISHED)
411 |                     else:
    |

hamgr/hamgr/providers/nova.py:427:89: E501 Line too long (91 > 88)
    |
425 |             with self.events_processing_lock:
426 |                 self.events_processing_running = False
427 |         LOG.debug('host events processing task has finished at %s', str(datetime.utcnow()))
    |                                                                                         ^^^ E501
428 |
429 |     def _report_event_to_masakari(self, event):
    |

hamgr/hamgr/providers/nova.py:450:89: E501 Line too long (97 > 88)
    |
448 |         except Exception:
449 |             LOG.error('failed to create masakari notification, error', exc_info=True)
450 |         LOG.warning('no valid masakari notification was created for event %s %s for host %s: %s',
    |                                                                                         ^^^^^^^^^ E501
451 |                     event.event_type, event.event_uuid, event.host_name, str(notification_obj))
452 |         return None
    |

hamgr/hamgr/providers/nova.py:451:89: E501 Line too long (95 > 88)
    |
449 |             LOG.error('failed to create masakari notification, error', exc_info=True)
450 |         LOG.warning('no valid masakari notification was created for event %s %s for host %s: %s',
451 |                     event.event_type, event.event_uuid, event.host_name, str(notification_obj))
    |                                                                                         ^^^^^^^ E501
452 |         return None
    |

hamgr/hamgr/providers/nova.py:501:89: E501 Line too long (95 > 88)
    |
499 |             with self.availability_zone_task_lock:
500 |                 if self.availability_zone_task_running:
501 |                     LOG.debug('Check host availability_zones for changes task already running')
    |                                                                                         ^^^^^^^ E501
502 |                     return
503 |                 self.availability_zone_task_running = True
    |

hamgr/hamgr/providers/nova.py:505:89: E501 Line too long (114 > 88)
    |
503 |                 self.availability_zone_task_running = True
504 |
505 |             LOG.debug('host availability_zone change processing task starts to run at %s', str(datetime.utcnow()))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
506 |
507 |             # ---------------------------------------------------------------
    |

hamgr/hamgr/providers/nova.py:509:89: E501 Line too long (99 > 88)
    |
507 |             # ---------------------------------------------------------------
508 |             # scenarios
509 |             #  1) nova availability_zone exists   [ sync from nova availability_zone to ha system ]
    |                                                                                         ^^^^^^^^^^^ E501
510 |             #     1.1) corresponding ha cluster exists
511 |             #        1.1.1) masakari (failover segment, hosts) does not match hosts from nova availability_zone
    |

hamgr/hamgr/providers/nova.py:511:89: E501 Line too long (111 > 88)
    |
509 |             #  1) nova availability_zone exists   [ sync from nova availability_zone to ha system ]
510 |             #     1.1) corresponding ha cluster exists
511 |             #        1.1.1) masakari (failover segment, hosts) does not match hosts from nova availability_zone
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
512 |             #             X = {hosts in masakari} , Y = {host in nova availability_zone}, Z = { common hosts in X and Y}
513 |             #            1.1.1.1) X and Y have no common
    |

hamgr/hamgr/providers/nova.py:512:89: E501 Line too long (120 > 88)
    |
510 |             #     1.1) corresponding ha cluster exists
511 |             #        1.1.1) masakari (failover segment, hosts) does not match hosts from nova availability_zone
512 |             #             X = {hosts in masakari} , Y = {host in nova availability_zone}, Z = { common hosts in X and Y}
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
513 |             #            1.1.1.1) X and Y have no common
514 |             #                 remove all masakari hosts, then add nova availability_zone hosts to masakari
    |

hamgr/hamgr/providers/nova.py:514:89: E501 Line too long (106 > 88)
    |
512 |             #             X = {hosts in masakari} , Y = {host in nova availability_zone}, Z = { common hosts in X and Y}
513 |             #            1.1.1.1) X and Y have no common
514 |             #                 remove all masakari hosts, then add nova availability_zone hosts to masakari
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
515 |             #            1.1.1.2) X and Y have some in common
516 |             #                 remove additional hosts (X-Z) from masakari, add additional host (Y-Z) to masakari
    |

hamgr/hamgr/providers/nova.py:516:89: E501 Line too long (112 > 88)
    |
514 |             #                 remove all masakari hosts, then add nova availability_zone hosts to masakari
515 |             #            1.1.1.2) X and Y have some in common
516 |             #                 remove additional hosts (X-Z) from masakari, add additional host (Y-Z) to masakari
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
517 |             #                 this also works for
518 |             #                   - Y is subset of X : just add additional hosts to masakari
    |

hamgr/hamgr/providers/nova.py:518:89: E501 Line too long (90 > 88)
    |
516 |             #                 remove additional hosts (X-Z) from masakari, add additional host (Y-Z) to masakari
517 |             #                 this also works for
518 |             #                   - Y is subset of X : just add additional hosts to masakari
    |                                                                                         ^^ E501
519 |             #                   - X is subset of Y : just remove additional hosts from masakari
520 |             #        1.1.2) masakari (failover segment, hosts) matches hosts from nova availability_zone
    |

hamgr/hamgr/providers/nova.py:519:89: E501 Line too long (95 > 88)
    |
517 |             #                 this also works for
518 |             #                   - Y is subset of X : just add additional hosts to masakari
519 |             #                   - X is subset of Y : just remove additional hosts from masakari
    |                                                                                         ^^^^^^^ E501
520 |             #        1.1.2) masakari (failover segment, hosts) matches hosts from nova availability_zone
521 |             #           no action needed
    |

hamgr/hamgr/providers/nova.py:520:89: E501 Line too long (104 > 88)
    |
518 |             #                   - Y is subset of X : just add additional hosts to masakari
519 |             #                   - X is subset of Y : just remove additional hosts from masakari
520 |             #        1.1.2) masakari (failover segment, hosts) matches hosts from nova availability_zone
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
521 |             #           no action needed
522 |             #    1.2) corresponding ha cluster does not exist
    |

hamgr/hamgr/providers/nova.py:523:89: E501 Line too long (103 > 88)
    |
521 |             #           no action needed
522 |             #    1.2) corresponding ha cluster does not exist
523 |             #        need to create a disabled ha cluster , and add masakari failover segment and hosts
    |                                                                                         ^^^^^^^^^^^^^^^ E501
524 |             #  2) nova availability_zone does not exists  [ build nova availability_zones from ha system ]
525 |             #     [ not sure whether this is valid scenario, because create nova availability_zones needs to know
    |

hamgr/hamgr/providers/nova.py:524:89: E501 Line too long (106 > 88)
    |
522 |             #    1.2) corresponding ha cluster does not exist
523 |             #        need to create a disabled ha cluster , and add masakari failover segment and hosts
524 |             #  2) nova availability_zone does not exists  [ build nova availability_zones from ha system ]
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
525 |             #     [ not sure whether this is valid scenario, because create nova availability_zones needs to know
526 |             #      availability zone infomation , especially when there is no availability zone . ]
    |

hamgr/hamgr/providers/nova.py:525:89: E501 Line too long (113 > 88)
    |
523 |             #        need to create a disabled ha cluster , and add masakari failover segment and hosts
524 |             #  2) nova availability_zone does not exists  [ build nova availability_zones from ha system ]
525 |             #     [ not sure whether this is valid scenario, because create nova availability_zones needs to know
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
526 |             #      availability zone infomation , especially when there is no availability zone . ]
527 |             # ----------------------------------------------------------
    |

hamgr/hamgr/providers/nova.py:526:89: E501 Line too long (99 > 88)
    |
524 |             #  2) nova availability_zone does not exists  [ build nova availability_zones from ha system ]
525 |             #     [ not sure whether this is valid scenario, because create nova availability_zones needs to know
526 |             #      availability zone infomation , especially when there is no availability zone . ]
    |                                                                                         ^^^^^^^^^^^ E501
527 |             # ----------------------------------------------------------
528 |             # first reconcile hosts between nova availability_zones and masakari
    |

hamgr/hamgr/providers/nova.py:544:89: E501 Line too long (118 > 88)
    |
542 |             LOG.debug('all vmha clusters : %s', str(hamgr_all_clusters))
543 |
544 |             # because hosts in availability zone reflect the real world settings for HA, so need to reconcile hosts in
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
545 |             # each availability zone from nova to hamgr and masakari
546 |             # for each active availability zone
    |

hamgr/hamgr/providers/nova.py:547:89: E501 Line too long (121 > 88)
    |
545 |             # each availability zone from nova to hamgr and masakari
546 |             # for each active availability zone
547 |             #  if there is corresponding ha cluster, then update hosts in masakari with hosts from this availability zone
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
548 |             #  else create ha cluster in hamgr , and in masakari , but put the cluster in disabled state
    |

hamgr/hamgr/providers/nova.py:548:89: E501 Line too long (104 > 88)
    |
546 |             # for each active availability zone
547 |             #  if there is corresponding ha cluster, then update hosts in masakari with hosts from this availability zone
548 |             #  else create ha cluster in hamgr , and in masakari , but put the cluster in disabled state
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
549 |             
550 |             for az in azInfo['availabilityZoneInfo']:
    |

hamgr/hamgr/providers/nova.py:556:89: E501 Line too long (97 > 88)
    |
554 |                 az_hosts = self._get_nova_hosts(self._token['id'], az_name)
555 |                 if not az_hosts:
556 |                     LOG.error('Error getting hosts in availability zone %s, will retry', az_name)
    |                                                                                         ^^^^^^^^^ E501
557 |                     return
558 |                 # is there a ha cluster for az_name ?
    |

hamgr/hamgr/providers/nova.py:559:89: E501 Line too long (92 > 88)
    |
557 |                     return
558 |                 # is there a ha cluster for az_name ?
559 |                 hamgr_clusters_for_az = [x for x in hamgr_all_clusters if x.name == az_name]
    |                                                                                         ^^^^ E501
560 |                 if not hamgr_clusters_for_az:
561 |                     LOG.debug('there is no matched vmha cluster with name matches to availability zone name %s',
    |

hamgr/hamgr/providers/nova.py:561:89: E501 Line too long (112 > 88)
    |
559 |                 hamgr_clusters_for_az = [x for x in hamgr_all_clusters if x.name == az_name]
560 |                 if not hamgr_clusters_for_az:
561 |                     LOG.debug('there is no matched vmha cluster with name matches to availability zone name %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
562 |                               az_name)
563 |                     continue
    |

hamgr/hamgr/providers/nova.py:565:89: E501 Line too long (100 > 88)
    |
563 |                     continue
564 |                 elif len(hamgr_clusters_for_az) > 1:
565 |                     LOG.warning('there are more than 1 vmha clusters for availability zone %s : %s',
    |                                                                                         ^^^^^^^^^^^^ E501
566 |                                 az_name, str(hamgr_clusters_for_az))
567 |                 LOG.info('%s host ids from availability zone %s: %s', str(len(az_hosts)),
    |

hamgr/hamgr/providers/nova.py:567:89: E501 Line too long (89 > 88)
    |
565 |                     LOG.warning('there are more than 1 vmha clusters for availability zone %s : %s',
566 |                                 az_name, str(hamgr_clusters_for_az))
567 |                 LOG.info('%s host ids from availability zone %s: %s', str(len(az_hosts)),
    |                                                                                         ^ E501
568 |                          str(az_name), str(az_hosts))
    |

hamgr/hamgr/providers/nova.py:570:89: E501 Line too long (94 > 88)
    |
568 |                          str(az_name), str(az_hosts))
569 |
570 |                 # we only support one-to-one mapping between vmha cluster to availability zone
    |                                                                                         ^^^^^^ E501
571 |                 current_cluster = hamgr_clusters_for_az[0]
572 |                 LOG.info('pick the first matched vmha cluster %s for availability zone name %s',
    |

hamgr/hamgr/providers/nova.py:572:89: E501 Line too long (96 > 88)
    |
570 |                 # we only support one-to-one mapping between vmha cluster to availability zone
571 |                 current_cluster = hamgr_clusters_for_az[0]
572 |                 LOG.info('pick the first matched vmha cluster %s for availability zone name %s',
    |                                                                                         ^^^^^^^^ E501
573 |                          current_cluster.name, az_name)
574 |                 if current_cluster.status == 'request-enable': 
    |

hamgr/hamgr/providers/nova.py:575:89: E501 Line too long (153 > 88)
    |
573 | …
574 | …ble': 
575 | …availability zone: %s not precessing it', current_cluster.name)                                 
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
576 | …
577 | …ent_cluster.name):
    |

hamgr/hamgr/providers/nova.py:581:89: E501 Line too long (132 > 88)
    |
579 |                     LOG.debug("current cluster status in hamgr %s", hamgr_entry.status)
580 |                     if hamgr_entry.status in [constants.HA_STATE_DISABLED]:
581 |                         LOG.info('VMHA enabled on cluster %s from resmgr. Setting db state to request-enable', current_cluster.name)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
582 |                         db_api.update_request_status(current_cluster.name, constants.HA_STATE_REQUEST_ENABLE)
583 |                         db_api.update_cluster_task_state(current_cluster.name, constants.TASK_WAITING)
    |

hamgr/hamgr/providers/nova.py:582:89: E501 Line too long (109 > 88)
    |
580 |                     if hamgr_entry.status in [constants.HA_STATE_DISABLED]:
581 |                         LOG.info('VMHA enabled on cluster %s from resmgr. Setting db state to request-enable', current_cluster.name)
582 |                         db_api.update_request_status(current_cluster.name, constants.HA_STATE_REQUEST_ENABLE)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
583 |                         db_api.update_cluster_task_state(current_cluster.name, constants.TASK_WAITING)
584 |                         continue
    |

hamgr/hamgr/providers/nova.py:583:89: E501 Line too long (102 > 88)
    |
581 |                         LOG.info('VMHA enabled on cluster %s from resmgr. Setting db state to request-enable', current_cluster.name)
582 |                         db_api.update_request_status(current_cluster.name, constants.HA_STATE_REQUEST_ENABLE)
583 |                         db_api.update_cluster_task_state(current_cluster.name, constants.TASK_WAITING)
    |                                                                                         ^^^^^^^^^^^^^^ E501
584 |                         continue
585 |                 # reconcile hosts to hamgr and masakari
    |

hamgr/hamgr/providers/nova.py:591:89: E501 Line too long (92 > 88)
    |
589 |                 cluster_task_state = current_cluster.task_state
590 |
591 |                 # ideally the hosts from masakari is the same as hosts in availability zones
    |                                                                                         ^^^^ E501
592 |                 # if more hosts in availability zone, means they exist in availability zone but not in masakari
593 |                 # if more hosts in masakari, means some of they are removed from availability zone
    |

hamgr/hamgr/providers/nova.py:592:89: E501 Line too long (111 > 88)
    |
591 |                 # ideally the hosts from masakari is the same as hosts in availability zones
592 |                 # if more hosts in availability zone, means they exist in availability zone but not in masakari
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
593 |                 # if more hosts in masakari, means some of they are removed from availability zone
    |

hamgr/hamgr/providers/nova.py:593:89: E501 Line too long (98 > 88)
    |
591 |                 # ideally the hosts from masakari is the same as hosts in availability zones
592 |                 # if more hosts in availability zone, means they exist in availability zone but not in masakari
593 |                 # if more hosts in masakari, means some of they are removed from availability zone
    |                                                                                         ^^^^^^^^^^ E501
594 |
595 |                 masakari_hosts = []
    |

hamgr/hamgr/providers/nova.py:599:89: E501 Line too long (98 > 88)
    |
597 |                 # remove host found in masakari segment but not in availability zone
598 |                 if masakari.is_failover_segment_exist(self._token, str(cluster_name)):
599 |                     masakari_hosts = masakari.get_nodes_in_segment(self._token, str(cluster_name))
    |                                                                                         ^^^^^^^^^^ E501
600 |                 masakari_hids = [x['name'] for x in masakari_hosts]
601 |                 common_ids = set(az_hosts).intersection(set(masakari_hids))
    |

hamgr/hamgr/providers/nova.py:603:89: E501 Line too long (101 > 88)
    |
601 |                 common_ids = set(az_hosts).intersection(set(masakari_hids))
602 |                 masakari_delta_ids = set(masakari_hids) - set(common_ids)
603 |                 LOG.debug('cluster name  %s, masakari hids : %s, az name %s hids %s, common ids %s, '
    |                                                                                         ^^^^^^^^^^^^^ E501
604 |                           'masakari additional hids %s, size:%s', str(cluster_name), str(masakari_hids),
605 |                           str(az_name), str(az_hosts), str(common_ids),
    |

hamgr/hamgr/providers/nova.py:604:89: E501 Line too long (104 > 88)
    |
602 |                 masakari_delta_ids = set(masakari_hids) - set(common_ids)
603 |                 LOG.debug('cluster name  %s, masakari hids : %s, az name %s hids %s, common ids %s, '
604 |                           'masakari additional hids %s, size:%s', str(cluster_name), str(masakari_hids),
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
605 |                           str(az_name), str(az_hosts), str(common_ids),
606 |                           str(masakari_delta_ids), str(len(masakari_delta_ids)))
    |

hamgr/hamgr/providers/nova.py:611:89: E501 Line too long (99 > 88)
    |
609 |                              str(az_name), str(masakari_delta_ids))
610 |                     # need to remove those additional hosts found in masakari
611 |                     if masakari.is_failover_segment_under_recovery(self._token, str(cluster_name)):
    |                                                                                         ^^^^^^^^^^^ E501
612 |                         LOG.info('will retry to remove hosts %s from masakari segment %s, '
613 |                                  'as the segment is under recovery',
    |

hamgr/hamgr/providers/nova.py:612:89: E501 Line too long (91 > 88)
    |
610 |                     # need to remove those additional hosts found in masakari
611 |                     if masakari.is_failover_segment_under_recovery(self._token, str(cluster_name)):
612 |                         LOG.info('will retry to remove hosts %s from masakari segment %s, '
    |                                                                                         ^^^ E501
613 |                                  'as the segment is under recovery',
614 |                                  str(masakari_delta_ids), str(cluster_name))
    |

hamgr/hamgr/providers/nova.py:616:89: E501 Line too long (97 > 88)
    |
614 |                                  str(masakari_delta_ids), str(cluster_name))
615 |                     else:
616 |                         LOG.info('remove additional hosts %s found in masakari from segment %s ',
    |                                                                                         ^^^^^^^^^ E501
617 |                                  str(masakari_delta_ids), str(cluster_name))
618 |                         masakari.delete_hosts_from_failover_segment(self._token,
    |

hamgr/hamgr/providers/nova.py:622:89: E501 Line too long (109 > 88)
    |
620 |                                                                     masakari_delta_ids)
621 |                         if cluster_enabled:
622 |                             LOG.info('remove ha slave role from removed hosts : %s', str(masakari_delta_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
623 |                             self._remove_ha_slave_if_exist(cluster_name, masakari_delta_ids, common_ids)
624 |                             LOG.info('try to rebalance consul roles after removed hosts : %s',
    |

hamgr/hamgr/providers/nova.py:623:89: E501 Line too long (104 > 88)
    |
621 |                         if cluster_enabled:
622 |                             LOG.info('remove ha slave role from removed hosts : %s', str(masakari_delta_ids))
623 |                             self._remove_ha_slave_if_exist(cluster_name, masakari_delta_ids, common_ids)
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
624 |                             LOG.info('try to rebalance consul roles after removed hosts : %s',
625 |                                      str(masakari_delta_ids))
    |

hamgr/hamgr/providers/nova.py:624:89: E501 Line too long (94 > 88)
    |
622 | …                     LOG.info('remove ha slave role from removed hosts : %s', str(masakari_delta_ids))
623 | …                     self._remove_ha_slave_if_exist(cluster_name, masakari_delta_ids, common_ids)
624 | …                     LOG.info('try to rebalance consul roles after removed hosts : %s',
    |                                                                                   ^^^^^^ E501
625 | …                              str(masakari_delta_ids))
626 | …                     #time.sleep(30)
    |

hamgr/hamgr/providers/nova.py:627:89: E501 Line too long (111 > 88)
    |
625 |                                      str(masakari_delta_ids))
626 |                             #time.sleep(30)
627 |                             #self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_REMOVED)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
628 |
629 |                 masakari_hosts = []
    |

hamgr/hamgr/providers/nova.py:633:89: E501 Line too long (93 > 88)
    |
631 |                 # add hosts found in availability zone but not in masakari segment
632 |                 if masakari.is_failover_segment_exist(self._token, cluster_name):
633 |                     masakari_hosts = masakari.get_nodes_in_segment(self._token, cluster_name)
    |                                                                                         ^^^^^ E501
634 |                 masakari_hids = [x['name'] for x in masakari_hosts]
635 |                 common_ids = set(az_hosts).intersection(set(masakari_hids))
    |

hamgr/hamgr/providers/nova.py:638:89: E501 Line too long (117 > 88)
    |
636 |                 nova_delta_ids = set(az_hosts) - set(common_ids)
637 |                 if len(nova_delta_ids) > 0:
638 |                     #Check if the host is already a part of Masakari Database before adding it to avoid any conflicts
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
639 |                     db_api.connect_masakari(masakari,self._mdb_uri)
640 |                     result = db_api.get_hosts_by_name(nova_delta_ids)
    |

hamgr/hamgr/providers/nova.py:642:89: E501 Line too long (114 > 88)
    |
640 |                     result = db_api.get_hosts_by_name(nova_delta_ids)
641 |
642 |                     LOG.info('found new hosts added into availability zone %s : %s', az_name, str(nova_delta_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
643 |                     # need to add those additional hosts into masakari
644 |                     if masakari.is_failover_segment_under_recovery(self._token, cluster_name):
    |

hamgr/hamgr/providers/nova.py:644:89: E501 Line too long (94 > 88)
    |
642 |                     LOG.info('found new hosts added into availability zone %s : %s', az_name, str(nova_delta_ids))
643 |                     # need to add those additional hosts into masakari
644 |                     if masakari.is_failover_segment_under_recovery(self._token, cluster_name):
    |                                                                                         ^^^^^^ E501
645 |                         LOG.info('will retry to add hosts %s to masakari segment %s, '
646 |                                  'as the segment is under recovery',
    |

hamgr/hamgr/providers/nova.py:648:36: E711 Comparison to `None` should be `cond is not None`
    |
646 |                                  'as the segment is under recovery',
647 |                                  str(nova_delta_ids), cluster_name)
648 |                     elif result != None:
    |                                    ^^^^ E711
649 |                         # host is already a part of other segment so not adding to avoid conflicts
650 |                         LOG.info('Not adding hosts as its already a part of masakari segment %s ', result)
    |
    = help: Replace with `cond is not None`

hamgr/hamgr/providers/nova.py:649:89: E501 Line too long (98 > 88)
    |
647 |                                  str(nova_delta_ids), cluster_name)
648 |                     elif result != None:
649 |                         # host is already a part of other segment so not adding to avoid conflicts
    |                                                                                         ^^^^^^^^^^ E501
650 |                         LOG.info('Not adding hosts as its already a part of masakari segment %s ', result)
651 |                     else:
    |

hamgr/hamgr/providers/nova.py:650:89: E501 Line too long (106 > 88)
    |
648 |                     elif result != None:
649 |                         # host is already a part of other segment so not adding to avoid conflicts
650 |                         LOG.info('Not adding hosts as its already a part of masakari segment %s ', result)
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
651 |                     else:
652 |                         # hosts already in availability zone so only need to add to masakari
    |

hamgr/hamgr/providers/nova.py:652:89: E501 Line too long (92 > 88)
    |
650 |                         LOG.info('Not adding hosts as its already a part of masakari segment %s ', result)
651 |                     else:
652 |                         # hosts already in availability zone so only need to add to masakari
    |                                                                                         ^^^^ E501
653 |                         LOG.info('add new hosts %s found in availability zone %s to masakari segment %s',
654 |                                  str(nova_delta_ids), az_name, cluster_name)
    |

hamgr/hamgr/providers/nova.py:653:89: E501 Line too long (105 > 88)
    |
651 |                     else:
652 |                         # hosts already in availability zone so only need to add to masakari
653 |                         LOG.info('add new hosts %s found in availability zone %s to masakari segment %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
654 |                                  str(nova_delta_ids), az_name, cluster_name)
655 |                         masakari.add_hosts_to_failover_segment(self._token,
    |

hamgr/hamgr/providers/nova.py:659:89: E501 Line too long (92 > 88)
    |
657 |                                                                nova_delta_ids)
658 |                         # if cluster_enabled:
659 |                         #     # pick consul role for new host based on other cluster members
    |                                                                                         ^^^^ E501
660 |                         #     consul_role = constants.CONSUL_ROLE_SERVER
661 |                         #     c_report = self._get_latest_consul_status(cluster_name)
    |

hamgr/hamgr/providers/nova.py:664:89: E501 Line too long (99 > 88)
    |
662 |                         #     if c_report and c_report.get('members', []):
663 |                         #         members = c_report.get('members')
664 |                         #         c_servers = [x for x in members if x['Tags']['role'] == 'consul']
    |                                                                                         ^^^^^^^^^^^ E501
665 |                         #         c_servers_alive = [x for x in c_servers if x['Status'] == 1]
666 |                         #         if len(c_servers_alive) >= constants.SERVER_THRESHOLD:
    |

hamgr/hamgr/providers/nova.py:665:89: E501 Line too long (94 > 88)
    |
663 |                         #         members = c_report.get('members')
664 |                         #         c_servers = [x for x in members if x['Tags']['role'] == 'consul']
665 |                         #         c_servers_alive = [x for x in c_servers if x['Status'] == 1]
    |                                                                                         ^^^^^^ E501
666 |                         #         if len(c_servers_alive) >= constants.SERVER_THRESHOLD:
667 |                         #             consul_role = constants.CONSUL_ROLE_CLIENT
    |

hamgr/hamgr/providers/nova.py:668:89: E501 Line too long (117 > 88)
    |
666 |                         #         if len(c_servers_alive) >= constants.SERVER_THRESHOLD:
667 |                         #             consul_role = constants.CONSUL_ROLE_CLIENT
668 |                         #     LOG.info('add ha slave role (%s) to added hosts: %s', consul_role, str(nova_delta_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
669 |                         #     self._add_ha_slave_if_not_exist(cluster_name, nova_delta_ids, consul_role, common_ids)
670 |                         #     # trigger a consul role rebalance request
    |

hamgr/hamgr/providers/nova.py:669:89: E501 Line too long (116 > 88)
    |
667 |                         #             consul_role = constants.CONSUL_ROLE_CLIENT
668 |                         #     LOG.info('add ha slave role (%s) to added hosts: %s', consul_role, str(nova_delta_ids))
669 |                         #     self._add_ha_slave_if_not_exist(cluster_name, nova_delta_ids, consul_role, common_ids)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
670 |                         #     # trigger a consul role rebalance request
671 |                         #     time.sleep(30)
    |

hamgr/hamgr/providers/nova.py:672:89: E501 Line too long (110 > 88)
    |
670 |                         #     # trigger a consul role rebalance request
671 |                         #     time.sleep(30)
672 |                         #     self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_ADDED)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
673 |                 # when cluster is enabled, make sure pf9-ha-slave role is on all active hosts
674 |                 # ----------------------------------------------------------
    |

hamgr/hamgr/providers/nova.py:673:89: E501 Line too long (93 > 88)
    |
671 |                         #     time.sleep(30)
672 |                         #     self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_ADDED)
673 |                 # when cluster is enabled, make sure pf9-ha-slave role is on all active hosts
    |                                                                                         ^^^^^ E501
674 |                 # ----------------------------------------------------------
675 |                 # then reconcile masakari hosts and pf9-ha-slave on those
    |

hamgr/hamgr/providers/nova.py:681:89: E501 Line too long (105 > 88)
    |
679 |                 # ----------------------------------------------------------
680 |                 if (not cluster_enabled) and \
681 |                         (cluster_status in [constants.HA_STATE_DISABLED, constants.HA_STATE_ERROR]) and \
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
682 |                         (cluster_task_state in [constants.TASK_COMPLETED, constants.TASK_ERROR_REMOVING]):
683 |                     # if availability zone exist but vmha cluster is disabled, try to remove pf9-ha-slave
    |

hamgr/hamgr/providers/nova.py:682:89: E501 Line too long (106 > 88)
    |
680 |                 if (not cluster_enabled) and \
681 |                         (cluster_status in [constants.HA_STATE_DISABLED, constants.HA_STATE_ERROR]) and \
682 |                         (cluster_task_state in [constants.TASK_COMPLETED, constants.TASK_ERROR_REMOVING]):
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
683 |                     # if availability zone exist but vmha cluster is disabled, try to remove pf9-ha-slave
684 |                     # in case previous action(disable vmha, or hostagent failed) failed to remove the pf9-ha-slave
    |

hamgr/hamgr/providers/nova.py:683:89: E501 Line too long (105 > 88)
    |
681 |                         (cluster_status in [constants.HA_STATE_DISABLED, constants.HA_STATE_ERROR]) and \
682 |                         (cluster_task_state in [constants.TASK_COMPLETED, constants.TASK_ERROR_REMOVING]):
683 |                     # if availability zone exist but vmha cluster is disabled, try to remove pf9-ha-slave
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
684 |                     # in case previous action(disable vmha, or hostagent failed) failed to remove the pf9-ha-slave
685 |                     # this will make sure pf9-ha-slave not left on hosts when vmha disabled for a availability zone
    |

hamgr/hamgr/providers/nova.py:684:89: E501 Line too long (114 > 88)
    |
682 |                         (cluster_task_state in [constants.TASK_COMPLETED, constants.TASK_ERROR_REMOVING]):
683 |                     # if availability zone exist but vmha cluster is disabled, try to remove pf9-ha-slave
684 |                     # in case previous action(disable vmha, or hostagent failed) failed to remove the pf9-ha-slave
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
685 |                     # this will make sure pf9-ha-slave not left on hosts when vmha disabled for a availability zone
686 |                     try:
    |

hamgr/hamgr/providers/nova.py:685:89: E501 Line too long (115 > 88)
    |
683 |                     # if availability zone exist but vmha cluster is disabled, try to remove pf9-ha-slave
684 |                     # in case previous action(disable vmha, or hostagent failed) failed to remove the pf9-ha-slave
685 |                     # this will make sure pf9-ha-slave not left on hosts when vmha disabled for a availability zone
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
686 |                     try:
687 |                         LOG.info('cluster (name %s, status %s, task state %s) is not enabled, '
    |

hamgr/hamgr/providers/nova.py:687:89: E501 Line too long (95 > 88)
    |
685 |                     # this will make sure pf9-ha-slave not left on hosts when vmha disabled for a availability zone
686 |                     try:
687 |                         LOG.info('cluster (name %s, status %s, task state %s) is not enabled, '
    |                                                                                         ^^^^^^^ E501
688 |                                  'trying to remove pf9-ha-slave role from hosts',
689 |                                  str(cluster_name), str(cluster_status), str(cluster_task_state))
    |

hamgr/hamgr/providers/nova.py:689:89: E501 Line too long (97 > 88)
    |
687 |                         LOG.info('cluster (name %s, status %s, task state %s) is not enabled, '
688 |                                  'trying to remove pf9-ha-slave role from hosts',
689 |                                  str(cluster_name), str(cluster_status), str(cluster_task_state))
    |                                                                                         ^^^^^^^^^ E501
690 |                         self._deauth(az_hosts)
691 |                     except Exception:
    |

hamgr/hamgr/providers/nova.py:692:89: E501 Line too long (95 > 88)
    |
690 |                         self._deauth(az_hosts)
691 |                     except Exception:
692 |                         LOG.warning('remove pf9-ha-slave on hosts %s failed, will retry later',
    |                                                                                         ^^^^^^^ E501
693 |                                     str(az_hosts))
694 |                     continue
    |

hamgr/hamgr/providers/nova.py:696:89: E501 Line too long (89 > 88)
    |
694 |                     continue
695 |
696 |                 LOG.debug('cluster %s is enabled, now checking slave role', cluster_name)
    |                                                                                         ^ E501
697 |                 availability_zone = az_name
698 |                 segment_name = str(cluster_name)
    |

hamgr/hamgr/providers/nova.py:735:89: E501 Line too long (96 > 88)
    |
733 |                     removed_host_ids = masakari_host_ids - availability_zone_host_ids
734 |
735 |                     LOG.info('Found existing active hosts : %s ', str(existing_active_host_ids))
    |                                                                                         ^^^^^^^^ E501
736 |                     LOG.info('Found existing inactive hosts : %s ', str(existing_inactive_host_ids))
737 |                     LOG.info('Found new active hosts : %s ', str(new_active_host_ids))
    |

hamgr/hamgr/providers/nova.py:736:89: E501 Line too long (100 > 88)
    |
735 |                     LOG.info('Found existing active hosts : %s ', str(existing_active_host_ids))
736 |                     LOG.info('Found existing inactive hosts : %s ', str(existing_inactive_host_ids))
    |                                                                                         ^^^^^^^^^^^^ E501
737 |                     LOG.info('Found new active hosts : %s ', str(new_active_host_ids))
738 |                     LOG.info('Found new inactive hosts : %s ', str(new_inactive_host_ids))
    |

hamgr/hamgr/providers/nova.py:738:89: E501 Line too long (90 > 88)
    |
736 |                     LOG.info('Found existing inactive hosts : %s ', str(existing_inactive_host_ids))
737 |                     LOG.info('Found new active hosts : %s ', str(new_active_host_ids))
738 |                     LOG.info('Found new inactive hosts : %s ', str(new_inactive_host_ids))
    |                                                                                         ^^ E501
739 |                     LOG.info('Found removed hosts : %s ', str(removed_host_ids))
740 |                     LOG.info('Found nova active hosts : %s ', str(nova_active_host_ids))
    |

hamgr/hamgr/providers/nova.py:742:89: E501 Line too long (101 > 88)
    |
740 |                     LOG.info('Found nova active hosts : %s ', str(nova_active_host_ids))
741 |
742 |                     # do this first than other steps because this is more important, if the maintance
    |                                                                                         ^^^^^^^^^^^^^ E501
743 |                     # state is not reseted after host become active, it will block sending notification
744 |                     # to masakari if the same host become offline again
    |

hamgr/hamgr/providers/nova.py:743:89: E501 Line too long (103 > 88)
    |
742 |                     # do this first than other steps because this is more important, if the maintance
743 |                     # state is not reseted after host become active, it will block sending notification
    |                                                                                         ^^^^^^^^^^^^^^^ E501
744 |                     # to masakari if the same host become offline again
745 |                     # resume on maintenance hosts, and enforce pf9-ha-slave role on active hosts
    |

hamgr/hamgr/providers/nova.py:745:89: E501 Line too long (96 > 88)
    |
743 |                     # state is not reseted after host become active, it will block sending notification
744 |                     # to masakari if the same host become offline again
745 |                     # resume on maintenance hosts, and enforce pf9-ha-slave role on active hosts
    |                                                                                         ^^^^^^^^ E501
746 |                     LOG.debug('try to reset hosts maintenance state in masakari for active hosts in nova %s',
747 |                               str(nova_active_host_ids))
    |

hamgr/hamgr/providers/nova.py:746:89: E501 Line too long (109 > 88)
    |
744 |                     # to masakari if the same host become offline again
745 |                     # resume on maintenance hosts, and enforce pf9-ha-slave role on active hosts
746 |                     LOG.debug('try to reset hosts maintenance state in masakari for active hosts in nova %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
747 |                               str(nova_active_host_ids))
748 |                     self._toggle_masakari_hosts_maintenance_status(segment_name=segment_name,
    |

hamgr/hamgr/providers/nova.py:755:89: E501 Line too long (102 > 88)
    |
753 |                         continue
754 |
755 |                     found_hosts_added = len(new_active_host_ids) > 0 or len(new_inactive_host_ids) > 0
    |                                                                                         ^^^^^^^^^^^^^^ E501
756 |                     found_hosts_removed = len(removed_host_ids) > 0
757 |                     found_hosts_changes = found_hosts_added or found_hosts_removed
    |

hamgr/hamgr/providers/nova.py:759:89: E501 Line too long (113 > 88)
    |
757 |                     found_hosts_changes = found_hosts_added or found_hosts_removed
758 |                     if not found_hosts_changes:
759 |                         LOG.info('no hosts added or removed, now make sure pf9-ha-slave is assigned on hosts %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
760 |                                  str(nova_active_host_ids))
761 |                         # make sure ha-slave is enabled on existing active hosts
    |

hamgr/hamgr/providers/nova.py:762:89: E501 Line too long (117 > 88)
    |
760 | …              str(nova_active_host_ids))
761 | …     # make sure ha-slave is enabled on existing active hosts
762 | …     hosts_info = self._resmgr_client.fetch_hosts_details(nova_active_host_ids, self._token['id'])
    |                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
763 | …     current_roles= dict(zip(hosts_info.keys(), [hosts_info.get(x,{}).get('roles', []) for x in hosts_info.keys()]))
    |

hamgr/hamgr/providers/nova.py:763:89: E501 Line too long (135 > 88)
    |
761 | …enabled on existing active hosts
762 | …r_client.fetch_hosts_details(nova_active_host_ids, self._token['id'])
763 | …hosts_info.keys(), [hosts_info.get(x,{}).get('roles', []) for x in hosts_info.keys()]))
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
764 | …
765 | …et()
    |

hamgr/hamgr/providers/nova.py:768:89: E501 Line too long (104 > 88)
    |
766 |                         ip_mismatch_host_ids = set()
767 |                         self._token = self._get_v3_token()
768 |                         join_ips, cluster_ip_lookup, cluster_details = self._get_join_info(cluster_name)
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
769 |                         LOG.info('expected cluster join_ips: %s', join_ips)
    |

hamgr/hamgr/providers/nova.py:773:89: E501 Line too long (93 > 88)
    |
771 |                         for hid in nova_active_host_ids:
772 |                             h_roles = current_roles[hid]
773 |                             LOG.debug("host %s  has roles : %s", str(hid), ','.join(h_roles))
    |                                                                                         ^^^^^ E501
774 |                             if "pf9-ha-slave" not in h_roles:
775 |                                 role_missed_host_ids.add(hid)
    |

hamgr/hamgr/providers/nova.py:777:89: E501 Line too long (105 > 88)
    |
775 | …                         role_missed_host_ids.add(hid)
776 | …                     else:
777 | …                         rs = hosts_info.get(hid).get('role_settings', {}).get("pf9-ha-slave", {})
    |                                                                                   ^^^^^^^^^^^^^^^^^ E501
778 | …                         if 'join' not in rs or rs['join'] != join_ips:
779 | …                             ip_mismatch_host_ids.add(hid)
    |

hamgr/hamgr/providers/nova.py:783:89: E501 Line too long (113 > 88)
    |
781 |                         if len(role_missed_host_ids) > 0:
782 |                             txt_ids = ','.join(list(role_missed_host_ids))
783 |                             LOG.info("assign ha-slave role for hosts which is missing pf9-ha-slave: %s", txt_ids)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
784 |                             # hosts are not changed but just missing pf9-ha-slave, it is ok to just re-assign roles
785 |                             # TODO: only assign to hosts in role_missed_host_ids??
    |

hamgr/hamgr/providers/nova.py:784:89: E501 Line too long (115 > 88)
    |
782 | …                     txt_ids = ','.join(list(role_missed_host_ids))
783 | …                     LOG.info("assign ha-slave role for hosts which is missing pf9-ha-slave: %s", txt_ids)
784 | …                     # hosts are not changed but just missing pf9-ha-slave, it is ok to just re-assign roles
    |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
785 | …                     # TODO: only assign to hosts in role_missed_host_ids??
786 | …                     #self._assign_roles(nova_client, availability_zone, nova_active_host_ids)
    |

hamgr/hamgr/providers/nova.py:786:89: E501 Line too long (101 > 88)
    |
784 | …                     # hosts are not changed but just missing pf9-ha-slave, it is ok to just re-assign roles
785 | …                     # TODO: only assign to hosts in role_missed_host_ids??
786 | …                     #self._assign_roles(nova_client, availability_zone, nova_active_host_ids)
    |                                                                                   ^^^^^^^^^^^^^ E501
787 | …                     self._add_ha_slave_if_not_exist(cluster_name, role_missed_host_ids, 'server',
788 | …                                                     masakari_host_ids)
    |

hamgr/hamgr/providers/nova.py:787:89: E501 Line too long (105 > 88)
    |
785 | …                     # TODO: only assign to hosts in role_missed_host_ids??
786 | …                     #self._assign_roles(nova_client, availability_zone, nova_active_host_ids)
787 | …                     self._add_ha_slave_if_not_exist(cluster_name, role_missed_host_ids, 'server',
    |                                                                                   ^^^^^^^^^^^^^^^^^ E501
788 | …                                                     masakari_host_ids)
789 | …                     LOG.debug("ha-slave roles are assigned to : %s", txt_ids)
    |

hamgr/hamgr/providers/nova.py:791:89: E501 Line too long (92 > 88)
    |
789 |                             LOG.debug("ha-slave roles are assigned to : %s", txt_ids)
790 |                         elif len(ip_mismatch_host_ids) > 0:
791 |                             LOG.info('updating join ips for availability_zone %s, hosts %s',
    |                                                                                         ^^^^ E501
792 |                                      str(availability_zone), ip_mismatch_host_ids)
793 |                             #self._auth(availability_zone, cluster_ip_lookup, cluster_ip_lookup, cluster_details,
    |

hamgr/hamgr/providers/nova.py:793:89: E501 Line too long (113 > 88)
    |
791 |                             LOG.info('updating join ips for availability_zone %s, hosts %s',
792 |                                      str(availability_zone), ip_mismatch_host_ids)
793 |                             #self._auth(availability_zone, cluster_ip_lookup, cluster_ip_lookup, cluster_details,
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
794 |                             #           self._token, ip_mismatch_host_ids)
795 |                         else:
    |

hamgr/hamgr/providers/nova.py:800:89: E501 Line too long (114 > 88)
    |
798 |                     if len(new_active_host_ids) > 0:
799 |                         # need to put pf-ha-slave role on them
800 |                         LOG.info('new active hosts are added into availability_zone %s but not in masakari : %s ',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
801 |                                  str(availability_zone),
802 |                                  str(new_active_host_ids))
    |

hamgr/hamgr/providers/nova.py:803:89: E501 Line too long (100 > 88)
    |
801 |                                  str(availability_zone),
802 |                                  str(new_active_host_ids))
803 |                         # same here, since we don't know the consul roles on existing hosts, so just
    |                                                                                         ^^^^^^^^^^^^ E501
804 |                         # make these hosts as consul server, and trigger a role rebalance request
805 |                         self._add_ha_slave_if_not_exist(cluster_name, new_active_host_ids, 'server',
    |

hamgr/hamgr/providers/nova.py:804:89: E501 Line too long (97 > 88)
    |
802 |                                  str(new_active_host_ids))
803 |                         # same here, since we don't know the consul roles on existing hosts, so just
804 |                         # make these hosts as consul server, and trigger a role rebalance request
    |                                                                                         ^^^^^^^^^ E501
805 |                         self._add_ha_slave_if_not_exist(cluster_name, new_active_host_ids, 'server',
806 |                                                         masakari_host_ids)
    |

hamgr/hamgr/providers/nova.py:805:89: E501 Line too long (100 > 88)
    |
803 |                         # same here, since we don't know the consul roles on existing hosts, so just
804 |                         # make these hosts as consul server, and trigger a role rebalance request
805 |                         self._add_ha_slave_if_not_exist(cluster_name, new_active_host_ids, 'server',
    |                                                                                         ^^^^^^^^^^^^ E501
806 |                                                         masakari_host_ids)
807 |                         # trigger consul role rebalance request
    |

hamgr/hamgr/providers/nova.py:809:89: E501 Line too long (105 > 88)
    |
807 |                         # trigger consul role rebalance request
808 |                         #time.sleep(30)
809 |                         #self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_ADDED)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
810 |
811 |                     if len(new_inactive_host_ids) > 0:
    |

hamgr/hamgr/providers/nova.py:812:89: E501 Line too long (98 > 88)
    |
811 |                     if len(new_inactive_host_ids) > 0:
812 |                         # need to wait for them become active so can put pf9-ha-slave role on them
    |                                                                                         ^^^^^^^^^^ E501
813 |                         LOG.info('new inactive hosts are added into availability_zone %s but '
814 |                                  'not in masakari : %s, wait for hosts to become active',
    |

hamgr/hamgr/providers/nova.py:813:89: E501 Line too long (94 > 88)
    |
811 |                     if len(new_inactive_host_ids) > 0:
812 |                         # need to wait for them become active so can put pf9-ha-slave role on them
813 |                         LOG.info('new inactive hosts are added into availability_zone %s but '
    |                                                                                         ^^^^^^ E501
814 |                                  'not in masakari : %s, wait for hosts to become active',
815 |                                  segment_name,
    |

hamgr/hamgr/providers/nova.py:814:89: E501 Line too long (89 > 88)
    |
812 |                         # need to wait for them become active so can put pf9-ha-slave role on them
813 |                         LOG.info('new inactive hosts are added into availability_zone %s but '
814 |                                  'not in masakari : %s, wait for hosts to become active',
    |                                                                                         ^ E501
815 |                                  segment_name,
816 |                                  str(new_inactive_host_ids))
    |

hamgr/hamgr/providers/nova.py:819:89: E501 Line too long (119 > 88)
    |
818 |                     if len(removed_host_ids) > 0:
819 |                         LOG.info('hosts are removed from nova availability_zone %s : %s, now remove pf9-ha-slave role',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
820 |                                  availability_zone, str(removed_host_ids))
821 |                         self._remove_ha_slave_if_exist(cluster_name, removed_host_ids,
    |

hamgr/hamgr/providers/nova.py:822:89: E501 Line too long (100 > 88)
    |
820 |                                  availability_zone, str(removed_host_ids))
821 |                         self._remove_ha_slave_if_exist(cluster_name, removed_host_ids,
822 |                             list( set(existing_active_host_ids).difference(set(removed_host_ids)) ))
    |                                                                                         ^^^^^^^^^^^^ E501
823 |                         LOG.info('try to rebalance consul roles after removing hosts: %s', str(removed_host_ids))
824 |                         #time.sleep(30)
    |

hamgr/hamgr/providers/nova.py:823:89: E501 Line too long (113 > 88)
    |
821 |                         self._remove_ha_slave_if_exist(cluster_name, removed_host_ids,
822 |                             list( set(existing_active_host_ids).difference(set(removed_host_ids)) ))
823 |                         LOG.info('try to rebalance consul roles after removing hosts: %s', str(removed_host_ids))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
824 |                         #time.sleep(30)
825 |                         #self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_REMOVED)
    |

hamgr/hamgr/providers/nova.py:825:89: E501 Line too long (107 > 88)
    |
823 |                         LOG.info('try to rebalance consul roles after removing hosts: %s', str(removed_host_ids))
824 |                         #time.sleep(30)
825 |                         #self._rebalance_consul_roles_if_needed(cluster_name, constants.EVENT_HOST_REMOVED)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
826 |
827 |                     if len(existing_inactive_host_ids) > 0:
    |

hamgr/hamgr/providers/nova.py:828:89: E501 Line too long (113 > 88)
    |
827 |                     if len(existing_inactive_host_ids) > 0:
828 |                         LOG.warning('existing inactive hosts in segment %s: %s, wait for hosts to become active',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
829 |                                     segment_name, str(existing_inactive_host_ids))
    |

hamgr/hamgr/providers/nova.py:834:89: E501 Line too long (115 > 88)
    |
832 |                     pass
833 |                 except ha_exceptions.InsufficientHosts:
834 |                     LOG.warning('Detected number of availability_zone %s hosts is insufficient', availability_zone)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
835 |                 except ha_exceptions.SegmentNotFound:
836 |                     LOG.warning('Masakari segment for cluster: %s was not found', current_cluster.name)
    |

hamgr/hamgr/providers/nova.py:836:89: E501 Line too long (103 > 88)
    |
834 |                     LOG.warning('Detected number of availability_zone %s hosts is insufficient', availability_zone)
835 |                 except ha_exceptions.SegmentNotFound:
836 |                     LOG.warning('Masakari segment for cluster: %s was not found', current_cluster.name)
    |                                                                                         ^^^^^^^^^^^^^^^ E501
837 |                 except ha_exceptions.HostPartOfCluster:
838 |                     LOG.error("Not enabling cluster as cluster hosts are part of another cluster")
    |

hamgr/hamgr/providers/nova.py:838:89: E501 Line too long (98 > 88)
    |
836 |                     LOG.warning('Masakari segment for cluster: %s was not found', current_cluster.name)
837 |                 except ha_exceptions.HostPartOfCluster:
838 |                     LOG.error("Not enabling cluster as cluster hosts are part of another cluster")
    |                                                                                         ^^^^^^^^^^ E501
839 |                 except Exception:
840 |                     LOG.exception('Exception while processing availability_zone %s', availability_zone)
    |

hamgr/hamgr/providers/nova.py:840:89: E501 Line too long (103 > 88)
    |
838 |                     LOG.error("Not enabling cluster as cluster hosts are part of another cluster")
839 |                 except Exception:
840 |                     LOG.exception('Exception while processing availability_zone %s', availability_zone)
    |                                                                                         ^^^^^^^^^^^^^^^ E501
841 |         except Exception as e:
842 |             LOG.exception('unhandled exception in host availability_zone change processing task : %s', str(e))
    |

hamgr/hamgr/providers/nova.py:842:89: E501 Line too long (110 > 88)
    |
840 |                     LOG.exception('Exception while processing availability_zone %s', availability_zone)
841 |         except Exception as e:
842 |             LOG.exception('unhandled exception in host availability_zone change processing task : %s', str(e))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
843 |         finally:
844 |             with self.availability_zone_task_lock:
    |

hamgr/hamgr/providers/nova.py:847:89: E501 Line too long (109 > 88)
    |
845 |                 LOG.debug('Availability Zone changes task completed')
846 |                 self.availability_zone_task_running = False
847 |         LOG.debug('host availability zone change processing task has finished at %s', str(datetime.utcnow()))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
848 |
849 |     def _toggle_masakari_hosts_maintenance_status(self, segment_name="", host_ids=[], ignore_status_in_nova=False, on_maintenance=Fal…
    |

hamgr/hamgr/providers/nova.py:849:89: E501 Line too long (137 > 88)
    |
847 | …processing task has finished at %s', str(datetime.utcnow()))
848 | …
849 | …(self, segment_name="", host_ids=[], ignore_status_in_nova=False, on_maintenance=False):
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
850 | …
851 | …
    |

hamgr/hamgr/providers/nova.py:857:89: E501 Line too long (90 > 88)
    |
855 |             segment_hosts_pairs = []
856 |             if segment_name:
857 |                 if not masakari.is_failover_segment_exist(self._token, str(segment_name)):
    |                                                                                         ^^ E501
858 |                     LOG.warning('vmha cluster with name %s does not exist, will not toggle hosts maintenance status',
859 |                                 str(segment_name))
    |

hamgr/hamgr/providers/nova.py:858:89: E501 Line too long (117 > 88)
    |
856 |             if segment_name:
857 |                 if not masakari.is_failover_segment_exist(self._token, str(segment_name)):
858 |                     LOG.warning('vmha cluster with name %s does not exist, will not toggle hosts maintenance status',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
859 |                                 str(segment_name))
860 |                     return
    |

hamgr/hamgr/providers/nova.py:862:89: E501 Line too long (94 > 88)
    |
860 |                     return
861 |
862 |                 masakari_hosts = masakari.get_nodes_in_segment(self._token, str(segment_name))
    |                                                                                         ^^^^^^ E501
863 |                 # always use the hosts found for the given segment, in case the hosts passed in
864 |                 # not belong to the given segment
    |

hamgr/hamgr/providers/nova.py:863:89: E501 Line too long (95 > 88)
    |
862 |                 masakari_hosts = masakari.get_nodes_in_segment(self._token, str(segment_name))
863 |                 # always use the hosts found for the given segment, in case the hosts passed in
    |                                                                                         ^^^^^^^ E501
864 |                 # not belong to the given segment
865 |                 valid_hosts = [x['name'] for x in masakari_hosts]
    |

hamgr/hamgr/providers/nova.py:867:89: E501 Line too long (116 > 88)
    |
865 |                 valid_hosts = [x['name'] for x in masakari_hosts]
866 |
867 |                 # when pass in host ids, just use the intersection, because data from masakari is the trusted source
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
868 |                 if host_ids and len(host_ids) > 0 :
869 |                     common = list(set(valid_hosts).intersection(set(host_ids)))
    |

hamgr/hamgr/providers/nova.py:886:89: E501 Line too long (94 > 88)
    |
884 |                 for az in nova_active_azs:
885 |                     # make sure vmha group for this availability_zone actually exists
886 |                     matched_clusters = [x for x in hamgr_clusters if x.name == az['zoneName']]
    |                                                                                         ^^^^^^ E501
887 |                     if not matched_clusters:
888 |                         LOG.warning('vmha cluster for host availability_zone %s does not exist or disabled, '
    |

hamgr/hamgr/providers/nova.py:888:89: E501 Line too long (109 > 88)
    |
886 |                     matched_clusters = [x for x in hamgr_clusters if x.name == az['zoneName']]
887 |                     if not matched_clusters:
888 |                         LOG.warning('vmha cluster for host availability_zone %s does not exist or disabled, '
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
889 |                                     'will not toggle hosts maintenance status', az['zoneName'])
890 |                         continue
    |

hamgr/hamgr/providers/nova.py:889:89: E501 Line too long (95 > 88)
    |
887 |                     if not matched_clusters:
888 |                         LOG.warning('vmha cluster for host availability_zone %s does not exist or disabled, '
889 |                                     'will not toggle hosts maintenance status', az['zoneName'])
    |                                                                                         ^^^^^^^ E501
890 |                         continue
    |

hamgr/hamgr/providers/nova.py:893:89: E501 Line too long (91 > 88)
    |
892 |                     # make sure masakari failover segment exists
893 |                     if not masakari.is_failover_segment_exist(self._token, az['zoneName']):
    |                                                                                         ^^^ E501
894 |                         LOG.error('vmha cluster for host availability zone %s exists, but masakari segment does not exist, '
895 |                                   'will not toggle hosts maintenance status', az['zoneName'])
    |

hamgr/hamgr/providers/nova.py:894:89: E501 Line too long (124 > 88)
    |
892 |                     # make sure masakari failover segment exists
893 |                     if not masakari.is_failover_segment_exist(self._token, az['zoneName']):
894 |                         LOG.error('vmha cluster for host availability zone %s exists, but masakari segment does not exist, '
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
895 |                                   'will not toggle hosts maintenance status', az['zoneName'])
896 |                         continue
    |

hamgr/hamgr/providers/nova.py:895:89: E501 Line too long (93 > 88)
    |
893 |                     if not masakari.is_failover_segment_exist(self._token, az['zoneName']):
894 |                         LOG.error('vmha cluster for host availability zone %s exists, but masakari segment does not exist, '
895 |                                   'will not toggle hosts maintenance status', az['zoneName'])
    |                                                                                         ^^^^^ E501
896 |                         continue
    |

hamgr/hamgr/providers/nova.py:898:89: E501 Line too long (95 > 88)
    |
896 |                         continue
897 |
898 |                     masakari_hosts = masakari.get_nodes_in_segment(self._token, az['zoneName'])
    |                                                                                         ^^^^^^^ E501
899 |                     valid_hosts = [x['name'] for x in masakari_hosts]
    |

hamgr/hamgr/providers/nova.py:901:89: E501 Line too long (115 > 88)
    |
899 |                     valid_hosts = [x['name'] for x in masakari_hosts]
900 |
901 |                     # if not pass in availability_zone id but just host ids, then use those host id to figure which
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
902 |                     # availability_zone they belong to, or just ignore host ids and check for every availability_zones
903 |                     if host_ids and len(host_ids) > 0 :
    |

hamgr/hamgr/providers/nova.py:902:89: E501 Line too long (118 > 88)
    |
901 |                     # if not pass in availability_zone id but just host ids, then use those host id to figure which
902 |                     # availability_zone they belong to, or just ignore host ids and check for every availability_zones
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
903 |                     if host_ids and len(host_ids) > 0 :
904 |                         common = list(set(valid_hosts).intersection(set(host_ids)))
    |

hamgr/hamgr/providers/nova.py:910:45: F821 Undefined name `agg`
    |
908 |                     # otherwise will check all hosts
909 |                     segment_hosts_pairs.append({
910 |                         'segment_name': str(agg.id),
    |                                             ^^^ F821
911 |                         'host_ids': valid_hosts
912 |                     })
    |

hamgr/hamgr/providers/nova.py:918:89: E501 Line too long (90 > 88)
    |
916 |                 segment_name = entry['segment_name']
917 |
918 |                 # don't reset host maintenance state if there is vm migration task running
    |                                                                                         ^^ E501
919 |                 if masakari.is_failover_segment_under_recovery(self._token, segment_name):
920 |                     LOG.info('segment %s is under recovery, will not toggle hosts maintenance status.',
    |

hamgr/hamgr/providers/nova.py:919:89: E501 Line too long (90 > 88)
    |
918 |                 # don't reset host maintenance state if there is vm migration task running
919 |                 if masakari.is_failover_segment_under_recovery(self._token, segment_name):
    |                                                                                         ^^ E501
920 |                     LOG.info('segment %s is under recovery, will not toggle hosts maintenance status.',
921 |                              segment_name)
    |

hamgr/hamgr/providers/nova.py:920:89: E501 Line too long (103 > 88)
    |
918 |                 # don't reset host maintenance state if there is vm migration task running
919 |                 if masakari.is_failover_segment_under_recovery(self._token, segment_name):
920 |                     LOG.info('segment %s is under recovery, will not toggle hosts maintenance status.',
    |                                                                                         ^^^^^^^^^^^^^^^ E501
921 |                              segment_name)
922 |                     continue
    |

hamgr/hamgr/providers/nova.py:929:89: E501 Line too long (100 > 88)
    |
927 |                     host_up_in_nova = self._is_nova_service_active(hostid, nova_client)
928 |
929 |                     # if request to ignore status in nova, then set maintenance to whatever required
    |                                                                                         ^^^^^^^^^^^^ E501
930 |                     # but if not to ignore status in nova, then can only reset maintenance when host is up in nova
931 |                     if not ignore_status_in_nova:
    |

hamgr/hamgr/providers/nova.py:930:89: E501 Line too long (114 > 88)
    |
929 |                     # if request to ignore status in nova, then set maintenance to whatever required
930 |                     # but if not to ignore status in nova, then can only reset maintenance when host is up in nova
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
931 |                     if not ignore_status_in_nova:
932 |                         if not host_up_in_nova and not on_maintenance:
    |

hamgr/hamgr/providers/nova.py:933:89: E501 Line too long (114 > 88)
    |
931 |                     if not ignore_status_in_nova:
932 |                         if not host_up_in_nova and not on_maintenance:
933 |                             LOG.debug('require to not ignore status in nova and toggle maintenance status to %s, '
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
934 |                                       'but host %s in segment %s is not up in nova. '
935 |                                       'will not toggle hosts maintenance status.',
    |

hamgr/hamgr/providers/nova.py:936:89: E501 Line too long (90 > 88)
    |
934 | …                               'but host %s in segment %s is not up in nova. '
935 | …                               'will not toggle hosts maintenance status.',
936 | …                               str(on_maintenance), str(hostid), str(segment_name))
    |                                                                                   ^^ E501
937 | …                     continue
    |

hamgr/hamgr/providers/nova.py:939:89: E501 Line too long (94 > 88)
    |
937 |                             continue
938 |
939 |                     if not masakari.is_host_on_maintenance(self._token, hostid, segment_name):
    |                                                                                         ^^^^^^ E501
940 |                         continue
    |

hamgr/hamgr/providers/nova.py:942:89: E501 Line too long (114 > 88)
    |
940 |                         continue
941 |
942 |                     LOG.info('toggle maintenance status to %s for host %s in segment %s, with status in nova %s)',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
943 |                               str(on_maintenance), str(hostid), str(segment_name), str(host_up_in_nova))
944 |                     try:
    |

hamgr/hamgr/providers/nova.py:943:89: E501 Line too long (104 > 88)
    |
942 |                     LOG.info('toggle maintenance status to %s for host %s in segment %s, with status in nova %s)',
943 |                               str(on_maintenance), str(hostid), str(segment_name), str(host_up_in_nova))
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
944 |                     try:
945 |                         masakari.update_host_maintenance(self._token, hostid, segment_name, on_maintenance)
    |

hamgr/hamgr/providers/nova.py:945:89: E501 Line too long (107 > 88)
    |
943 |                               str(on_maintenance), str(hostid), str(segment_name), str(host_up_in_nova))
944 |                     try:
945 |                         masakari.update_host_maintenance(self._token, hostid, segment_name, on_maintenance)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
946 |                         LOG.info('maintenance status for host %s in masakari segment %s has been toggled to %s',
947 |                                  str(hostid), str(segment_name), str(on_maintenance))
    |

hamgr/hamgr/providers/nova.py:946:89: E501 Line too long (112 > 88)
    |
944 |                     try:
945 |                         masakari.update_host_maintenance(self._token, hostid, segment_name, on_maintenance)
946 |                         LOG.info('maintenance status for host %s in masakari segment %s has been toggled to %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
947 |                                  str(hostid), str(segment_name), str(on_maintenance))
948 |                     except Exception as e:
    |

hamgr/hamgr/providers/nova.py:949:89: E501 Line too long (98 > 88)
    |
947 |                                  str(hostid), str(segment_name), str(on_maintenance))
948 |                     except Exception as e:
949 |                         LOG.warning('failed to toggle maintenance for host %s to %s , error : %s',
    |                                                                                         ^^^^^^^^^^ E501
950 |                                     hostid, str(on_maintenance), str(e))
951 |         except Exception:
    |

hamgr/hamgr/providers/nova.py:952:89: E501 Line too long (93 > 88)
    |
950 |                                     hostid, str(on_maintenance), str(e))
951 |         except Exception:
952 |             LOG.exception('unhandled exception when toggle masakari host maintenance status')
    |                                                                                         ^^^^^ E501
953 |
954 |     def _cleanup_vmha_and_masakari(self):
    |

hamgr/hamgr/providers/nova.py:972:89: E501 Line too long (105 > 88)
    |
970 |         masakari_segment_names = [x['name'] for x in masakari_active_segments]
971 |         LOG.debug('names of masakari segments found : %s', str(masakari_segment_names))
972 |         common_between_nova_and_hamgr = list(set(nova_active_azs).intersection(set(hamgr_cluster_names)))
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
973 |         LOG.debug('common set between host availability_zones and vmha cluster : %s', str(common_between_nova_and_hamgr))
974 |         hamgr_clusters_to_remove = list(set(hamgr_cluster_names).difference(common_between_nova_and_hamgr))
    |

hamgr/hamgr/providers/nova.py:973:89: E501 Line too long (121 > 88)
    |
971 |         LOG.debug('names of masakari segments found : %s', str(masakari_segment_names))
972 |         common_between_nova_and_hamgr = list(set(nova_active_azs).intersection(set(hamgr_cluster_names)))
973 |         LOG.debug('common set between host availability_zones and vmha cluster : %s', str(common_between_nova_and_hamgr))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
974 |         hamgr_clusters_to_remove = list(set(hamgr_cluster_names).difference(common_between_nova_and_hamgr))
975 |         LOG.debug('additional vmha clusters for removal : %s', str(hamgr_clusters_to_remove))
    |

hamgr/hamgr/providers/nova.py:974:89: E501 Line too long (107 > 88)
    |
972 |         common_between_nova_and_hamgr = list(set(nova_active_azs).intersection(set(hamgr_cluster_names)))
973 |         LOG.debug('common set between host availability_zones and vmha cluster : %s', str(common_between_nova_and_hamgr))
974 |         hamgr_clusters_to_remove = list(set(hamgr_cluster_names).difference(common_between_nova_and_hamgr))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
975 |         LOG.debug('additional vmha clusters for removal : %s', str(hamgr_clusters_to_remove))
    |

hamgr/hamgr/providers/nova.py:975:89: E501 Line too long (93 > 88)
    |
973 |         LOG.debug('common set between host availability_zones and vmha cluster : %s', str(common_between_nova_and_hamgr))
974 |         hamgr_clusters_to_remove = list(set(hamgr_cluster_names).difference(common_between_nova_and_hamgr))
975 |         LOG.debug('additional vmha clusters for removal : %s', str(hamgr_clusters_to_remove))
    |                                                                                         ^^^^^ E501
976 |
977 |         # try to remove additional ha clusters
    |

hamgr/hamgr/providers/nova.py:981:89: E501 Line too long (132 > 88)
    |
979 |             try:
980 |                 if self.check_vmha_enabled_on_resmgr(cluster_name=cluster_name):
981 |                     LOG.debug('the cluster %s seems to be enabled from resmgr side. Skipping disabling call for this', cluster_name)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
982 |                     continue
983 |                 LOG.debug('disable additional vmha cluster : %s', cluster_name)
    |

hamgr/hamgr/providers/nova.py:986:89: E501 Line too long (113 > 88)
    |
984 |                 self._disable(cluster_name, synchronize=True)
985 |             except Exception as exp:
986 |                 LOG.warning('failed to remove additional vmha cluster with name %s : %s', cluster_name, str(exp))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
987 |
988 |         common_between_nova_and_masakari = list(set(nova_active_azs).intersection(set(masakari_segment_names)))
    |

hamgr/hamgr/providers/nova.py:988:89: E501 Line too long (111 > 88)
    |
986 |                 LOG.warning('failed to remove additional vmha cluster with name %s : %s', cluster_name, str(exp))
987 |
988 |         common_between_nova_and_masakari = list(set(nova_active_azs).intersection(set(masakari_segment_names)))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
989 |         LOG.debug('common set between host availability_zones and masakari segments : %s', str(common_between_nova_and_masakari))
990 |         masakari_segments_to_remove = list(set(masakari_segment_names).difference(set(common_between_nova_and_masakari)))
    |

hamgr/hamgr/providers/nova.py:989:89: E501 Line too long (129 > 88)
    |
988 |         common_between_nova_and_masakari = list(set(nova_active_azs).intersection(set(masakari_segment_names)))
989 |         LOG.debug('common set between host availability_zones and masakari segments : %s', str(common_between_nova_and_masakari))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
990 |         masakari_segments_to_remove = list(set(masakari_segment_names).difference(set(common_between_nova_and_masakari)))
991 |         LOG.debug('additional masakari segments for removal : %s', str(masakari_segments_to_remove))
    |

hamgr/hamgr/providers/nova.py:990:89: E501 Line too long (121 > 88)
    |
988 |         common_between_nova_and_masakari = list(set(nova_active_azs).intersection(set(masakari_segment_names)))
989 |         LOG.debug('common set between host availability_zones and masakari segments : %s', str(common_between_nova_and_masakari))
990 |         masakari_segments_to_remove = list(set(masakari_segment_names).difference(set(common_between_nova_and_masakari)))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
991 |         LOG.debug('additional masakari segments for removal : %s', str(masakari_segments_to_remove))
992 |         # try to remove additional masakari cluster if it was not removed during vmha cluster removal
    |

hamgr/hamgr/providers/nova.py:991:89: E501 Line too long (100 > 88)
    |
989 |         LOG.debug('common set between host availability_zones and masakari segments : %s', str(common_between_nova_and_masakari))
990 |         masakari_segments_to_remove = list(set(masakari_segment_names).difference(set(common_between_nova_and_masakari)))
991 |         LOG.debug('additional masakari segments for removal : %s', str(masakari_segments_to_remove))
    |                                                                                         ^^^^^^^^^^^^ E501
992 |         # try to remove additional masakari cluster if it was not removed during vmha cluster removal
993 |         for segment_name in masakari_segments_to_remove:
    |

hamgr/hamgr/providers/nova.py:992:89: E501 Line too long (101 > 88)
    |
990 |         masakari_segments_to_remove = list(set(masakari_segment_names).difference(set(common_between_nova_and_masakari)))
991 |         LOG.debug('additional masakari segments for removal : %s', str(masakari_segments_to_remove))
992 |         # try to remove additional masakari cluster if it was not removed during vmha cluster removal
    |                                                                                         ^^^^^^^^^^^^^ E501
993 |         for segment_name in masakari_segments_to_remove:
994 |             try:
    |

hamgr/hamgr/providers/nova.py:997:89: E501 Line too long (117 > 88)
    |
995 |                 masakari.delete_failover_segment(self._token, segment_name)
996 |             except Exception as exp:
997 |                 LOG.warning('failed to remove additional masakari segment with name %s : %s', segment_name, str(exp))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
998 |
999 |     def _get_latest_consul_status(self, cluster_name):
    |

hamgr/hamgr/providers/nova.py:1005:89: E501 Line too long (108 > 88)
     |
1003 |         LOG.debug('latest consul status : %s', str(status))
1004 |         if not status or status['status'] != constants.RPC_TASK_STATE_FINISHED:
1005 |             LOG.warning('failed to get latest consul status for cluster %s : %s', cluster_name, str(status))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
1006 |             return None
     |

hamgr/hamgr/providers/nova.py:1011:89: E501 Line too long (91 > 88)
     |
1009 |         return report
1010 |
1011 |     def _rebalance_consul_roles_if_needed(self, cluster_name, event_type, event_uuid=None):
     |                                                                                         ^^^ E501
1012 |         LOG.debug('check if consul cluster %s needs rebalance on event type %s, uuid %s',
1013 |                   str(cluster_name), str(event_type), str(event_uuid))
     |

hamgr/hamgr/providers/nova.py:1012:89: E501 Line too long (89 > 88)
     |
1011 |     def _rebalance_consul_roles_if_needed(self, cluster_name, event_type, event_uuid=None):
1012 |         LOG.debug('check if consul cluster %s needs rebalance on event type %s, uuid %s',
     |                                                                                         ^ E501
1013 |                   str(cluster_name), str(event_type), str(event_uuid))
1014 |         if event_type not in constants.HOST_EVENTS:
     |

hamgr/hamgr/providers/nova.py:1015:89: E501 Line too long (97 > 88)
     |
1013 |                   str(cluster_name), str(event_type), str(event_uuid))
1014 |         if event_type not in constants.HOST_EVENTS:
1015 |             LOG.warning('not inspect consul role rebalance, as type of event %s is invalid : %s',
     |                                                                                         ^^^^^^^^^ E501
1016 |                         str(event_uuid), event_type)
1017 |             return
     |

hamgr/hamgr/providers/nova.py:1040:89: E501 Line too long (98 > 88)
     |
1038 |         candidates = self._get_consul_rebalance_candidates(members)
1039 |         if not candidates:
1040 |             LOG.warning("no candidates available for role rebalance for cluster %s", cluster_name)
     |                                                                                         ^^^^^^^^^^ E501
1041 |             return
     |

hamgr/hamgr/providers/nova.py:1085:89: E501 Line too long (95 > 88)
     |
1083 |             for cluster in clusters:
1084 |                 availability_zone = cluster.name
1085 |                 availability_zone = self._get_availability_zone(nova_client, availability_zone)
     |                                                                                         ^^^^^^^ E501
1086 |                 hosts = set(availability_zone.hosts)
1087 |                 if str(reportedBy) in hosts:
     |

hamgr/hamgr/providers/nova.py:1107:89: E501 Line too long (97 > 88)
     |
1105 |             LOG.exception('unhandled exception when try to add new consul status')
1106 |
1107 |     def _execute_consul_role_rebalance(self, rebalance_request, cluster_name, host_ip, join_ips):
     |                                                                                         ^^^^^^^^^ E501
1108 |         req_id = rebalance_request['id']
1109 |         target_host_id = rebalance_request['host_id']
     |

hamgr/hamgr/providers/nova.py:1112:89: E501 Line too long (104 > 88)
     |
1110 |         target_old_role = rebalance_request['old_role']
1111 |         target_new_role = rebalance_request['new_role']
1112 |         LOG.info('execute consul role rebalance request %s for host %s from old role %s to new role %s',
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
1113 |                   req_id, target_host_id, target_old_role, target_new_role)
1114 |         # because the resmgr keeps the customerized settings for consul role, for pf9-ha-slave role
     |

hamgr/hamgr/providers/nova.py:1114:89: E501 Line too long (99 > 88)
     |
1112 |         LOG.info('execute consul role rebalance request %s for host %s from old role %s to new role %s',
1113 |                   req_id, target_host_id, target_old_role, target_new_role)
1114 |         # because the resmgr keeps the customerized settings for consul role, for pf9-ha-slave role
     |                                                                                         ^^^^^^^^^^^ E501
1115 |         # the difference between consul server and client is the 'bootstrap_expect' settings
1116 |         # for consul server role, the value is now 3, but for consul slave, the value is 0
     |

hamgr/hamgr/providers/nova.py:1115:89: E501 Line too long (92 > 88)
     |
1113 |                   req_id, target_host_id, target_old_role, target_new_role)
1114 |         # because the resmgr keeps the customerized settings for consul role, for pf9-ha-slave role
1115 |         # the difference between consul server and client is the 'bootstrap_expect' settings
     |                                                                                         ^^^^ E501
1116 |         # for consul server role, the value is now 3, but for consul slave, the value is 0
1117 |         # after updated the settings for pf9-ha-slave role,  the consul config file won't be changed
     |

hamgr/hamgr/providers/nova.py:1116:89: E501 Line too long (90 > 88)
     |
1114 |         # because the resmgr keeps the customerized settings for consul role, for pf9-ha-slave role
1115 |         # the difference between consul server and client is the 'bootstrap_expect' settings
1116 |         # for consul server role, the value is now 3, but for consul slave, the value is 0
     |                                                                                         ^^ E501
1117 |         # after updated the settings for pf9-ha-slave role,  the consul config file won't be changed
1118 |         # until restart the pf9-ha-slave service, or manually change the config file, then run
     |

hamgr/hamgr/providers/nova.py:1117:89: E501 Line too long (100 > 88)
     |
1115 |         # the difference between consul server and client is the 'bootstrap_expect' settings
1116 |         # for consul server role, the value is now 3, but for consul slave, the value is 0
1117 |         # after updated the settings for pf9-ha-slave role,  the consul config file won't be changed
     |                                                                                         ^^^^^^^^^^^^ E501
1118 |         # until restart the pf9-ha-slave service, or manually change the config file, then run
1119 |         # consul join command
     |

hamgr/hamgr/providers/nova.py:1118:89: E501 Line too long (94 > 88)
     |
1116 |         # for consul server role, the value is now 3, but for consul slave, the value is 0
1117 |         # after updated the settings for pf9-ha-slave role,  the consul config file won't be changed
1118 |         # until restart the pf9-ha-slave service, or manually change the config file, then run
     |                                                                                         ^^^^^^ E501
1119 |         # consul join command
1120 |         # so need two steps
     |

hamgr/hamgr/providers/nova.py:1141:89: E501 Line too long (93 > 88)
     |
1139 |             error = 'host %s does not have pf9-ha-slave role' % target_host_id
1140 |             LOG.warning('abort consul role rebalance request, as %s', error)
1141 |             conclusion.update({'status': constants.RPC_TASK_STATE_ABORTED, 'message': error})
     |                                                                                         ^^^^^ E501
1142 |             return conclusion
     |

hamgr/hamgr/providers/nova.py:1145:89: E501 Line too long (107 > 88)
     |
1144 |         _, _, nodes_details = self._get_ips_for_hosts_v3(cluster_name)
1145 |         data = self._customize_pf9_ha_slave_config(cluster_name, join_ips, host_ip, host_ip, nodes_details)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
1146 |         # step 1 : modify 'bootstrap_expect' base on the new role
1147 |         if target_new_role == constants.CONSUL_ROLE_SERVER:
     |

hamgr/hamgr/providers/nova.py:1154:89: E501 Line too long (105 > 88)
     |
1152 |                   target_host_id, str(data))
1153 |         # update resmgr with the new settings
1154 |         result = self._resmgr_client.update_role(target_host_id, "pf9-ha-slave", data, self._token['id'])
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
1155 |         LOG.debug('rebalance by updating settings for host %s on role '
1156 |                   'pf9-ha-slave with : %s, returns : %s',
     |

hamgr/hamgr/providers/nova.py:1161:89: E501 Line too long (106 > 88)
     |
1159 |         resp = None
1160 |         if not succeeced:
1161 |             LOG.warning('failed to update resmgr for consul role rebalance host %s with data %s, resp %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
1162 |                      target_host_id,
1163 |                      str(data),
     |

hamgr/hamgr/providers/nova.py:1165:89: E501 Line too long (132 > 88)
     |
1163 |                      str(data),
1164 |                      str(result))
1165 |             conclusion.update({'status': constants.RPC_TASK_STATE_ABORTED, 'message': 'failed to update resmgr : %s' % result.text})
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1166 |             return conclusion
1167 |         else:
     |

hamgr/hamgr/providers/nova.py:1168:89: E501 Line too long (90 > 88)
     |
1166 |             return conclusion
1167 |         else:
1168 |             # step 2 : notify pf9-ha-slave with RPC message contains the rebalance request
     |                                                                                         ^^ E501
1169 |             LOG.info('sending consul role rebalance request %s ', str(rebalance_request))
1170 |             resp = get_rebalance_controller(self._config).rebalance_and_wait_for_result(rebalance_request)
     |

hamgr/hamgr/providers/nova.py:1169:89: E501 Line too long (89 > 88)
     |
1167 |         else:
1168 |             # step 2 : notify pf9-ha-slave with RPC message contains the rebalance request
1169 |             LOG.info('sending consul role rebalance request %s ', str(rebalance_request))
     |                                                                                         ^ E501
1170 |             resp = get_rebalance_controller(self._config).rebalance_and_wait_for_result(rebalance_request)
     |

hamgr/hamgr/providers/nova.py:1170:89: E501 Line too long (106 > 88)
     |
1168 |             # step 2 : notify pf9-ha-slave with RPC message contains the rebalance request
1169 |             LOG.info('sending consul role rebalance request %s ', str(rebalance_request))
1170 |             resp = get_rebalance_controller(self._config).rebalance_and_wait_for_result(rebalance_request)
     |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
1171 |
1172 |         if resp:
     |

hamgr/hamgr/providers/nova.py:1176:89: E501 Line too long (110 > 88)
     |
1174 |             consul_status = resp.get('consul_status', {})
1175 |             resp_msg = resp.get('message', {})
1176 |             conclusion.update({'status': resp['status'], 'message': resp_msg, 'consul_status': consul_status})
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
1177 |             return conclusion
1178 |         else:
     |

hamgr/hamgr/providers/nova.py:1179:89: E501 Line too long (98 > 88)
     |
1177 |             return conclusion
1178 |         else:
1179 |             msg = 'empty consul role rebalance response for request : %s' % str(rebalance_request)
     |                                                                                         ^^^^^^^^^^ E501
1180 |             LOG.warning('consul role rebalance failed due to %s', msg)
1181 |             conclusion.update({'status': constants.RPC_TASK_STATE_ERROR, 'message': msg})
     |

hamgr/hamgr/providers/nova.py:1181:89: E501 Line too long (89 > 88)
     |
1179 |             msg = 'empty consul role rebalance response for request : %s' % str(rebalance_request)
1180 |             LOG.warning('consul role rebalance failed due to %s', msg)
1181 |             conclusion.update({'status': constants.RPC_TASK_STATE_ERROR, 'message': msg})
     |                                                                                         ^ E501
1182 |             return conclusion
     |

hamgr/hamgr/providers/nova.py:1184:89: E501 Line too long (104 > 88)
     |
1182 |             return conclusion
1183 |
1184 |     def _add_ha_slave_if_not_exist(self, cluster_name, host_ids_for_adding, consul_role, peer_host_ids):
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
1185 |         if consul_role not in ['server', 'agent']:
1186 |             consul_role = 'server'
     |

hamgr/hamgr/providers/nova.py:1189:89: E501 Line too long (100 > 88)
     |
1187 |         nova_client = self._get_nova_client()
1188 |         self._token = self._get_v3_token()
1189 |         hosts_info = self._resmgr_client.fetch_hosts_details(host_ids_for_adding, self._token['id'])
     |                                                                                         ^^^^^^^^^^^^ E501
1190 |         current_roles = dict(zip(hosts_info.keys(), [hosts_info.get(x, {}).get('roles', []) for x in hosts_info.keys()]))
     |

hamgr/hamgr/providers/nova.py:1190:89: E501 Line too long (121 > 88)
     |
1188 |         self._token = self._get_v3_token()
1189 |         hosts_info = self._resmgr_client.fetch_hosts_details(host_ids_for_adding, self._token['id'])
1190 |         current_roles = dict(zip(hosts_info.keys(), [hosts_info.get(x, {}).get('roles', []) for x in hosts_info.keys()]))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1191 |
1192 |         role_missed_host_ids = []
     |

hamgr/hamgr/providers/nova.py:1198:89: E501 Line too long (102 > 88)
     |
1196 |                 role_missed_host_ids.append(hid)
1197 |         if len(role_missed_host_ids) > 0:
1198 |             LOG.info('authorize pf9-ha-slave during adding new hosts: %s ', str(role_missed_host_ids))
     |                                                                                         ^^^^^^^^^^^^^^ E501
1199 |             hypervisors = nova_client.hypervisors.list()
1200 |             #all_hosts = list(set(host_ids_for_adding).union(set(peer_host_ids)))
     |

hamgr/hamgr/providers/nova.py:1213:89: E501 Line too long (98 > 88)
     |
1211 |                     break
1212 |             cluster_hosts = set(az_hosts)
1213 |             hosts_info = self._resmgr_client.fetch_hosts_details(cluster_hosts, self._token['id'])
     |                                                                                         ^^^^^^^^^^ E501
1214 |
1215 |             ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |

hamgr/hamgr/providers/nova.py:1215:89: E501 Line too long (97 > 88)
     |
1213 |             hosts_info = self._resmgr_client.fetch_hosts_details(cluster_hosts, self._token['id'])
1214 |
1215 |             ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |                                                                                         ^^^^^^^^^ E501
1216 |                                                                                      cluster_hosts,
1217 |                                                                                      hosts_info)
     |

hamgr/hamgr/providers/nova.py:1227:89: E501 Line too long (94 > 88)
     |
1225 |             self._wait_for_role_to_ok_v2(role_missed_host_ids)
1226 |             # Update join_ips for existing hosts
1227 |             LOG.info('When adding new hosts: updating pf9-ha-slave for existing %d hosts: %s',
     |                                                                                         ^^^^^^ E501
1228 |                      len(set(peer_host_ids)), str(peer_host_ids))
1229 |             self._auth(cluster_name, ip_lookup, cluster_ip_lookup, nodes_details,
     |

hamgr/hamgr/providers/nova.py:1251:89: E501 Line too long (90 > 88)
     |
1249 |         #all_hosts = list(set(host_ids).union(set(peer_host_ids)))
1250 |         all_hosts = list(set(host_ids).union(set(cluster_hosts)))
1251 |         hosts_info = self._resmgr_client.fetch_hosts_details(all_hosts, self._token['id'])
     |                                                                                         ^^ E501
1252 |
1253 |         current_roles = dict(zip(hosts_info.keys(), [hosts_info.get(x, {}).get('roles', []) for x in hosts_info.keys()]))
     |

hamgr/hamgr/providers/nova.py:1253:89: E501 Line too long (121 > 88)
     |
1251 |         hosts_info = self._resmgr_client.fetch_hosts_details(all_hosts, self._token['id'])
1252 |
1253 |         current_roles = dict(zip(hosts_info.keys(), [hosts_info.get(x, {}).get('roles', []) for x in hosts_info.keys()]))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1254 |         role_assigned_host_ids = []
1255 |         for hid in host_ids:
     |

hamgr/hamgr/providers/nova.py:1264:89: E501 Line too long (97 > 88)
     |
1262 |             self._wait_for_role_to_ok_v2(host_ids)
1263 |             # Update join_ips for existing hosts
1264 |             ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |                                                                                         ^^^^^^^^^ E501
1265 |                                                                                      cluster_hosts,
1266 |                                                                                      hosts_info)
     |

hamgr/hamgr/providers/nova.py:1272:89: E501 Line too long (92 > 88)
     |
1270 |             LOG.debug('nodes_details: %s', len(nodes_details))
1271 |
1272 |             LOG.info('When removing hosts: updating pf9-ha-slave for existing %d hosts: %s',
     |                                                                                         ^^^^ E501
1273 |                      len(set(peer_host_ids)), str(peer_host_ids))
1274 |             self._auth(cluster_name, ip_lookup, cluster_ip_lookup, nodes_details,
     |

hamgr/hamgr/providers/nova.py:1312:89: E501 Line too long (93 > 88)
     |
1310 |                                         project_domain_id="default")
1311 |         sess = session.Session(auth=auth)
1312 |         nova = client.Client(2, session=sess, region_name=self._region, interface='internal')
     |                                                                                         ^^^^^ E501
1313 |         return nova
     |

hamgr/hamgr/providers/nova.py:1320:89: E501 Line too long (94 > 88)
     |
1318 |         cluster = db_api.get_cluster(name)
1319 |         if cluster is None:
1320 |             LOG.warning('no hamgr cluster record for availability zone %s', availability_zone)
     |                                                                                         ^^^^^^ E501
1321 |             return {}
1322 |         enabled = cluster.enabled if cluster is not None else False
     |

hamgr/hamgr/providers/nova.py:1371:89: E501 Line too long (89 > 88)
     |
1369 |                 LOG.debug('role status for host %s : %s', host, str(json_resp))
1370 |                 if json_resp.get('role_status', '') != 'ok':
1371 |                     LOG.warning('Role status of host %s is not ok : %s, not enabling HA '
     |                                                                                         ^ E501
1372 |                              'at the moment.', host, json_resp.get('role_status', ''))
1373 |                     raise ha_exceptions.InvalidHostRoleStatus(host)
     |

hamgr/hamgr/providers/nova.py:1375:89: E501 Line too long (89 > 88)
     |
1373 |                     raise ha_exceptions.InvalidHostRoleStatus(host)
1374 |                 if json_resp['info']['responding'] is False:
1375 |                     LOG.warning('Host %s is not responding : %s, not enabling HA at the '
     |                                                                                         ^ E501
1376 |                              'moment.', host, json_resp['info']['responding'])
1377 |                     raise ha_exceptions.HostOffline(host)
     |

hamgr/hamgr/providers/nova.py:1379:89: E501 Line too long (126 > 88)
     |
1377 |                     raise ha_exceptions.HostOffline(host)
1378 |
1379 |     def _customize_pf9_ha_slave_config(self, cluster_name, consul_join_ips, consul_host_ip, consul_cluster_ip, nodes_details):
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1380 |         # since the pf9-ha-slave role is controlled by hamgr, all the customizable settings for pf9-ha-slave role
1381 |         # that need to be synced with hamgr should be list here to be passed down to resmgr for updating
     |

hamgr/hamgr/providers/nova.py:1380:89: E501 Line too long (113 > 88)
     |
1379 |     def _customize_pf9_ha_slave_config(self, cluster_name, consul_join_ips, consul_host_ip, consul_cluster_ip, nodes_details):
1380 |         # since the pf9-ha-slave role is controlled by hamgr, all the customizable settings for pf9-ha-slave role
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1381 |         # that need to be synced with hamgr should be list here to be passed down to resmgr for updating
1382 |         # the settings for pf9-ha-slave on host.
     |

hamgr/hamgr/providers/nova.py:1381:89: E501 Line too long (104 > 88)
     |
1379 |     def _customize_pf9_ha_slave_config(self, cluster_name, consul_join_ips, consul_host_ip, consul_cluster_ip, nodes_details):
1380 |         # since the pf9-ha-slave role is controlled by hamgr, all the customizable settings for pf9-ha-slave role
1381 |         # that need to be synced with hamgr should be list here to be passed down to resmgr for updating
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
1382 |         # the settings for pf9-ha-slave on host.
1383 |         # the keys needs to match the keys which are customizable in pf9-ha-slave config file
     |

hamgr/hamgr/providers/nova.py:1383:89: E501 Line too long (93 > 88)
     |
1381 |         # that need to be synced with hamgr should be list here to be passed down to resmgr for updating
1382 |         # the settings for pf9-ha-slave on host.
1383 |         # the keys needs to match the keys which are customizable in pf9-ha-slave config file
     |                                                                                         ^^^^^ E501
1384 |         # first the basic settings
1385 |         customize_cfg = dict(cluster_name=str(cluster_name),
     |

hamgr/hamgr/providers/nova.py:1391:89: E501 Line too long (89 > 88)
     |
1389 |                              cluster_details=json.dumps(nodes_details))
1390 |         # then other settings
1391 |         is_enabled = self._config.getboolean("DEFAULT", "enable_consul_role_rebalance") \
     |                                                                                         ^ E501
1392 |             if self._config.has_option("DEFAULT", "enable_consul_role_rebalance") else False
     |

hamgr/hamgr/providers/nova.py:1392:89: E501 Line too long (92 > 88)
     |
1390 |         # then other settings
1391 |         is_enabled = self._config.getboolean("DEFAULT", "enable_consul_role_rebalance") \
1392 |             if self._config.has_option("DEFAULT", "enable_consul_role_rebalance") else False
     |                                                                                         ^^^^ E501
1393 |
1394 |         customize_cfg['role_rebalance_enabled'] = str(is_enabled)
     |

hamgr/hamgr/providers/nova.py:1399:89: E501 Line too long (90 > 88)
     |
1397 |             exchange = self._config.get(section, 'exchange_name')
1398 |             exchange_type = self._config.get(section, 'exchange_type')
1399 |             routingkey_for_sending = self._config.get(section, 'routingkey_for_sending') \
     |                                                                                         ^^ E501
1400 |                 if self._config.has_option(section, 'routingkey_for_sending') else 'sending'
1401 |             routingkey_for_receiving = self._config.get(section, 'routingkey_for_receiving') \
     |

hamgr/hamgr/providers/nova.py:1400:89: E501 Line too long (92 > 88)
     |
1398 |             exchange_type = self._config.get(section, 'exchange_type')
1399 |             routingkey_for_sending = self._config.get(section, 'routingkey_for_sending') \
1400 |                 if self._config.has_option(section, 'routingkey_for_sending') else 'sending'
     |                                                                                         ^^^^ E501
1401 |             routingkey_for_receiving = self._config.get(section, 'routingkey_for_receiving') \
1402 |                 if self._config.has_option(section, 'routingkey_for_receiving') else 'receiving'
     |

hamgr/hamgr/providers/nova.py:1401:89: E501 Line too long (94 > 88)
     |
1399 |             routingkey_for_sending = self._config.get(section, 'routingkey_for_sending') \
1400 |                 if self._config.has_option(section, 'routingkey_for_sending') else 'sending'
1401 |             routingkey_for_receiving = self._config.get(section, 'routingkey_for_receiving') \
     |                                                                                         ^^^^^^ E501
1402 |                 if self._config.has_option(section, 'routingkey_for_receiving') else 'receiving'
1403 |             # here no matter what the settings are used by hamgr, the pf9-ha-slave needs to matched settings
     |

hamgr/hamgr/providers/nova.py:1402:89: E501 Line too long (96 > 88)
     |
1400 |                 if self._config.has_option(section, 'routingkey_for_sending') else 'sending'
1401 |             routingkey_for_receiving = self._config.get(section, 'routingkey_for_receiving') \
1402 |                 if self._config.has_option(section, 'routingkey_for_receiving') else 'receiving'
     |                                                                                         ^^^^^^^^ E501
1403 |             # here no matter what the settings are used by hamgr, the pf9-ha-slave needs to matched settings
1404 |             # in order to send and receive message on the same exchange
     |

hamgr/hamgr/providers/nova.py:1403:89: E501 Line too long (108 > 88)
     |
1401 |             routingkey_for_receiving = self._config.get(section, 'routingkey_for_receiving') \
1402 |                 if self._config.has_option(section, 'routingkey_for_receiving') else 'receiving'
1403 |             # here no matter what the settings are used by hamgr, the pf9-ha-slave needs to matched settings
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
1404 |             # in order to send and receive message on the same exchange
1405 |             customize_cfg['amqp_exchange_name'] = exchange
     |

hamgr/hamgr/providers/nova.py:1407:89: E501 Line too long (97 > 88)
     |
1405 |             customize_cfg['amqp_exchange_name'] = exchange
1406 |             customize_cfg['amqp_exchange_type'] = exchange_type
1407 |             # the routing key for sending on controller is the routing key for receiving on hosts
     |                                                                                         ^^^^^^^^^ E501
1408 |             customize_cfg['amqp_routingkey_sending'] = routingkey_for_receiving
1409 |             # the routing key for receiving on controller is the routing key for sending on hosts
     |

hamgr/hamgr/providers/nova.py:1409:89: E501 Line too long (97 > 88)
     |
1407 |             # the routing key for sending on controller is the routing key for receiving on hosts
1408 |             customize_cfg['amqp_routingkey_sending'] = routingkey_for_receiving
1409 |             # the routing key for receiving on controller is the routing key for sending on hosts
     |                                                                                         ^^^^^^^^^ E501
1410 |             customize_cfg['amqp_routingkey_receiving'] = routingkey_for_sending
     |

hamgr/hamgr/providers/nova.py:1413:89: E501 Line too long (118 > 88)
     |
1412 |         if self._is_consul_encryption_enabled():
1413 |             gossip_key = keyhelper.get_consul_gossip_encryption_key(cluster_name=str(cluster_name), seed=self._db_pwd)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1414 |             _, ca_cert_content = keyhelper.read_consul_ca_key_cert_pair()
1415 |             svc_key_content, svc_cert_content = keyhelper.read_consul_svc_key_cert_pair(cluster_name)
     |

hamgr/hamgr/providers/nova.py:1415:89: E501 Line too long (101 > 88)
     |
1413 |             gossip_key = keyhelper.get_consul_gossip_encryption_key(cluster_name=str(cluster_name), seed=self._db_pwd)
1414 |             _, ca_cert_content = keyhelper.read_consul_ca_key_cert_pair()
1415 |             svc_key_content, svc_cert_content = keyhelper.read_consul_svc_key_cert_pair(cluster_name)
     |                                                                                         ^^^^^^^^^^^^^ E501
1416 |             customize_cfg['encrypt'] = gossip_key
1417 |             customize_cfg['verify_incoming'] = "true"
     |

hamgr/hamgr/providers/nova.py:1437:89: E501 Line too long (109 > 88)
     |
1435 |         return customize_cfg
1436 |
1437 |     def _auth(self, availability_zone, ip_lookup, cluster_ip_lookup, nodes_details, token, nodes, role=None):
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
1438 |         valid_ips = [x for x in cluster_ip_lookup.values() if x != '']
1439 |         ips = ','.join([str(v) for v in sorted(valid_ips)])
     |

hamgr/hamgr/providers/nova.py:1444:89: E501 Line too long (137 > 88)
     |
1442 | …
1443 | …
1444 | …config(availability_zone, ips, ip_lookup[node], cluster_ip_lookup[node], nodes_details)
     |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1445 | …
1446 | …role == 'server' else 0
     |

hamgr/hamgr/providers/nova.py:1452:89: E501 Line too long (113 > 88)
     |
1450 |             #     LOG.info('Updating pf9-ha-slave role on node %s using IP %s',
1451 |             #              node, ip_lookup[node])
1452 |             # LOG.debug('authorize by updating settings for host %s for pf9-ha-slave with : %s', node, str(data))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1453 |             resp = self._resmgr_client.update_role(node, 'pf9-ha-slave', data, self._token['id'])
1454 |             if resp.status_code == requests.codes.not_found and \
     |

hamgr/hamgr/providers/nova.py:1453:89: E501 Line too long (97 > 88)
     |
1451 |             #              node, ip_lookup[node])
1452 |             # LOG.debug('authorize by updating settings for host %s for pf9-ha-slave with : %s', node, str(data))
1453 |             resp = self._resmgr_client.update_role(node, 'pf9-ha-slave', data, self._token['id'])
     |                                                                                         ^^^^^^^^^ E501
1454 |             if resp.status_code == requests.codes.not_found and \
1455 |                     resp.content.find(b'HostDown'):
     |

hamgr/hamgr/providers/nova.py:1463:89: E501 Line too long (101 > 88)
     |
1461 |                          node)
1462 |                 time.sleep(5)
1463 |                 resp = self._resmgr_client.update_role(node, 'pf9-ha-slave', data, self._token['id'])
     |                                                                                         ^^^^^^^^^^^^^ E501
1464 |                 if datetime.now() - start_time > timedelta(seconds=self._max_auth_wait_seconds):
1465 |                     break
     |

hamgr/hamgr/providers/nova.py:1464:89: E501 Line too long (96 > 88)
     |
1462 |                 time.sleep(5)
1463 |                 resp = self._resmgr_client.update_role(node, 'pf9-ha-slave', data, self._token['id'])
1464 |                 if datetime.now() - start_time > timedelta(seconds=self._max_auth_wait_seconds):
     |                                                                                         ^^^^^^^^ E501
1465 |                     break
1466 |             if resp.status_code != requests.codes.ok:
     |

hamgr/hamgr/providers/nova.py:1472:89: E501 Line too long (97 > 88)
     |
1471 |     def _get_cluster_ip(self, host_id, json_resp):
1472 |         LOG.debug('try to get cluster_ip for host %s from resp %s', str(host_id), str(json_resp))
     |                                                                                         ^^^^^^^^^ E501
1473 |         if not json_resp:
1474 |             LOG.warning('_get_cluster_ip : response object is none, cannot parse cluster ip')
     |

hamgr/hamgr/providers/nova.py:1474:89: E501 Line too long (93 > 88)
     |
1472 |         LOG.debug('try to get cluster_ip for host %s from resp %s', str(host_id), str(json_resp))
1473 |         if not json_resp:
1474 |             LOG.warning('_get_cluster_ip : response object is none, cannot parse cluster ip')
     |                                                                                         ^^^^^ E501
1475 |             return None
1476 |         if 'cluster_ip' not in json_resp:
     |

hamgr/hamgr/providers/nova.py:1489:89: E501 Line too long (89 > 88)
     |
1487 |         nova_client = self._get_nova_client()
1488 |         hypervisors = nova_client.hypervisors.list()
1489 |         hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
     |                                                                                         ^ E501
1490 |         ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
1491 |                                                                                  host_ids,
     |

hamgr/hamgr/providers/nova.py:1490:89: E501 Line too long (93 > 88)
     |
1488 |         hypervisors = nova_client.hypervisors.list()
1489 |         hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
1490 |         ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |                                                                                         ^^^^^ E501
1491 |                                                                                  host_ids,
1492 |                                                                                  hosts_info)
     |

hamgr/hamgr/providers/nova.py:1509:89: E501 Line too long (118 > 88)
     |
1507 |                 roles_for_host = hosts_info.get(host_id, {}).get('roles', {})
1508 |                 if roles_for_host:
1509 |                     json_resp = hosts_info.get(host_id, {}).get("role_settings", {}).get("pf9-ostackhost-neutron", {})
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1510 |                     LOG.debug('role details for host %s : %s', host_id, str(json_resp))
1511 |                     cluster_ip = self._get_cluster_ip(host_id, json_resp)
     |

hamgr/hamgr/providers/nova.py:1513:89: E501 Line too long (110 > 88)
     |
1511 |                     cluster_ip = self._get_cluster_ip(host_id, json_resp)
1512 |                     if cluster_ip:
1513 |                         LOG.debug('Using cluster ip %s from ostackhost role for host %s', cluster_ip, host_id)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
1514 |                         cluster_ip_lookup[host_id] = cluster_ip
1515 |                         ip_lookup[host_id] = cluster_ip
     |

hamgr/hamgr/providers/nova.py:1526:89: E501 Line too long (104 > 88)
     |
1524 |         if len(ip_lookup.keys()) != len(host_ids):
1525 |             ids = set(host_ids).difference(set(ip_lookup.keys()))
1526 |             LOG.warning('size not match : ip_lookup : %s, hosts : %s,  found no consul ip for hosts %s',
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
1527 |                      str(ip_lookup), str(host_ids), str(ids))
1528 |             raise ha_exceptions.HostsIpNotFound(list(ids))
     |

hamgr/hamgr/providers/nova.py:1531:89: E501 Line too long (112 > 88)
     |
1529 |         if len(cluster_ip_lookup.keys()) != len(host_ids):
1530 |             ids = set(host_ids).difference(set(cluster_ip_lookup.keys()))
1531 |             LOG.warning('size not match : cluster_ip_lookup : %s, hosts : %s, found no cluster ip for hosts %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
1532 |                      str(cluster_ip_lookup), str(host_ids), str(ids))
1533 |             raise ha_exceptions.HostsIpNotFound(list(ids))
     |

hamgr/hamgr/providers/nova.py:1569:89: E501 Line too long (94 > 88)
     |
1567 |         # need join ips for offline hosts in availability_zone as well
1568 |         cluster_hosts = set(hosts) 
1569 |         hosts_info = self._resmgr_client.fetch_hosts_details(cluster_hosts, self._token['id'])
     |                                                                                         ^^^^^^ E501
1570 |         ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
1571 |                                                                                  cluster_hosts,
     |

hamgr/hamgr/providers/nova.py:1570:89: E501 Line too long (93 > 88)
     |
1568 |         cluster_hosts = set(hosts) 
1569 |         hosts_info = self._resmgr_client.fetch_hosts_details(cluster_hosts, self._token['id'])
1570 |         ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |                                                                                         ^^^^^ E501
1571 |                                                                                  cluster_hosts,
1572 |                                                                                  hosts_info)
     |

hamgr/hamgr/providers/nova.py:1574:89: E501 Line too long (114 > 88)
     |
1572 |                                                                                  hosts_info)
1573 |         LOG.info('authorize pf9-ha-slave during assign roles')
1574 |         self._auth(availability_zone, ip_lookup, cluster_ip_lookup, nodes_details, self._token, servers, 'server')
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1575 |         self._auth(availability_zone, ip_lookup, cluster_ip_lookup, nodes_details, self._token, agents, 'agent')
     |

hamgr/hamgr/providers/nova.py:1575:89: E501 Line too long (112 > 88)
     |
1573 |         LOG.info('authorize pf9-ha-slave during assign roles')
1574 |         self._auth(availability_zone, ip_lookup, cluster_ip_lookup, nodes_details, self._token, servers, 'server')
1575 |         self._auth(availability_zone, ip_lookup, cluster_ip_lookup, nodes_details, self._token, agents, 'agent')
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
1576 |
1577 |     def __perf_meter(self, method, time_start):
     |

hamgr/hamgr/providers/nova.py:1597:9: F841 Local variable `nova_client` is assigned to but never used
     |
1595 |                             as part of a cluster migration operation.
1596 |         """
1597 |         nova_client = self._get_nova_client()
     |         ^^^^^^^^^^^ F841
1598 |         cluster = None
1599 |         cluster_id = None
     |
     = help: Remove assignment to unused variable `nova_client`

hamgr/hamgr/providers/nova.py:1634:89: E501 Line too long (96 > 88)
     |
1632 |         try:
1633 |             LOG.debug('create ha cluster for enabling request')
1634 |             cluster = db_api.create_cluster_if_needed(availability_zone, constants.TASK_WAITING)
     |                                                                                         ^^^^^^^^ E501
1635 |             db_api.update_cluster_task_state(availability_zone, constants.TASK_WAITING)
1636 |             # set the status to 'request-enable'
     |

hamgr/hamgr/providers/nova.py:1637:89: E501 Line too long (94 > 88)
     |
1635 |             db_api.update_cluster_task_state(availability_zone, constants.TASK_WAITING)
1636 |             # set the status to 'request-enable'
1637 |             db_api.update_request_status(availability_zone, constants.HA_STATE_REQUEST_ENABLE)
     |                                                                                         ^^^^^^ E501
1638 |             # publish status
1639 |             self._notify_status(constants.HA_STATE_REQUEST_ENABLE, "cluster", availability_zone)
     |

hamgr/hamgr/providers/nova.py:1639:89: E501 Line too long (96 > 88)
     |
1637 |             db_api.update_request_status(availability_zone, constants.HA_STATE_REQUEST_ENABLE)
1638 |             # publish status
1639 |             self._notify_status(constants.HA_STATE_REQUEST_ENABLE, "cluster", availability_zone)
     |                                                                                         ^^^^^^^^ E501
1640 |         except Exception as e:
1641 |             if cluster_id:
     |

hamgr/hamgr/providers/nova.py:1645:89: E501 Line too long (95 > 88)
     |
1643 |             LOG.error('unhandled exception : %s', str(e))
1644 |
1645 |     def _handle_enable_request(self, request, hosts=None, next_state=constants.TASK_COMPLETED):
     |                                                                                         ^^^^^^^ E501
1646 |         LOG.info('Handling enable request : %s', str(request))
1647 |         if not request:
     |

hamgr/hamgr/providers/nova.py:1657:89: E501 Line too long (91 > 88)
     |
1655 |         try:
1656 |             # observed that hosts sometimes need longer time to get to converged state
1657 |             # if this happens, _validate_hosts will throw exceptions, then the request will
     |                                                                                         ^^^ E501
1658 |             # not be processed until all requirements are met
1659 |             self._validate_hosts(hosts)
     |

hamgr/hamgr/providers/nova.py:1668:89: E501 Line too long (101 > 88)
     |
1666 |                 ha_exceptions.InvalidHostRoleStatus,
1667 |                 ha_exceptions.InvalidHypervisorRoleStatus) as ex:
1668 |             LOG.warning('exception when handle enable request : %s, will retry the request', str(ex))
     |                                                                                         ^^^^^^^^^^^^^ E501
1669 |             return
1670 |         except Exception:
     |

hamgr/hamgr/providers/nova.py:1671:89: E501 Line too long (93 > 88)
     |
1669 |             return
1670 |         except Exception:
1671 |             LOG.exception('unhandled exception in validate hosts when handle enable request')
     |                                                                                         ^^^^^ E501
1672 |             return
1673 |         time_begin = datetime.utcnow()
     |

hamgr/hamgr/providers/nova.py:1677:89: E501 Line too long (99 > 88)
     |
1675 |         self.__perf_meter('utils.get_token', time_begin)
1676 |         try:
1677 |             # when request to enable a cluster, first create CA if not exist, and svc key and certs
     |                                                                                         ^^^^^^^^^^^ E501
1678 |             # if self._is_consul_encryption_enabled():
1679 |             #     ca_changed = False
     |

hamgr/hamgr/providers/nova.py:1690:89: E501 Line too long (92 > 88)
     |
1688 |             #     if not keyhelper.are_consul_svc_key_cert_pair_exist(cluster_name) or \
1689 |             #             keyhelper.is_consul_svc_cert_expired(cluster_name):
1690 |             #         svc_changed = keyhelper.create_consul_svc_key_cert_pairs(cluster_name)
     |                                                                                         ^^^^ E501
1691 |             #         LOG.info('svc key and cert for cluster name %s are generated ? %s', cluster_name, str(svc_changed))
1692 |             #     else:
     |

hamgr/hamgr/providers/nova.py:1691:89: E501 Line too long (121 > 88)
     |
1689 |             #             keyhelper.is_consul_svc_cert_expired(cluster_name):
1690 |             #         svc_changed = keyhelper.create_consul_svc_key_cert_pairs(cluster_name)
1691 |             #         LOG.info('svc key and cert for cluster name %s are generated ? %s', cluster_name, str(svc_changed))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1692 |             #     else:
1693 |             #         LOG.debug('svc key and cert for cluster name %s are good for now', cluster_name)
     |

hamgr/hamgr/providers/nova.py:1693:89: E501 Line too long (102 > 88)
     |
1691 |             #         LOG.info('svc key and cert for cluster name %s are generated ? %s', cluster_name, str(svc_changed))
1692 |             #     else:
1693 |             #         LOG.debug('svc key and cert for cluster name %s are good for now', cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^ E501
1694 |
1695 |             # 1. update task_state to 'creating' and mark request as 'enabling' in status
     |

hamgr/hamgr/providers/nova.py:1695:89: E501 Line too long (89 > 88)
     |
1693 |             #         LOG.debug('svc key and cert for cluster name %s are good for now', cluster_name)
1694 |
1695 |             # 1. update task_state to 'creating' and mark request as 'enabling' in status
     |                                                                                         ^ E501
1696 |             cluster = db_api.get_cluster(cluster_id)
1697 |             if cluster.task_state != constants.TASK_CREATING:
     |

hamgr/hamgr/providers/nova.py:1698:89: E501 Line too long (96 > 88)
     |
1696 |             cluster = db_api.get_cluster(cluster_id)
1697 |             if cluster.task_state != constants.TASK_CREATING:
1698 |                 db_api.update_cluster_task_state(str_availability_zone, constants.TASK_CREATING)
     |                                                                                         ^^^^^^^^ E501
1699 |             LOG.info('updating status of cluster %s to %s', str(cluster_id), constants.HA_STATE_ENABLING)
1700 |             time_begin = datetime.utcnow()
     |

hamgr/hamgr/providers/nova.py:1699:89: E501 Line too long (105 > 88)
     |
1697 |             if cluster.task_state != constants.TASK_CREATING:
1698 |                 db_api.update_cluster_task_state(str_availability_zone, constants.TASK_CREATING)
1699 |             LOG.info('updating status of cluster %s to %s', str(cluster_id), constants.HA_STATE_ENABLING)
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
1700 |             time_begin = datetime.utcnow()
1701 |             db_api.update_request_status(cluster_id, constants.HA_STATE_ENABLING)
     |

hamgr/hamgr/providers/nova.py:1703:89: E501 Line too long (91 > 88)
     |
1701 |             db_api.update_request_status(cluster_id, constants.HA_STATE_ENABLING)
1702 |             self._notify_status(constants.HA_STATE_ENABLING, "cluster", cluster_id)
1703 |             self.__perf_meter('db_api.update_enable_or_disable_request_status', time_begin)
     |                                                                                         ^^^ E501
1704 |
1705 |             # 2. Push roles
     |

hamgr/hamgr/providers/nova.py:1714:89: E501 Line too long (94 > 88)
     |
1712 |             time_begin = datetime.utcnow()
1713 |             if not masakari.is_failover_segment_exist(self._token, str(cluster_name)):
1714 |                 LOG.info('create masakari masakari segment during handling enabling request, '
     |                                                                                         ^^^^^^ E501
1715 |                          'segment id %s, name %s, hosts %s', str(cluster_id), cluster_name, str(hosts))
1716 |                 # masakari failover segment must be created with vmha cluster name, not id
     |

hamgr/hamgr/providers/nova.py:1715:89: E501 Line too long (103 > 88)
     |
1713 |             if not masakari.is_failover_segment_exist(self._token, str(cluster_name)):
1714 |                 LOG.info('create masakari masakari segment during handling enabling request, '
1715 |                          'segment id %s, name %s, hosts %s', str(cluster_id), cluster_name, str(hosts))
     |                                                                                         ^^^^^^^^^^^^^^^ E501
1716 |                 # masakari failover segment must be created with vmha cluster name, not id
1717 |                 masakari.create_failover_segment(self._token, cluster_name, hosts)
     |

hamgr/hamgr/providers/nova.py:1716:89: E501 Line too long (90 > 88)
     |
1714 |                 LOG.info('create masakari masakari segment during handling enabling request, '
1715 |                          'segment id %s, name %s, hosts %s', str(cluster_id), cluster_name, str(hosts))
1716 |                 # masakari failover segment must be created with vmha cluster name, not id
     |                                                                                         ^^ E501
1717 |                 masakari.create_failover_segment(self._token, cluster_name, hosts)
1718 |             self.__perf_meter('masakari.create_segment', time_begin)
     |

hamgr/hamgr/providers/nova.py:1727:89: E501 Line too long (91 > 88)
     |
1725 |                                          constants.HA_STATE_ENABLED)
1726 |             self._notify_status(constants.HA_STATE_ENABLED, "cluster", cluster_id)
1727 |             self.__perf_meter('db_api.update_enable_or_disable_request_status', time_begin)
     |                                                                                         ^^^ E501
1728 |
1729 |             # 5. finally mark the cluster as enabled
     |

hamgr/hamgr/providers/nova.py:1778:89: E501 Line too long (107 > 88)
     |
1776 |                 break
1777 |
1778 |             app_info = self._resmgr_client.fetch_app_details(nodes, self._token['id'], self._bbmaster_host)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
1779 |
1780 |             all_ok = True
     |

hamgr/hamgr/providers/nova.py:1784:24: E712 Avoid equality comparisons to `True`; use `resp.get('converged', False):` for truth checks
     |
1782 |                 resp = app_info.get(node, {})
1783 |                 if resp:
1784 |                     if resp.get('converged', False) == True:
     |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
1785 |                         converged.add(node)
1786 |                         all_ok &= True
     |
     = help: Replace with `resp.get('converged', False)`

hamgr/hamgr/providers/nova.py:1809:89: E501 Line too long (91 > 88)
     |
1807 |             LOG.info('De-authorizing pf9-ha-slave role on node %s', node)
1808 |             start_time = datetime.now()
1809 |             resp = self._resmgr_client.delete_role(node, "pf9-ha-slave", self._token['id'])
     |                                                                                         ^^^ E501
1810 |             # Retry deauth if resmgr throws conflict error for upto 2 minutes
1811 |             while resp.status_code == requests.codes.conflict:
     |

hamgr/hamgr/providers/nova.py:1815:89: E501 Line too long (95 > 88)
     |
1813 |                          'after 5 sec', node)
1814 |                 time.sleep(5)
1815 |                 resp = self._resmgr_client.delete_role(node, "pf9-ha-slave", self._token['id'])
     |                                                                                         ^^^^^^^ E501
1816 |                 if datetime.now() - start_time > timedelta(seconds=self._max_auth_wait_seconds):
1817 |                     break
     |

hamgr/hamgr/providers/nova.py:1816:89: E501 Line too long (96 > 88)
     |
1814 |                 time.sleep(5)
1815 |                 resp = self._resmgr_client.delete_role(node, "pf9-ha-slave", self._token['id'])
1816 |                 if datetime.now() - start_time > timedelta(seconds=self._max_auth_wait_seconds):
     |                                                                                         ^^^^^^^^ E501
1817 |                     break
     |

hamgr/hamgr/providers/nova.py:1820:89: E501 Line too long (90 > 88)
     |
1819 |             if resp.status_code != requests.codes.ok:
1820 |                 LOG.error('De-authorizing pf9-ha-slave role on host %s failed, error: %s',
     |                                                                                         ^^ E501
1821 |                           node, str(resp))
     |

hamgr/hamgr/providers/nova.py:1825:89: E501 Line too long (89 > 88)
     |
1823 |             # Explicitly delete rabbitmq queue for the host being deauthed
1824 |             req_url = 'http://{0}:{1}@{2}:{3}/api/queues/%2f/{4}-{5}' \
1825 |                       .format(self._amqp_user, self._amqp_password, self._amqp_mgmt_host,
     |                                                                                         ^ E501
1826 |                               AMQP_HTTP_PORT, AMQP_HOST_QUEUE_PREFIX, node)
1827 |             resp = requests.delete(req_url)
     |

hamgr/hamgr/providers/nova.py:1828:89: E501 Line too long (93 > 88)
     |
1826 |                               AMQP_HTTP_PORT, AMQP_HOST_QUEUE_PREFIX, node)
1827 |             resp = requests.delete(req_url)
1828 |             if resp.status_code not in (requests.codes.no_content, requests.codes.not_found):
     |                                                                                         ^^^^^ E501
1829 |                 LOG.warning('Failed to delete rabbitmq queue for host %s on role deauth: %s',
1830 |                             node, resp.status_code)
     |

hamgr/hamgr/providers/nova.py:1829:89: E501 Line too long (93 > 88)
     |
1827 |             resp = requests.delete(req_url)
1828 |             if resp.status_code not in (requests.codes.no_content, requests.codes.not_found):
1829 |                 LOG.warning('Failed to delete rabbitmq queue for host %s on role deauth: %s',
     |                                                                                         ^^^^^ E501
1830 |                             node, resp.status_code)
1831 |         return resp
     |

hamgr/hamgr/providers/nova.py:1838:89: E501 Line too long (90 > 88)
     |
1836 |         """Disable HA
1837 |
1838 |         :params availability_zone: Host availability_zone ID on which HA is being disabled
     |                                                                                         ^^ E501
1839 |         :params synchronize: when set to True, function blocks till ha-slave
1840 |                              role is removed from all the hosts
     |

hamgr/hamgr/providers/nova.py:1866:89: E501 Line too long (100 > 88)
     |
1865 |         try:
1866 |             LOG.info('set cluster id %s task state to %s', str(cluster.id), constants.TASK_REMOVING)
     |                                                                                         ^^^^^^^^^^^^ E501
1867 |             db_api.update_cluster_task_state(cluster.id, constants.TASK_REMOVING)
1868 |             # mark the status as 'request-disable' for processing
     |

hamgr/hamgr/providers/nova.py:1869:89: E501 Line too long (107 > 88)
     |
1867 |             db_api.update_cluster_task_state(cluster.id, constants.TASK_REMOVING)
1868 |             # mark the status as 'request-disable' for processing
1869 |             LOG.info('set cluster id %s status to %s', str(cluster.id),constants.HA_STATE_REQUEST_DISABLE )
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
1870 |             db_api.update_request_status(cluster.id, constants.HA_STATE_REQUEST_DISABLE)
1871 |             self._notify_status(constants.HA_STATE_REQUEST_DISABLE, "cluster", cluster.id)
     |

hamgr/hamgr/providers/nova.py:1871:89: E501 Line too long (90 > 88)
     |
1869 |             LOG.info('set cluster id %s status to %s', str(cluster.id),constants.HA_STATE_REQUEST_DISABLE )
1870 |             db_api.update_request_status(cluster.id, constants.HA_STATE_REQUEST_DISABLE)
1871 |             self._notify_status(constants.HA_STATE_REQUEST_DISABLE, "cluster", cluster.id)
     |                                                                                         ^^ E501
1872 |         except Exception as e:
1873 |             LOG.error('unhandled exceptions when disable cluster with name %s : %s ', str_availability_zone, str(e))
     |

hamgr/hamgr/providers/nova.py:1873:89: E501 Line too long (116 > 88)
     |
1871 |             self._notify_status(constants.HA_STATE_REQUEST_DISABLE, "cluster", cluster.id)
1872 |         except Exception as e:
1873 |             LOG.error('unhandled exceptions when disable cluster with name %s : %s ', str_availability_zone, str(e))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1874 |
1875 |     def process_ha_enable_disable_requests(self):
     |

hamgr/hamgr/providers/nova.py:1881:89: E501 Line too long (90 > 88)
     |
1879 |                 return
1880 |             self.ha_status_processing_running = True
1881 |         LOG.debug('HA status processing task starts to run at %s', str(datetime.utcnow()))
     |                                                                                         ^^ E501
1882 |         try:
1883 |             self._token = self._get_v3_token()
     |

hamgr/hamgr/providers/nova.py:1888:89: E501 Line too long (95 > 88)
     |
1886 |                 for request in requests:
1887 |                     if request.status == constants.HA_STATE_REQUEST_ENABLE:
1888 |                         # cleanup before enable request is processed to avoid masakari conflict
     |                                                                                         ^^^^^^^ E501
1889 |                         self._cleanup_vmha_and_masakari()
1890 |                         with self.ha_status_processing_lock:
     |

hamgr/hamgr/providers/nova.py:1895:89: E501 Line too long (109 > 88)
     |
1893 | …                     if not azInfo:
1894 | …                         # azInfo can be null if no AZ is created or 
1895 | …                         #an error connecting to nova-api (invalid token, nova-api not available..etc)
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^ E501
1896 | …                         LOG.info('No AZ created or error getting availability zone info, will retry')
1897 | …                         continue
     |

hamgr/hamgr/providers/nova.py:1896:89: E501 Line too long (109 > 88)
     |
1894 | …                         # azInfo can be null if no AZ is created or 
1895 | …                         #an error connecting to nova-api (invalid token, nova-api not available..etc)
1896 | …                         LOG.info('No AZ created or error getting availability zone info, will retry')
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^ E501
1897 | …                         continue
1898 | …                     az_hosts = []
     |

hamgr/hamgr/providers/nova.py:1905:89: E501 Line too long (138 > 88)
     |
1903 | …                 break
1904 | …         if len(az_hosts) < 2:
1905 | …             LOG.info('less than 2 hosts in availability zone %s waiting till it has >=2 hosts', str_availability_zone)
     |                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1906 | …             continue
1907 | …     self._handle_enable_request(request, hosts=az_hosts)
     |

hamgr/hamgr/providers/nova.py:1910:89: E501 Line too long (90 > 88)
     |
1908 |                     if request.status == constants.HA_STATE_REQUEST_DISABLE:
1909 |                         self._handle_disable_request(request)
1910 |                         # cleanup after disable request is processed to keep things synced
     |                                                                                         ^^ E501
1911 |                         self._cleanup_vmha_and_masakari()
1912 |         finally:
     |

hamgr/hamgr/providers/nova.py:1915:89: E501 Line too long (89 > 88)
     |
1913 |             with self.ha_status_processing_lock:
1914 |                 self.ha_status_processing_running = False
1915 |         LOG.debug('HA status processing task has finished at %s', str(datetime.utcnow()))
     |                                                                                         ^ E501
1916 |
1917 |     def _handle_disable_request(self, request, next_state=constants.TASK_COMPLETED):
     |

hamgr/hamgr/providers/nova.py:1960:89: E501 Line too long (100 > 88)
     |
1958 |                 self._token, cluster_name)
1959 |             if need_to_wait:
1960 |                 LOG.info('Not disabling cluster %s for now, as masakari segment is under recovery, '
     |                                                                                         ^^^^^^^^^^^^ E501
1961 |                          'will retry disabling request later', cluster_name)
1962 |                 return
     |

hamgr/hamgr/providers/nova.py:1964:89: E501 Line too long (106 > 88)
     |
1962 |                 return
1963 |
1964 |             # since the failover segment is not under recovery , so force to reset host maintenance status
     |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
1965 |             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster_name, ignore_status_in_nova=True)
     |

hamgr/hamgr/providers/nova.py:1965:89: E501 Line too long (113 > 88)
     |
1964 |             # since the failover segment is not under recovery , so force to reset host maintenance status
1965 |             self._toggle_masakari_hosts_maintenance_status(segment_name=cluster_name, ignore_status_in_nova=True)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
1966 |
1967 |             # change status from 'request-disable' to 'disabling'
     |

hamgr/hamgr/providers/nova.py:1968:89: E501 Line too long (110 > 88)
     |
1967 |             # change status from 'request-disable' to 'disabling'
1968 |             LOG.info('set cluster id %s task state to %s', str(cluster.id), str(constants.HA_STATE_DISABLING))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
1969 |             db_api.update_request_status(cluster.id, constants.HA_STATE_DISABLING)
1970 |             self._notify_status(constants.HA_STATE_DISABLING, "cluster", cluster.id)
     |

hamgr/hamgr/providers/nova.py:1974:89: E501 Line too long (92 > 88)
     |
1972 |                 LOG.debug('De-authorize roles from hosts and wait for completion')
1973 |                 self._deauth(hosts)
1974 |                 LOG.info('Waiting for role deauth to converge for cluster %s', cluster_name)
     |                                                                                         ^^^^ E501
1975 |                 self._wait_for_role_to_ok_v2(hosts)
1976 |                 LOG.info('De-authorize process complete for availability_zone %s hosts', cluster_name)
     |

hamgr/hamgr/providers/nova.py:1976:89: E501 Line too long (102 > 88)
     |
1974 |                 LOG.info('Waiting for role deauth to converge for cluster %s', cluster_name)
1975 |                 self._wait_for_role_to_ok_v2(hosts)
1976 |                 LOG.info('De-authorize process complete for availability_zone %s hosts', cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^ E501
1977 |             else:
1978 |                 LOG.info('no hosts found in availability_zone for deauth %s', cluster_name)
     |

hamgr/hamgr/providers/nova.py:1978:89: E501 Line too long (91 > 88)
     |
1976 |                 LOG.info('De-authorize process complete for availability_zone %s hosts', cluster_name)
1977 |             else:
1978 |                 LOG.info('no hosts found in availability_zone for deauth %s', cluster_name)
     |                                                                                         ^^^ E501
1979 |             LOG.info('Deleting failover segment %s from masakari', cluster_name)
1980 |             masakari.delete_failover_segment(self._token, cluster_name)
     |

hamgr/hamgr/providers/nova.py:1984:89: E501 Line too long (101 > 88)
     |
1982 |             db_api.update_request_status(cluster.id, constants.HA_STATE_DISABLED)
1983 |             self._notify_status(constants.HA_STATE_DISABLED, "cluster", cluster.id)
1984 |             LOG.info('Successfully processed disable request for availability_zone %s', cluster_name)
     |                                                                                         ^^^^^^^^^^^^^ E501
1985 |         except Exception:
1986 |             if cluster:
     |

hamgr/hamgr/providers/nova.py:1991:89: E501 Line too long (91 > 88)
     |
1989 |                 db_api.update_request_status(cluster.id, constants.HA_STATE_ERROR)
1990 |                 self._notify_status(constants.HA_STATE_ERROR, "cluster", cluster.id)
1991 |                 db_api.update_cluster_task_state(cluster.id, constants.TASK_ERROR_REMOVING)
     |                                                                                         ^^^ E501
1992 |             raise
1993 |         else:
     |

hamgr/hamgr/providers/nova.py:1995:89: E501 Line too long (98 > 88)
     |
1993 |         else:
1994 |             if cluster:
1995 |                 # There are cases where the ha request got failed(intermittent network issue) and 
     |                                                                                         ^^^^^^^^^^ E501
1996 |                 # handle disable request was called. But before setting the cluster as deleted, we must
1997 |                 # check if the cluster exists on resmgr. If yes, then lets not delete it
     |

hamgr/hamgr/providers/nova.py:1996:89: E501 Line too long (103 > 88)
     |
1994 |             if cluster:
1995 |                 # There are cases where the ha request got failed(intermittent network issue) and 
1996 |                 # handle disable request was called. But before setting the cluster as deleted, we must
     |                                                                                         ^^^^^^^^^^^^^^^ E501
1997 |                 # check if the cluster exists on resmgr. If yes, then lets not delete it
1998 |                 if not self.check_vmha_enabled_on_resmgr(cluster.name):
     |

hamgr/hamgr/providers/nova.py:2003:89: E501 Line too long (90 > 88)
     |
2002 |     def put(self, availability_zone, method):
2003 |         LOG.info('process %s request for Availability zone %s', method, availability_zone)
     |                                                                                         ^^ E501
2004 |         if method == 'enable':
2005 |             self._enable(availability_zone)
     |

hamgr/hamgr/providers/nova.py:2015:89: E501 Line too long (91 > 88)
     |
2013 |         for cluster in clusters:
2014 |             availability_zone = cluster.name
2015 |             availability_zone = self._get_availability_zone(nova_client, availability_zone)
     |                                                                                         ^^^ E501
2016 |             if host_id in availability_zone.hosts:
2017 |                 return cluster
     |

hamgr/hamgr/providers/nova.py:2027:89: E501 Line too long (94 > 88)
     |
2025 |         az_hosts = self._get_nova_hosts(self._token['id'], cluster.name)
2026 |         if not az_hosts:
2027 |             LOG.error('Error getting hosts in availability zone %s, will retry', cluster.name)
     |                                                                                         ^^^^^^ E501
2028 |             return
2029 |         current_host_ids = set(az_hosts)
     |

hamgr/hamgr/providers/nova.py:2033:64: F821 Undefined name `availability_zone`
     |
2031 |         try:
2032 |             self._token = self._get_v3_token()
2033 |             nodes = masakari.get_nodes_in_segment(self._token, availability_zone)
     |                                                                ^^^^^^^^^^^^^^^^^ F821
2034 |             db_node_ids = set([node['name'] for node in nodes])
2035 |             for current_host in current_host_ids:
     |

hamgr/hamgr/providers/nova.py:2053:31: F821 Undefined name `availability_zone`
     |
2051 |                             set(self.hosts_down_per_cluster[cluster.id].keys())
2052 |                 # Task state will be managed by this function
2053 |                 self._disable(availability_zone, synchronize=True,
     |                               ^^^^^^^^^^^^^^^^^ F821
2054 |                               next_state=constants.TASK_MIGRATING)
2055 |                 self._enable(availability_zone, hosts=list(host_list),
     |

hamgr/hamgr/providers/nova.py:2055:30: F821 Undefined name `availability_zone`
     |
2053 |                 self._disable(availability_zone, synchronize=True,
2054 |                               next_state=constants.TASK_MIGRATING)
2055 |                 self._enable(availability_zone, hosts=list(host_list),
     |                              ^^^^^^^^^^^^^^^^^ F821
2056 |                              next_state=constants.TASK_MIGRATING)
2057 |                 self.hosts_down_per_cluster.pop(cluster.id)
     |

hamgr/hamgr/providers/nova.py:2106:13: F841 Local variable `nova_client` is assigned to but never used
     |
2104 |         host_name = event_details['host_id']
2105 |         try:
2106 |             nova_client = self._get_nova_client()
     |             ^^^^^^^^^^^ F841
2107 |             self._token = self._get_v3_token()
2108 |             LOG.debug('prepare to write event, host %s, event %s ,  details %s',
     |
     = help: Remove assignment to unused variable `nova_client`

hamgr/hamgr/providers/nova.py:2149:89: E501 Line too long (89 > 88)
     |
2147 |                         # write change event into db
2148 |                         db_api.create_change_event(target_cluster_id,
2149 |                                                    { 'host_id': event_details['host_id'],
     |                                                                                         ^ E501
2150 |                                                      'event': event_details['event'] },
2151 |                                                    event_details['event']['eventId'])
     |

hamgr/hamgr/providers/nova.py:2152:89: E501 Line too long (92 > 88)
     |
2150 |                                                      'event': event_details['event'] },
2151 |                                                    event_details['event']['eventId'])
2152 |                         LOG.info('change event record is created for host %s in cluster %s',
     |                                                                                         ^^^^ E501
2153 |                                  host_name, target_cluster_id)
2154 |                     else:
     |

hamgr/hamgr/providers/nova.py:2156:89: E501 Line too long (101 > 88)
     |
2154 |                     else:
2155 |                         ids = [x.uuid for x in existing_changes]
2156 |                         LOG.warning('ignore reporting change event %s for host %s, as it is already '
     |                                                                                         ^^^^^^^^^^^^^ E501
2157 |                                     'reported within %s seconds : %s', event_type, host_name,
2158 |                                     self._event_report_threshold_seconds, str(ids))
     |

hamgr/hamgr/providers/nova.py:2157:89: E501 Line too long (93 > 88)
     |
2155 |                         ids = [x.uuid for x in existing_changes]
2156 |                         LOG.warning('ignore reporting change event %s for host %s, as it is already '
2157 |                                     'reported within %s seconds : %s', event_type, host_name,
     |                                                                                         ^^^^^ E501
2158 |                                     self._event_report_threshold_seconds, str(ids))
     |

hamgr/hamgr/providers/nova.py:2163:89: E501 Line too long (99 > 88)
     |
2161 |                     # threshold seconds to avoid flooding
2162 |                     end_time = datetime.utcnow()
2163 |                     start_time = end_time - timedelta(seconds=self._event_report_threshold_seconds)
     |                                                                                         ^^^^^^^^^^^ E501
2164 |                     existing_events = db_api.get_processing_events_between_times(
2165 |                         event_type,
     |

hamgr/hamgr/providers/nova.py:2200:89: E501 Line too long (121 > 88)
     |
2198 |                         candidates = self._get_consul_rebalance_candidates(members)
2199 |                         if not candidates:
2200 |                             LOG.warning("No candidates available for role rebalance for cluster %s", target_cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2201 |                         else:
2202 |                             LOG.info('reporting consul rebalance for event type %s happened to host %s',
     |

hamgr/hamgr/providers/nova.py:2202:89: E501 Line too long (104 > 88)
     |
2200 |                             LOG.warning("No candidates available for role rebalance for cluster %s", target_cluster_name)
2201 |                         else:
2202 |                             LOG.info('reporting consul rebalance for event type %s happened to host %s',
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2203 |                                      event_type, host_name)
2204 |                             self._report_consul_rebalance(cluster_name=target_cluster_name,
     |

hamgr/hamgr/providers/nova.py:2211:89: E501 Line too long (97 > 88)
     |
2209 |                     else:
2210 |                         ids = [x.event_uuid for x in existing_events]
2211 |                         LOG.warning('ignore reporting event %s %s for host %s, as it is already '
     |                                                                                         ^^^^^^^^^ E501
2212 |                                  'reported within %s seconds : %s',
2213 |                                  event_type, event_uuid, host_name, self._event_report_threshold_seconds, str(ids))
     |

hamgr/hamgr/providers/nova.py:2213:89: E501 Line too long (115 > 88)
     |
2211 |                         LOG.warning('ignore reporting event %s %s for host %s, as it is already '
2212 |                                  'reported within %s seconds : %s',
2213 |                                  event_type, event_uuid, host_name, self._event_report_threshold_seconds, str(ids))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2214 |                 else:
2215 |                     LOG.warning('ignore reporting event %s for host %s , '
     |

hamgr/hamgr/providers/nova.py:2216:89: E501 Line too long (93 > 88)
     |
2214 |                 else:
2215 |                     LOG.warning('ignore reporting event %s for host %s , '
2216 |                              'as it is not found in any active nova availability_zones : %s',
     |                                                                                         ^^^^^ E501
2217 |                              event_type, host_name, str(event_details))
2218 |             else:
     |

hamgr/hamgr/providers/nova.py:2219:89: E501 Line too long (104 > 88)
     |
2217 |                              event_type, host_name, str(event_details))
2218 |             else:
2219 |                 LOG.warning('ignore reporting event, no active clusters found for event %s for host %s',
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2220 |                          event_type, host_name)
     |

hamgr/hamgr/providers/nova.py:2222:89: E501 Line too long (109 > 88)
     |
2220 |                          event_type, host_name)
2221 |
2222 |             # return True will stop the ha slave to re-send report, when return False, the ha slave will keep
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
2223 |             # sending report until it received True
2224 |             return True
     |

hamgr/hamgr/providers/nova.py:2226:89: E501 Line too long (97 > 88)
     |
2224 |             return True
2225 |         except Exception:
2226 |             LOG.exception('failed to record event of type %s for host %s', event_type, host_name)
     |                                                                                         ^^^^^^^^^ E501
2227 |         return False
     |

hamgr/hamgr/providers/nova.py:2231:89: E501 Line too long (107 > 88)
     |
2229 |     def _get_consul_rebalance_candidates(self, consul_members):
2230 |         members = consul_members
2231 |         # create a consul role rebalance record for this event, the rebalance thread will handle them later
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
2232 |         consul_servers = [x for x in members if x['Tags']['role'] == 'consul']
2233 |         consul_servers_alive = [x for x in consul_servers if x['Status'] == 1]
     |

hamgr/hamgr/providers/nova.py:2259:89: E501 Line too long (94 > 88)
     |
2257 |                 consul_host = consul_servers_alive[i - start]
2258 |                 # only active host can be used for rebalance
2259 |                 if self._is_nova_service_active(consul_host['Name'], self._get_nova_client()):
     |                                                                                         ^^^^^^ E501
2260 |                     candidates.append({'host': consul_host['Name'],
2261 |                                        'old_role': old_role,
     |

hamgr/hamgr/providers/nova.py:2266:89: E501 Line too long (101 > 88)
     |
2264 |         elif len(consul_servers_alive) < constants.SERVER_THRESHOLD:
2265 |             wanted = constants.SERVER_THRESHOLD - len(consul_servers_alive)
2266 |             LOG.info('not enough alive consul role of server, found %s, required %s, wanted %s more',
     |                                                                                         ^^^^^^^^^^^^^ E501
2267 |                      str(len(consul_servers_alive)),
2268 |                      str(constants.SERVER_THRESHOLD),
     |

hamgr/hamgr/providers/nova.py:2295:89: E501 Line too long (110 > 88)
     |
2293 |                         break
2294 |         else:
2295 |             LOG.debug('consul role rebalance is not needed, num of alive consul servers %s meets required %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
2296 |                       str(len(consul_servers_alive)), str(constants.SERVER_THRESHOLD))
2297 |         if candidates:
     |

hamgr/hamgr/providers/nova.py:2298:89: E501 Line too long (99 > 88)
     |
2296 |                       str(len(consul_servers_alive)), str(constants.SERVER_THRESHOLD))
2297 |         if candidates:
2298 |             LOG.info('found consul role rebalance candidates. consul members: %s, candidates : %s',
     |                                                                                         ^^^^^^^^^^^ E501
2299 |                      str(consul_members), str(candidates))
2300 |         return candidates
     |

hamgr/hamgr/providers/nova.py:2302:89: E501 Line too long (114 > 88)
     |
2300 |         return candidates
2301 |
2302 |     def _report_consul_rebalance(self, cluster_name, event_type, candidates, event_uuid=None, consul_report=None):
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2303 |         try:
2304 |             cluster = db_api.get_cluster(str(cluster_name), read_deleted=False, raise_exception=True)
     |

hamgr/hamgr/providers/nova.py:2304:89: E501 Line too long (101 > 88)
     |
2302 |     def _report_consul_rebalance(self, cluster_name, event_type, candidates, event_uuid=None, consul_report=None):
2303 |         try:
2304 |             cluster = db_api.get_cluster(str(cluster_name), read_deleted=False, raise_exception=True)
     |                                                                                         ^^^^^^^^^^^^^ E501
2305 |             if not candidates or (cluster.status != constants.HA_STATE_ENABLED):
2306 |                 LOG.debug('cluster %s: no rebalance candidates or no need to rebalance', cluster_name)
     |

hamgr/hamgr/providers/nova.py:2306:89: E501 Line too long (102 > 88)
     |
2304 |             cluster = db_api.get_cluster(str(cluster_name), read_deleted=False, raise_exception=True)
2305 |             if not candidates or (cluster.status != constants.HA_STATE_ENABLED):
2306 |                 LOG.debug('cluster %s: no rebalance candidates or no need to rebalance', cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^ E501
2307 |                 return
     |

hamgr/hamgr/providers/nova.py:2310:89: E501 Line too long (97 > 88)
     |
2309 |             LOG.info('report consul rebalance with candidates : %s', str(candidates))
2310 |             # create rebalance request for each target hosts, they should be processed one by one
     |                                                                                         ^^^^^^^^^ E501
2311 |             for candidate in candidates:
2312 |                 host_id = candidate['host']
     |

hamgr/hamgr/providers/nova.py:2318:89: E501 Line too long (96 > 88)
     |
2316 |                                     'new_role': candidate['new_role']
2317 |                                     }
2318 |                 existing_actions = db_api.get_unhandled_consul_role_rebalance_records_by_action(
     |                                                                                         ^^^^^^^^ E501
2319 |                     json.dumps(rebalance_action))
2320 |                 # if for the same host, there are unhandled requests(either server to slave, or slave to server)
     |

hamgr/hamgr/providers/nova.py:2320:89: E501 Line too long (112 > 88)
     |
2318 |                 existing_actions = db_api.get_unhandled_consul_role_rebalance_records_by_action(
2319 |                     json.dumps(rebalance_action))
2320 |                 # if for the same host, there are unhandled requests(either server to slave, or slave to server)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2321 |                 # that's means consecutive host events happened , so only need to create rebalance request
2322 |                 # base on the most recent consul status
     |

hamgr/hamgr/providers/nova.py:2321:89: E501 Line too long (106 > 88)
     |
2319 |                     json.dumps(rebalance_action))
2320 |                 # if for the same host, there are unhandled requests(either server to slave, or slave to server)
2321 |                 # that's means consecutive host events happened , so only need to create rebalance request
     |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
2322 |                 # base on the most recent consul status
2323 |                 if existing_actions and len(existing_actions) > 0:
     |

hamgr/hamgr/providers/nova.py:2326:89: E501 Line too long (112 > 88)
     |
2324 |                     # mark all old unhandled existing request as cancelled
2325 |                     for old_req in existing_actions:
2326 |                         error = 'newer change %s required for host %s' % (json.dumps(rebalance_action), host_id)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2327 |                         LOG.info('cancel unhandled consul role rebalance request %s (%s), as %s',
2328 |                                  old_req.uuid,
     |

hamgr/hamgr/providers/nova.py:2327:89: E501 Line too long (97 > 88)
     |
2325 |                     for old_req in existing_actions:
2326 |                         error = 'newer change %s required for host %s' % (json.dumps(rebalance_action), host_id)
2327 |                         LOG.info('cancel unhandled consul role rebalance request %s (%s), as %s',
     |                                                                                         ^^^^^^^^^ E501
2328 |                                  old_req.uuid,
2329 |                                  old_req.rebalance_action,
     |

hamgr/hamgr/providers/nova.py:2338:89: E501 Line too long (118 > 88)
     |
2336 |                 # check nova again to make sure the candidate host is still active
2337 |                 if not self._is_nova_service_active(host_id, self._get_nova_client()):
2338 |                     LOG.warning('host %s is not active in nova, ignore it for consul role rebalance request', host_id)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2339 |                 else:
2340 |                     LOG.info('create consul role rebalance request for host %s : %s', host_id, str(rebalance_action))
     |

hamgr/hamgr/providers/nova.py:2340:89: E501 Line too long (117 > 88)
     |
2338 |                     LOG.warning('host %s is not active in nova, ignore it for consul role rebalance request', host_id)
2339 |                 else:
2340 |                     LOG.info('create consul role rebalance request for host %s : %s', host_id, str(rebalance_action))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2341 |                     db_api.add_consul_role_rebalance_record(event_type,
2342 |                                                             event_uuid,
     |

hamgr/hamgr/providers/nova.py:2343:89: E501 Line too long (113 > 88)
     |
2341 |                     db_api.add_consul_role_rebalance_record(event_type,
2342 |                                                             event_uuid,
2343 |                                                             json.dumps(consul_report) if consul_report else None,
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2344 |                                                             json.dumps(rebalance_action),
2345 |                                                             str(uuid4()))
     |

hamgr/hamgr/providers/nova.py:2346:89: E501 Line too long (94 > 88)
     |
2344 |                                                             json.dumps(rebalance_action),
2345 |                                                             str(uuid4()))
2346 |                     #TODO: check there is no rebalance action for another host in same segment
     |                                                                                         ^^^^^^ E501
2347 |         except:
2348 |             LOG.exception('unhandled exception during reporting consul rebalance')
     |

hamgr/hamgr/providers/nova.py:2347:9: E722 Do not use bare `except`
     |
2345 |                                                             str(uuid4()))
2346 |                     #TODO: check there is no rebalance action for another host in same segment
2347 |         except:
     |         ^^^^^^ E722
2348 |             LOG.exception('unhandled exception during reporting consul rebalance')
     |

hamgr/hamgr/providers/nova.py:2363:89: E501 Line too long (100 > 88)
     |
2361 |             if not isinstance(cluster_id_or_name, str) and \
2362 |                     not isinstance(cluster_id_or_name, int):
2363 |                 LOG.info('cluster_id_or_name %s can only be string or int', str(cluster_id_or_name))
     |                                                                                         ^^^^^^^^^^^^ E501
2364 |                 return None
     |

hamgr/hamgr/providers/nova.py:2370:89: E501 Line too long (97 > 88)
     |
2368 |             targets = []
2369 |             if isinstance(cluster_id_or_name, str):
2370 |                 targets = [cluster for cluster in clusters if cluster.name == cluster_id_or_name]
     |                                                                                         ^^^^^^^^^ E501
2371 |             elif isinstance(cluster_id_or_name, int):
2372 |                 targets = [cluster for cluster in clusters if cluster.id == cluster_id_or_name]
     |

hamgr/hamgr/providers/nova.py:2372:89: E501 Line too long (95 > 88)
     |
2370 |                 targets = [cluster for cluster in clusters if cluster.name == cluster_id_or_name]
2371 |             elif isinstance(cluster_id_or_name, int):
2372 |                 targets = [cluster for cluster in clusters if cluster.id == cluster_id_or_name]
     |                                                                                         ^^^^^^^ E501
2373 |
2374 |             if len(targets) > 0:
     |

hamgr/hamgr/providers/nova.py:2376:89: E501 Line too long (95 > 88)
     |
2374 |             if len(targets) > 0:
2375 |                 availability_zone = targets[0].name
2376 |                 availability_zone = self._get_availability_zone(nova_client, availability_zone)
     |                                                                                         ^^^^^^^ E501
2377 |                 LOG.debug('host availability_zone details for cluster %s : %s',
2378 |                           str(cluster_id_or_name), str(availability_zone))
     |

hamgr/hamgr/providers/nova.py:2381:9: E722 Do not use bare `except`
     |
2379 |                 return availability_zone
2380 |             return None
2381 |         except:
     |         ^^^^^^ E722
2382 |             LOG.exception('unhandled exception when get availability_zone info '
2383 |                           'for cluster %s', str(cluster_id_or_name))
     |

hamgr/hamgr/providers/nova.py:2393:89: E501 Line too long (102 > 88)
     |
2391 |                 return
2392 |             self.consul_role_rebalance_processing_running = True
2393 |         LOG.debug('consul role rebalance processing task start to work at %s', str(datetime.utcnow()))
     |                                                                                         ^^^^^^^^^^^^^^ E501
2394 |
2395 |         req_id = None
     |

hamgr/hamgr/providers/nova.py:2403:89: E501 Line too long (90 > 88)
     |
2401 |             # wait for response from host to update the record
2402 |             # ----------------------------------------------------------------
2403 |             unhandled_requests = db_api.get_all_unhandled_consul_role_rebalance_requests()
     |                                                                                         ^^ E501
2404 |             if not unhandled_requests:
2405 |                 # when there are no unhandled consul role rebalance requests, try to detect whether
     |

hamgr/hamgr/providers/nova.py:2405:89: E501 Line too long (99 > 88)
     |
2403 |             unhandled_requests = db_api.get_all_unhandled_consul_role_rebalance_requests()
2404 |             if not unhandled_requests:
2405 |                 # when there are no unhandled consul role rebalance requests, try to detect whether
     |                                                                                         ^^^^^^^^^^^ E501
2406 |                 # there is a need to generate the role rebalance request to correct any over rebalanced
2407 |                 # scenarios (issue found from ticket https://platform9.zendesk.com/agent/tickets/1252718)
     |

hamgr/hamgr/providers/nova.py:2406:89: E501 Line too long (103 > 88)
     |
2404 |             if not unhandled_requests:
2405 |                 # when there are no unhandled consul role rebalance requests, try to detect whether
2406 |                 # there is a need to generate the role rebalance request to correct any over rebalanced
     |                                                                                         ^^^^^^^^^^^^^^^ E501
2407 |                 # scenarios (issue found from ticket https://platform9.zendesk.com/agent/tickets/1252718)
2408 |                 self._token = self._get_v3_token()
     |

hamgr/hamgr/providers/nova.py:2416:89: E501 Line too long (96 > 88)
     |
2414 |                 for az in azInfo['availabilityZoneInfo']:
2415 |                     az_name = az['zoneName']
2416 |                     hamgr_clusters_for_az = [x for x in hamgr_all_clusters if x.name == az_name]
     |                                                                                         ^^^^^^^^ E501
2417 |                     if len(hamgr_clusters_for_az) < 1:
2418 |                         continue
     |

hamgr/hamgr/providers/nova.py:2424:89: E501 Line too long (113 > 88)
     |
2422 |                     if not cluster_enabled:
2423 |                         continue
2424 |                     LOG.debug('check whether need to rebalance consul roles for consul cluster %s', cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2425 |                     self._rebalance_consul_roles_if_needed(cluster_name=cluster_name,
2426 |                                                            event_type=constants.EVENT_CONSUL_INSPECT)
     |

hamgr/hamgr/providers/nova.py:2433:89: E501 Line too long (105 > 88)
     |
2431 |                 LOG.info('processing consul role rebalance request %s for event %s: %s',
2432 |                          req.uuid, str(req.event_uuid), str(req.rebalance_action))
2433 |                 # first check by time, abort request if timestamp shows the request older than 15 minutes
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2434 |                 if (datetime.utcnow() - req.last_updated) > timedelta(minutes=15):
2435 |                     error = 'request created at %s is stale' % req.last_updated
     |

hamgr/hamgr/providers/nova.py:2436:89: E501 Line too long (101 > 88)
     |
2434 |                 if (datetime.utcnow() - req.last_updated) > timedelta(minutes=15):
2435 |                     error = 'request created at %s is stale' % req.last_updated
2436 |                     LOG.warning('ignore consul role rebalance request %s, as %s', str(req_id), error)
     |                                                                                         ^^^^^^^^^^^^^ E501
2437 |                     db_api.update_consul_role_rebalance(req.uuid,
2438 |                                                         None,
     |

hamgr/hamgr/providers/nova.py:2443:89: E501 Line too long (120 > 88)
     |
2441 |                                                         error)
2442 |                     continue
2443 |                 # then check by status, query the same request again to get most recent status (in case it is canceled )
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2444 |                 same_req = db_api.get_consul_role_balance_record_by_uuid(req.uuid)
2445 |                 if same_req is None or same_req.action_status == constants.RPC_TASK_STATE_ABORTED:
     |

hamgr/hamgr/providers/nova.py:2445:89: E501 Line too long (98 > 88)
     |
2443 |                 # then check by status, query the same request again to get most recent status (in case it is canceled )
2444 |                 same_req = db_api.get_consul_role_balance_record_by_uuid(req.uuid)
2445 |                 if same_req is None or same_req.action_status == constants.RPC_TASK_STATE_ABORTED:
     |                                                                                         ^^^^^^^^^^ E501
2446 |                     LOG.warning('ignore consul role rebalance request %s, as it was already in state %s',
2447 |                              req.uuid,
     |

hamgr/hamgr/providers/nova.py:2446:89: E501 Line too long (105 > 88)
     |
2444 |                 same_req = db_api.get_consul_role_balance_record_by_uuid(req.uuid)
2445 |                 if same_req is None or same_req.action_status == constants.RPC_TASK_STATE_ABORTED:
2446 |                     LOG.warning('ignore consul role rebalance request %s, as it was already in state %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2447 |                              req.uuid,
2448 |                              req.action_status)
     |

hamgr/hamgr/providers/nova.py:2462:89: E501 Line too long (100 > 88)
     |
2460 |                 if event_type not in constants.HOST_EVENTS:
2461 |                     error = 'invalid event type %s' % event_type
2462 |                     LOG.warning('ignore consul role rebalance request %s, as %s', event_uuid, error)
     |                                                                                         ^^^^^^^^^^^^ E501
2463 |                     db_api.update_consul_role_rebalance(req.uuid,
2464 |                                                         None,
     |

hamgr/hamgr/providers/nova.py:2470:89: E501 Line too long (109 > 88)
     |
2468 |                     continue
2469 |
2470 |                 # if the event type is host-up or host-down, then there is an such event reported by ha-slave
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
2471 |                 # in this scenario, need to sync with the event to see whether the event is finished or not
2472 |                 if event_type in [constants.EVENT_HOST_UP, constants.EVENT_HOST_DOWN]:
     |

hamgr/hamgr/providers/nova.py:2471:89: E501 Line too long (107 > 88)
     |
2470 |                 # if the event type is host-up or host-down, then there is an such event reported by ha-slave
2471 |                 # in this scenario, need to sync with the event to see whether the event is finished or not
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
2472 |                 if event_type in [constants.EVENT_HOST_UP, constants.EVENT_HOST_DOWN]:
2473 |                     if not event_uuid:
     |

hamgr/hamgr/providers/nova.py:2474:89: E501 Line too long (91 > 88)
     |
2472 |                 if event_type in [constants.EVENT_HOST_UP, constants.EVENT_HOST_DOWN]:
2473 |                     if not event_uuid:
2474 |                         error = 'no valid event uuid for this event type : %s' % event_type
     |                                                                                         ^^^ E501
2475 |                         LOG.warning('ignore consul role rebalance request %s, as %s', event_uuid, error)
2476 |                         db_api.update_consul_role_rebalance(req.uuid,
     |

hamgr/hamgr/providers/nova.py:2475:89: E501 Line too long (104 > 88)
     |
2473 |                     if not event_uuid:
2474 |                         error = 'no valid event uuid for this event type : %s' % event_type
2475 |                         LOG.warning('ignore consul role rebalance request %s, as %s', event_uuid, error)
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2476 |                         db_api.update_consul_role_rebalance(req.uuid,
2477 |                                                             None,
     |

hamgr/hamgr/providers/nova.py:2486:89: E501 Line too long (90 > 88)
     |
2484 |                     if not host_event:
2485 |                         # no such event, so abort this request
2486 |                         error = 'no matched host event %s (%s)' % (event_uuid, event_type)
     |                                                                                         ^^ E501
2487 |                         LOG.warning('ignore consul role rebalance request %s, as %s', event_uuid, error)
2488 |                         db_api.update_consul_role_rebalance(req.uuid,
     |

hamgr/hamgr/providers/nova.py:2487:89: E501 Line too long (104 > 88)
     |
2485 |                         # no such event, so abort this request
2486 |                         error = 'no matched host event %s (%s)' % (event_uuid, event_type)
2487 |                         LOG.warning('ignore consul role rebalance request %s, as %s', event_uuid, error)
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2488 |                         db_api.update_consul_role_rebalance(req.uuid,
2489 |                                                             None,
     |

hamgr/hamgr/providers/nova.py:2498:89: E501 Line too long (91 > 88)
     |
2496 |                     event_status = host_event.notification_status
2497 |                     # masakari notification status can be :
2498 |                     # "new", "running", "error", "failed", "ignored", "finished", "aborted"
     |                                                                                         ^^^ E501
2499 |                     #  will retry when the host event has not been processed
2500 |                     if not event_status or event_status in ['new', 'running']:
     |

hamgr/hamgr/providers/nova.py:2501:89: E501 Line too long (110 > 88)
     |
2499 |                     #  will retry when the host event has not been processed
2500 |                     if not event_status or event_status in ['new', 'running']:
2501 |                         # since the host event has not been handled, can not do rebalance, so keep the request
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
2502 |                         LOG.info('will retry consul role rebalance request, as associated host event %s (%s) has not '
2503 |                                  'been processed yet, current status: %s',
     |

hamgr/hamgr/providers/nova.py:2502:89: E501 Line too long (118 > 88)
     |
2500 |                     if not event_status or event_status in ['new', 'running']:
2501 |                         # since the host event has not been handled, can not do rebalance, so keep the request
2502 |                         LOG.info('will retry consul role rebalance request, as associated host event %s (%s) has not '
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2503 |                                  'been processed yet, current status: %s',
2504 |                                  event_uuid,
     |

hamgr/hamgr/providers/nova.py:2513:89: E501 Line too long (91 > 88)
     |
2511 |                         error = "associated host event %s (%s) was in %s status" % (
2512 |                             event_uuid, event_type, event_status)
2513 |                         LOG.warning('abort consul role rebalance request as the %s', error)
     |                                                                                         ^^^ E501
2514 |                         db_api.update_consul_role_rebalance(req.uuid,
2515 |                                                             None,
     |

hamgr/hamgr/providers/nova.py:2522:89: E501 Line too long (103 > 88)
     |
2521 |                     if event_status != constants.STATE_FINISHED:
2522 |                         error = "unexpected status for host event %s : %s" % (event_uuid, event_status)
     |                                                                                         ^^^^^^^^^^^^^^^ E501
2523 |                         LOG.warning('ignore consul role rebalance request %s (%s), as %s',
2524 |                                  host_event.event_uuid,
     |

hamgr/hamgr/providers/nova.py:2523:89: E501 Line too long (90 > 88)
     |
2521 |                     if event_status != constants.STATE_FINISHED:
2522 |                         error = "unexpected status for host event %s : %s" % (event_uuid, event_status)
2523 |                         LOG.warning('ignore consul role rebalance request %s (%s), as %s',
     |                                                                                         ^^ E501
2524 |                                  host_event.event_uuid,
2525 |                                  host_event.event_type,
     |

hamgr/hamgr/providers/nova.py:2535:89: E501 Line too long (93 > 88)
     |
2534 |                     # to avoid to send request to a dead host, need to check with nova
2535 |                     # is the target host still alive since the original request was created ?
     |                                                                                         ^^^^^ E501
2536 |                     if not self._is_nova_service_active(target_host_id):
2537 |                         error = 'host %s is inactive ' % target_host_id
     |

hamgr/hamgr/providers/nova.py:2548:89: E501 Line too long (99 > 88)
     |
2546 |                         continue
2547 |
2548 |                 # the associated host event has been finished, it is ok to start to rebalance roles
     |                                                                                         ^^^^^^^^^^^ E501
2549 |                 LOG.info('start to process consul role rebalance request %s for event %s with type %s',
2550 |                          str(req.uuid), event_uuid, event_type)
     |

hamgr/hamgr/providers/nova.py:2549:89: E501 Line too long (103 > 88)
     |
2548 |                 # the associated host event has been finished, it is ok to start to rebalance roles
2549 |                 LOG.info('start to process consul role rebalance request %s for event %s with type %s',
     |                                                                                         ^^^^^^^^^^^^^^^ E501
2550 |                          str(req.uuid), event_uuid, event_type)
     |

hamgr/hamgr/providers/nova.py:2561:89: E501 Line too long (106 > 88)
     |
2560 |                 if req.before_rebalance:
2561 |                     LOG.debug('get consul settings from before_rebalance : %s', str(req.before_rebalance))
     |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
2562 |                     consul_status_before = json.loads(req.before_rebalance)
2563 |                     consul_addresses = [x['Addr'] for x in consul_status_before['members']]
     |

hamgr/hamgr/providers/nova.py:2563:89: E501 Line too long (91 > 88)
     |
2561 |                     LOG.debug('get consul settings from before_rebalance : %s', str(req.before_rebalance))
2562 |                     consul_status_before = json.loads(req.before_rebalance)
2563 |                     consul_addresses = [x['Addr'] for x in consul_status_before['members']]
     |                                                                                         ^^^ E501
2564 |                     target_consuls = [x for x in consul_status_before['members'] if x['Name'] == target_host_id]
2565 |                     if len(target_consuls) != 1:
     |

hamgr/hamgr/providers/nova.py:2564:89: E501 Line too long (112 > 88)
     |
2562 |                     consul_status_before = json.loads(req.before_rebalance)
2563 |                     consul_addresses = [x['Addr'] for x in consul_status_before['members']]
2564 |                     target_consuls = [x for x in consul_status_before['members'] if x['Name'] == target_host_id]
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2565 |                     if len(target_consuls) != 1:
2566 |                         error = 'no consul status for target host %s' % target_host_id
     |

hamgr/hamgr/providers/nova.py:2567:89: E501 Line too long (102 > 88)
     |
2565 |                     if len(target_consuls) != 1:
2566 |                         error = 'no consul status for target host %s' % target_host_id
2567 |                         LOG.warning('ignore consul role rebalance request %s, as %s', req.uuid, error)
     |                                                                                         ^^^^^^^^^^^^^^ E501
2568 |                         db_api.update_consul_role_rebalance(req.uuid,
2569 |                                                             None,
     |

hamgr/hamgr/providers/nova.py:2588:89: E501 Line too long (91 > 88)
     |
2586 |                                                                id=str(req.uuid))
2587 |
2588 |                 LOG.info('run consul role rebalance request %s with ip %s to join %s : %s',
     |                                                                                         ^^^ E501
2589 |                          req.uuid, cluster_ip, join_ips, str(rebalance_request))
2590 |                 rebalance_result = self._execute_consul_role_rebalance(rebalance_request, cluster_name, cluster_ip,
     |

hamgr/hamgr/providers/nova.py:2590:89: E501 Line too long (115 > 88)
     |
2588 |                 LOG.info('run consul role rebalance request %s with ip %s to join %s : %s',
2589 |                          req.uuid, cluster_ip, join_ips, str(rebalance_request))
2590 |                 rebalance_result = self._execute_consul_role_rebalance(rebalance_request, cluster_name, cluster_ip,
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2591 |                                                                        join_ips)
2592 |                 LOG.info('result of consul role rebalance request %s : %s',
     |

hamgr/hamgr/providers/nova.py:2604:89: E501 Line too long (101 > 88)
     |
2602 |         except Exception as ex:
2603 |             error = 'exception : %s' % str(ex)
2604 |             LOG.exception('unhandled exception in process_consul_role_rebalance_requests, %s', error)
     |                                                                                         ^^^^^^^^^^^^^ E501
2605 |             if req_id:
2606 |                 db_api.update_consul_role_rebalance(req_id,
     |

hamgr/hamgr/providers/nova.py:2615:89: E501 Line too long (100 > 88)
     |
2613 |             with self.consul_role_rebalance_processing_lock:
2614 |                 self.consul_role_rebalance_processing_running = False
2615 |         LOG.info('consul role rebalance processing task has finished at %s', str(datetime.utcnow()))
     |                                                                                         ^^^^^^^^^^^^ E501
2616 |
2617 |     def process_consul_encryption_configuration(self):
     |

hamgr/hamgr/providers/nova.py:2620:89: E501 Line too long (95 > 88)
     |
2618 |         with self.consul_encryption_processing_lock:
2619 |             if self.consul_encryption_processing_running:
2620 |                 LOG.debug('consul encryption configuration processing task is already running')
     |                                                                                         ^^^^^^^ E501
2621 |                 return
2622 |             self.consul_encryption_processing_running = True
     |

hamgr/hamgr/providers/nova.py:2624:89: E501 Line too long (112 > 88)
     |
2622 |             self.consul_encryption_processing_running = True
2623 |
2624 |         LOG.debug('consul encryption configuration processing task start to work at %s', str(datetime.utcnow()))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2625 |         try:
2626 |             if not self._is_consul_encryption_enabled():
     |

hamgr/hamgr/providers/nova.py:2645:89: E501 Line too long (119 > 88)
     |
2643 |                 LOG.debug('get_all_active_clusters return none')
2644 |                 return
2645 |             LOG.info('checking certs for %s active clusters : %s', str(len(clusters)), str([x.name for x in clusters]))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2646 |             for cluster in clusters:
2647 |                 cluster_name = cluster.name
     |

hamgr/hamgr/providers/nova.py:2649:89: E501 Line too long (105 > 88)
     |
2647 |                 cluster_name = cluster.name
2648 |                 svc_changed = False
2649 |                 # for ha enabled cluster, when svc key and cert not exist , or expired, then refresh them
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2650 |                 if not keyhelper.are_consul_svc_key_cert_pair_exist(cluster_name) or \
2651 |                         keyhelper.is_consul_svc_cert_expired(cluster_name) or \
     |

hamgr/hamgr/providers/nova.py:2653:89: E501 Line too long (90 > 88)
     |
2651 |                         keyhelper.is_consul_svc_cert_expired(cluster_name) or \
2652 |                         ca_changed:
2653 |                     svc_changed = keyhelper.create_consul_svc_key_cert_pairs(cluster_name)
     |                                                                                         ^^ E501
2654 |                     LOG.info('expired svc key and cert for cluster %s are refreshed ? %s', cluster_name,
2655 |                              str(svc_changed))
     |

hamgr/hamgr/providers/nova.py:2654:89: E501 Line too long (104 > 88)
     |
2652 |                         ca_changed:
2653 |                     svc_changed = keyhelper.create_consul_svc_key_cert_pairs(cluster_name)
2654 |                     LOG.info('expired svc key and cert for cluster %s are refreshed ? %s', cluster_name,
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2655 |                              str(svc_changed))
2656 |                 else:
     |

hamgr/hamgr/providers/nova.py:2657:89: E501 Line too long (95 > 88)
     |
2655 |                              str(svc_changed))
2656 |                 else:
2657 |                     LOG.debug('svc key and cert for cluster %s are good for now', cluster_name)
     |                                                                                         ^^^^^^^ E501
2658 |
2659 |                 # get hosts ids from masakari for current cluster
     |

hamgr/hamgr/providers/nova.py:2665:89: E501 Line too long (97 > 88)
     |
2663 |                           str(len(host_ids)), cluster_name, str(host_ids))
2664 |                 hypervisors = nova_client.hypervisors.list()
2665 |                 hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
     |                                                                                         ^^^^^^^^^ E501
2666 |                 LOG.debug('Details for hosts %s : %s', str(host_ids), str(hosts_info))
2667 |                 ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |

hamgr/hamgr/providers/nova.py:2667:89: E501 Line too long (101 > 88)
     |
2665 |                 hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
2666 |                 LOG.debug('Details for hosts %s : %s', str(host_ids), str(hosts_info))
2667 |                 ip_lookup, cluster_ip_lookup, nodes_details = self._get_ips_for_hosts_v2(hypervisors,
     |                                                                                         ^^^^^^^^^^^^^ E501
2668 |                                                                                          host_ids,
2669 |                                                                                          hosts_info)
     |

hamgr/hamgr/providers/nova.py:2677:89: E501 Line too long (112 > 88)
     |
2675 |                         self._token = self._get_v3_token()
2676 |                         # get the target host info to make sure the role status is ok
2677 |                         resp_role = hosts_info.get(host_id, {}).get('role_settings', {}).get("pf9-ha-slave", {})
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2678 |                         if not resp_role:
2679 |                             LOG.warning('empty settings for role pf9-ha-slave for host %s : %s', str(host_id), str(resp_role))
     |

hamgr/hamgr/providers/nova.py:2679:89: E501 Line too long (126 > 88)
     |
2677 |                         resp_role = hosts_info.get(host_id, {}).get('role_settings', {}).get("pf9-ha-slave", {})
2678 |                         if not resp_role:
2679 |                             LOG.warning('empty settings for role pf9-ha-slave for host %s : %s', str(host_id), str(resp_role))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2680 |                             continue
2681 |                         LOG.debug('pf9-ha-slave role settings for host %s : %s', host_id, str(resp_role))
     |

hamgr/hamgr/providers/nova.py:2681:89: E501 Line too long (105 > 88)
     |
2679 |                             LOG.warning('empty settings for role pf9-ha-slave for host %s : %s', str(host_id), str(resp_role))
2680 |                             continue
2681 |                         LOG.debug('pf9-ha-slave role settings for host %s : %s', host_id, str(resp_role))
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2682 |
2683 |                         # issue was found in https://platform9.atlassian.net/browse/IAAS-9826
     |

hamgr/hamgr/providers/nova.py:2684:89: E501 Line too long (95 > 88)
     |
2683 |                         # issue was found in https://platform9.atlassian.net/browse/IAAS-9826
2684 |                         # where after upgraded to 3.9 to 3.10, the ca and svc certs are created
     |                                                                                         ^^^^^^^ E501
2685 |                         # but calls to nova and resmgr failed after the cert creation, the old code
2686 |                         # only upgrade resmgr one time, so even though on du certs are not change, but
     |

hamgr/hamgr/providers/nova.py:2685:89: E501 Line too long (99 > 88)
     |
2683 |                         # issue was found in https://platform9.atlassian.net/browse/IAAS-9826
2684 |                         # where after upgraded to 3.9 to 3.10, the ca and svc certs are created
2685 |                         # but calls to nova and resmgr failed after the cert creation, the old code
     |                                                                                         ^^^^^^^^^^^ E501
2686 |                         # only upgrade resmgr one time, so even though on du certs are not change, but
2687 |                         # hosts won't get them.
     |

hamgr/hamgr/providers/nova.py:2686:89: E501 Line too long (102 > 88)
     |
2684 |                         # where after upgraded to 3.9 to 3.10, the ca and svc certs are created
2685 |                         # but calls to nova and resmgr failed after the cert creation, the old code
2686 |                         # only upgrade resmgr one time, so even though on du certs are not change, but
     |                                                                                         ^^^^^^^^^^^^^^ E501
2687 |                         # hosts won't get them.
2688 |                         # this fix will always compare certs on du with what hosts have, if they don't
     |

hamgr/hamgr/providers/nova.py:2688:89: E501 Line too long (102 > 88)
     |
2686 |                         # only upgrade resmgr one time, so even though on du certs are not change, but
2687 |                         # hosts won't get them.
2688 |                         # this fix will always compare certs on du with what hosts have, if they don't
     |                                                                                         ^^^^^^^^^^^^^^ E501
2689 |                         # match, will always try to update them
2690 |                         gossip_key = keyhelper.get_consul_gossip_encryption_key(cluster_name=str(cluster_name),
     |

hamgr/hamgr/providers/nova.py:2690:89: E501 Line too long (111 > 88)
     |
2688 |                         # this fix will always compare certs on du with what hosts have, if they don't
2689 |                         # match, will always try to update them
2690 |                         gossip_key = keyhelper.get_consul_gossip_encryption_key(cluster_name=str(cluster_name),
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
2691 |                                                                                 seed=self._db_pwd)
2692 |                         _, ca_cert_content = keyhelper.read_consul_ca_key_cert_pair()
     |

hamgr/hamgr/providers/nova.py:2693:89: E501 Line too long (113 > 88)
     |
2691 |                                                                                 seed=self._db_pwd)
2692 |                         _, ca_cert_content = keyhelper.read_consul_ca_key_cert_pair()
2693 |                         svc_key_content, svc_cert_content = keyhelper.read_consul_svc_key_cert_pair(cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2694 |
2695 |                         existing_encrypt = resp_role.get('encrypt', "")
     |

hamgr/hamgr/providers/nova.py:2697:89: E501 Line too long (89 > 88)
     |
2695 |                         existing_encrypt = resp_role.get('encrypt', "")
2696 |                         need_refresh = (existing_encrypt != gossip_key)
2697 |                         existing_key_file_content = resp_role.get('key_file_content', "")
     |                                                                                         ^ E501
2698 |                         need_refresh |= (existing_key_file_content != svc_key_content)
2699 |                         existing_cert_file_content = resp_role.get('cert_file_content', "")
     |

hamgr/hamgr/providers/nova.py:2699:89: E501 Line too long (91 > 88)
     |
2697 |                         existing_key_file_content = resp_role.get('key_file_content', "")
2698 |                         need_refresh |= (existing_key_file_content != svc_key_content)
2699 |                         existing_cert_file_content = resp_role.get('cert_file_content', "")
     |                                                                                         ^^^ E501
2700 |                         need_refresh |= (existing_cert_file_content != svc_cert_content)
2701 |                         existing_ca_file_content = resp_role.get('ca_file_content', "")
     |

hamgr/hamgr/providers/nova.py:2705:89: E501 Line too long (105 > 88)
     |
2704 |                         if need_refresh:
2705 |                             LOG.info('gossip key for host %s in availability_zone %s needs refresh ? %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2706 |                                      host_id, cluster_name, str(existing_encrypt != gossip_key))
2707 |                             LOG.info('svc key for host %s in availability_zone %s needs refresh ? %s',
     |

hamgr/hamgr/providers/nova.py:2706:89: E501 Line too long (96 > 88)
     |
2704 |                         if need_refresh:
2705 |                             LOG.info('gossip key for host %s in availability_zone %s needs refresh ? %s',
2706 |                                      host_id, cluster_name, str(existing_encrypt != gossip_key))
     |                                                                                         ^^^^^^^^ E501
2707 |                             LOG.info('svc key for host %s in availability_zone %s needs refresh ? %s',
2708 |                                      host_id, cluster_name, str(existing_key_file_content != svc_key_content))
     |

hamgr/hamgr/providers/nova.py:2707:89: E501 Line too long (102 > 88)
     |
2705 | …                     LOG.info('gossip key for host %s in availability_zone %s needs refresh ? %s',
2706 | …                              host_id, cluster_name, str(existing_encrypt != gossip_key))
2707 | …                     LOG.info('svc key for host %s in availability_zone %s needs refresh ? %s',
     |                                                                                   ^^^^^^^^^^^^^^ E501
2708 | …                              host_id, cluster_name, str(existing_key_file_content != svc_key_content))
2709 | …                     LOG.info('svc cert for host %s in availability_zone %s needs refresh ? %s',
     |

hamgr/hamgr/providers/nova.py:2708:89: E501 Line too long (110 > 88)
     |
2706 | …                              host_id, cluster_name, str(existing_encrypt != gossip_key))
2707 | …                     LOG.info('svc key for host %s in availability_zone %s needs refresh ? %s',
2708 | …                              host_id, cluster_name, str(existing_key_file_content != svc_key_content))
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^ E501
2709 | …                     LOG.info('svc cert for host %s in availability_zone %s needs refresh ? %s',
2710 | …                              host_id, cluster_name, str(existing_cert_file_content != svc_cert_content))
     |

hamgr/hamgr/providers/nova.py:2709:89: E501 Line too long (103 > 88)
     |
2707 | …                     LOG.info('svc key for host %s in availability_zone %s needs refresh ? %s',
2708 | …                              host_id, cluster_name, str(existing_key_file_content != svc_key_content))
2709 | …                     LOG.info('svc cert for host %s in availability_zone %s needs refresh ? %s',
     |                                                                                   ^^^^^^^^^^^^^^^ E501
2710 | …                              host_id, cluster_name, str(existing_cert_file_content != svc_cert_content))
2711 | …                     LOG.info('ca cert for host %s in availability_zone %s needs refresh ? %s',
     |

hamgr/hamgr/providers/nova.py:2710:89: E501 Line too long (112 > 88)
     |
2708 | …                              host_id, cluster_name, str(existing_key_file_content != svc_key_content))
2709 | …                     LOG.info('svc cert for host %s in availability_zone %s needs refresh ? %s',
2710 | …                              host_id, cluster_name, str(existing_cert_file_content != svc_cert_content))
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^ E501
2711 | …                     LOG.info('ca cert for host %s in availability_zone %s needs refresh ? %s',
2712 | …                              host_id, cluster_name, str(existing_ca_file_content != ca_cert_content))
     |

hamgr/hamgr/providers/nova.py:2711:89: E501 Line too long (102 > 88)
     |
2709 | …                     LOG.info('svc cert for host %s in availability_zone %s needs refresh ? %s',
2710 | …                              host_id, cluster_name, str(existing_cert_file_content != svc_cert_content))
2711 | …                     LOG.info('ca cert for host %s in availability_zone %s needs refresh ? %s',
     |                                                                                   ^^^^^^^^^^^^^^ E501
2712 | …                              host_id, cluster_name, str(existing_ca_file_content != ca_cert_content))
     |

hamgr/hamgr/providers/nova.py:2712:89: E501 Line too long (109 > 88)
     |
2710 |                                      host_id, cluster_name, str(existing_cert_file_content != svc_cert_content))
2711 |                             LOG.info('ca cert for host %s in availability_zone %s needs refresh ? %s',
2712 |                                      host_id, cluster_name, str(existing_ca_file_content != ca_cert_content))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
2713 |
2714 |                             LOG.info('config for host %s in availability_zone %s will be refreshed', str(host_id), cluster_name)
     |

hamgr/hamgr/providers/nova.py:2714:89: E501 Line too long (128 > 88)
     |
2712 |                                      host_id, cluster_name, str(existing_ca_file_content != ca_cert_content))
2713 |
2714 |                             LOG.info('config for host %s in availability_zone %s will be refreshed', str(host_id), cluster_name)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2715 |                             valid_ips = [x for x in cluster_ip_lookup.values() if x != '']
2716 |                             join_ips = ','.join([str(v) for v in sorted(valid_ips)])
     |

hamgr/hamgr/providers/nova.py:2715:89: E501 Line too long (90 > 88)
     |
2714 | …                     LOG.info('config for host %s in availability_zone %s will be refreshed', str(host_id), cluster_name)
2715 | …                     valid_ips = [x for x in cluster_ip_lookup.values() if x != '']
     |                                                                                   ^^ E501
2716 | …                     join_ips = ','.join([str(v) for v in sorted(valid_ips)])
2717 | …                     join_nodes = {}
     |

hamgr/hamgr/providers/nova.py:2717:29: F841 Local variable `join_nodes` is assigned to but never used
     |
2715 | …                     valid_ips = [x for x in cluster_ip_lookup.values() if x != '']
2716 | …                     join_ips = ','.join([str(v) for v in sorted(valid_ips)])
2717 | …                     join_nodes = {}
     |                       ^^^^^^^^^^ F841
2718 | …                     host_ip = ip_lookup[host_id]
2719 | …                     # after the pf9-ha-slave role is enabled, the resmgr should have below customized settings:
     |
     = help: Remove assignment to unused variable `join_nodes`

hamgr/hamgr/providers/nova.py:2719:89: E501 Line too long (119 > 88)
     |
2717 | …                     join_nodes = {}
2718 | …                     host_ip = ip_lookup[host_id]
2719 | …                     # after the pf9-ha-slave role is enabled, the resmgr should have below customized settings:
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2720 | …                     # - cluster_ip, join, ip_address, bootstrap_expect
2721 | …                     # no matter they are existed or not, always set cluster_ip, join, ip_address.
     |

hamgr/hamgr/providers/nova.py:2721:89: E501 Line too long (105 > 88)
     |
2719 | …                     # after the pf9-ha-slave role is enabled, the resmgr should have below customized settings:
2720 | …                     # - cluster_ip, join, ip_address, bootstrap_expect
2721 | …                     # no matter they are existed or not, always set cluster_ip, join, ip_address.
     |                                                                                   ^^^^^^^^^^^^^^^^^ E501
2722 | …                     # only the bootstrap_expect can not be determined here
2723 | …                     data = self._customize_pf9_ha_slave_config(cluster_name, join_ips, host_ip, host_ip, nodes_details)
     |

hamgr/hamgr/providers/nova.py:2723:89: E501 Line too long (127 > 88)
     |
2721 |                             # no matter they are existed or not, always set cluster_ip, join, ip_address.
2722 |                             # only the bootstrap_expect can not be determined here
2723 |                             data = self._customize_pf9_ha_slave_config(cluster_name, join_ips, host_ip, host_ip, nodes_details)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2724 |
2725 |                             # update resmgr with the new role settings
     |

hamgr/hamgr/providers/nova.py:2726:89: E501 Line too long (103 > 88)
     |
2725 | …                     # update resmgr with the new role settings
2726 | …                     LOG.debug('updating cert settings for cluster %s for host %s with data %s',
     |                                                                                   ^^^^^^^^^^^^^^^ E501
2727 | …                               cluster_name, host_id, str(data))
2728 | …                     result = self._resmgr_client.update_role(host_id, "pf9-ha-slave", data, self._token['id'])
     |

hamgr/hamgr/providers/nova.py:2728:89: E501 Line too long (118 > 88)
     |
2726 | …                     LOG.debug('updating cert settings for cluster %s for host %s with data %s',
2727 | …                               cluster_name, host_id, str(data))
2728 | …                     result = self._resmgr_client.update_role(host_id, "pf9-ha-slave", data, self._token['id'])
     |                                                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2729 | …                     if not result or result.status_code != requests.codes.ok:
2730 | …                         LOG.warning('failed to update role settings for host %s', host_id)
     |

hamgr/hamgr/providers/nova.py:2730:89: E501 Line too long (98 > 88)
     |
2728 | …                     result = self._resmgr_client.update_role(host_id, "pf9-ha-slave", data, self._token['id'])
2729 | …                     if not result or result.status_code != requests.codes.ok:
2730 | …                         LOG.warning('failed to update role settings for host %s', host_id)
     |                                                                                   ^^^^^^^^^^ E501
2731 | …                     else:
2732 | …                         LOG.info('Successfully updated cert settings for cluster %s for host %s',
     |

hamgr/hamgr/providers/nova.py:2732:89: E501 Line too long (105 > 88)
     |
2730 |                                 LOG.warning('failed to update role settings for host %s', host_id)
2731 |                             else:
2732 |                                 LOG.info('Successfully updated cert settings for cluster %s for host %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2733 |                                          cluster_name, host_id)
2734 |                         else:
     |

hamgr/hamgr/providers/nova.py:2735:89: E501 Line too long (117 > 88)
     |
2733 |                                          cluster_name, host_id)
2734 |                         else:
2735 |                             LOG.debug('key or cert config refresh is not needed for host %s in availability_zone %s',
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2736 |                                       host_id, cluster_name)
2737 |                     except Exception as xes:
     |

hamgr/hamgr/providers/nova.py:2738:89: E501 Line too long (117 > 88)
     |
2736 |                                       host_id, cluster_name)
2737 |                     except Exception as xes:
2738 |                         LOG.exception('unhandled exception in process_consul_encryption_configuration: %s', str(xes))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2739 |         except Exception as ex:
2740 |             LOG.exception('unhandled exception in process_consul_encryption_configuration : %s', str(ex))
     |

hamgr/hamgr/providers/nova.py:2740:89: E501 Line too long (105 > 88)
     |
2738 |                         LOG.exception('unhandled exception in process_consul_encryption_configuration: %s', str(xes))
2739 |         except Exception as ex:
2740 |             LOG.exception('unhandled exception in process_consul_encryption_configuration : %s', str(ex))
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2741 |         finally:
2742 |             with self.consul_encryption_processing_lock:
     |

hamgr/hamgr/providers/nova.py:2744:89: E501 Line too long (111 > 88)
     |
2742 |             with self.consul_encryption_processing_lock:
2743 |                 self.consul_encryption_processing_running = False
2744 |         LOG.debug('consul encryption configuration processing task has finished at %s', str(datetime.utcnow()))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
2745 |
2746 |     def get_common_hosts_configs(self, availability_zone):
     |

hamgr/hamgr/providers/nova.py:2758:89: E501 Line too long (94 > 88)
     |
2756 |             nova_client = self._get_nova_client()
2757 |
2758 |             cluster_exists = db_api.get_cluster(str(availability_zone), raise_exception=False)
     |                                                                                         ^^^^^^ E501
2759 |             LOG.debug('found clusters %s : %s', str(availability_zone), str(cluster_exists))
2760 |             enabled = False
     |

hamgr/hamgr/providers/nova.py:2759:89: E501 Line too long (92 > 88)
     |
2758 |             cluster_exists = db_api.get_cluster(str(availability_zone), raise_exception=False)
2759 |             LOG.debug('found clusters %s : %s', str(availability_zone), str(cluster_exists))
     |                                                                                         ^^^^ E501
2760 |             enabled = False
2761 |             if cluster_exists:
     |

hamgr/hamgr/providers/nova.py:2771:89: E501 Line too long (90 > 88)
     |
2769 |             else:
2770 |                 # get hosts from masakari
2771 |                 hosts = masakari.get_nodes_in_segment(self._token, str(availability_zone))
     |                                                                                         ^^ E501
2772 |                 host_ids = [x['name'] for x in hosts]
2773 |                 LOG.debug('details of hosts from masakari : %s' , str(host_ids))
     |

hamgr/hamgr/providers/nova.py:2774:89: E501 Line too long (125 > 88)
     |
2772 |                 host_ids = [x['name'] for x in hosts]
2773 |                 LOG.debug('details of hosts from masakari : %s' , str(host_ids))
2774 |             LOG.debug('host ids found that associated with availability_zone %s : %s', str(availability_zone), str(host_ids))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2775 |
2776 |             # call resmgr for each host to get configs
     |

hamgr/hamgr/providers/nova.py:2777:13: F841 Local variable `headers` is assigned to but never used
     |
2776 |             # call resmgr for each host to get configs
2777 |             headers = {'X-Auth-Token': self._token['id'], 'Content-Type': 'application/json'}
     |             ^^^^^^^ F841
2778 |             # check whether the mounted nfs are same for all hosts
2779 |             hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
     |
     = help: Remove assignment to unused variable `headers`

hamgr/hamgr/providers/nova.py:2777:89: E501 Line too long (93 > 88)
     |
2776 |             # call resmgr for each host to get configs
2777 |             headers = {'X-Auth-Token': self._token['id'], 'Content-Type': 'application/json'}
     |                                                                                         ^^^^^ E501
2778 |             # check whether the mounted nfs are same for all hosts
2779 |             hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
     |

hamgr/hamgr/providers/nova.py:2779:89: E501 Line too long (93 > 88)
     |
2777 |             headers = {'X-Auth-Token': self._token['id'], 'Content-Type': 'application/json'}
2778 |             # check whether the mounted nfs are same for all hosts
2779 |             hosts_info = self._resmgr_client.fetch_hosts_details(host_ids, self._token['id'])
     |                                                                                         ^^^^^ E501
2780 |             for host_id in host_ids:
2781 |                 # object to carry necessary info for making decision
     |

hamgr/hamgr/providers/nova.py:2793:89: E501 Line too long (91 > 88)
     |
2791 |                     continue
2792 |                 LOG.debug('settings for host %s : %s', host_id, str(host_settings))
2793 |                 mounted_nfs_settings = host_settings['extensions'].get('mounted_nfs', None)
     |                                                                                         ^^^ E501
2794 |                 if mounted_nfs_settings:
2795 |                     item['mounted_nfs'] = mounted_nfs_settings.get('data', {}).get('mounted', [])
     |

hamgr/hamgr/providers/nova.py:2795:89: E501 Line too long (97 > 88)
     |
2793 |                 mounted_nfs_settings = host_settings['extensions'].get('mounted_nfs', None)
2794 |                 if mounted_nfs_settings:
2795 |                     item['mounted_nfs'] = mounted_nfs_settings.get('data', {}).get('mounted', [])
     |                                                                                         ^^^^^^^^^ E501
2796 |                 LOG.debug('mounted nfs settings for host %s : %s', host_id, str(mounted_nfs_settings))
2797 |                 # step 2 - get instances_path configured for role pf9-ostackhost-neutron
     |

hamgr/hamgr/providers/nova.py:2796:89: E501 Line too long (102 > 88)
     |
2794 |                 if mounted_nfs_settings:
2795 |                     item['mounted_nfs'] = mounted_nfs_settings.get('data', {}).get('mounted', [])
2796 |                 LOG.debug('mounted nfs settings for host %s : %s', host_id, str(mounted_nfs_settings))
     |                                                                                         ^^^^^^^^^^^^^^ E501
2797 |                 # step 2 - get instances_path configured for role pf9-ostackhost-neutron
2798 |                 role_settings = host_settings.get("role_settings", {}).get("pf9-ostackhost-neutron", {})
     |

hamgr/hamgr/providers/nova.py:2798:89: E501 Line too long (104 > 88)
     |
2796 |                 LOG.debug('mounted nfs settings for host %s : %s', host_id, str(mounted_nfs_settings))
2797 |                 # step 2 - get instances_path configured for role pf9-ostackhost-neutron
2798 |                 role_settings = host_settings.get("role_settings", {}).get("pf9-ostackhost-neutron", {})
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2799 |                 if not role_settings:
2800 |                     continue
     |

hamgr/hamgr/providers/nova.py:2801:89: E501 Line too long (105 > 88)
     |
2799 |                 if not role_settings:
2800 |                     continue
2801 |                 LOG.debug('settings for role %s : %s', str('pf9-ostackhost-neutron'), str(role_settings))
     |                                                                                         ^^^^^^^^^^^^^^^^^ E501
2802 |                 instances_path = role_settings.get('instances_path', '')
2803 |                 LOG.debug('instances_path configuration for host %s : %s', str(host_id), str(instances_path))
     |

hamgr/hamgr/providers/nova.py:2803:89: E501 Line too long (109 > 88)
     |
2801 |                 LOG.debug('settings for role %s : %s', str('pf9-ostackhost-neutron'), str(role_settings))
2802 |                 instances_path = role_settings.get('instances_path', '')
2803 |                 LOG.debug('instances_path configuration for host %s : %s', str(host_id), str(instances_path))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
2804 |                 if instances_path:
2805 |                     item['nova_instances_path'] = instances_path
     |

hamgr/hamgr/providers/nova.py:2806:89: E501 Line too long (90 > 88)
     |
2804 |                 if instances_path:
2805 |                     item['nova_instances_path'] = instances_path
2806 |                 LOG.debug('nova instances path for host %s : %s', host_id, instances_path)
     |                                                                                         ^^ E501
2807 |                 # step 3 - store found info accordingly
2808 |                 if len(item['mounted_nfs']) <= 0:
     |

hamgr/hamgr/providers/nova.py:2814:89: E501 Line too long (94 > 88)
     |
2812 |                     if instances_path:
2813 |                         path_matched_nfs = \
2814 |                             [x for x in item['mounted_nfs'] if x.get('destination', None) in \
     |                                                                                         ^^^^^^ E501
2815 |                              [instances_path,'/mnt/nfs/instances']]
2816 |                         if len(path_matched_nfs) > 0 :
     |

hamgr/hamgr/providers/nova.py:2834:89: E501 Line too long (89 > 88)
     |
2832 |         error = None
2833 |         if len(host_ids) <= 0:
2834 |             error = "no hosts found for availability_zone %s " % (str(availability_zone))
     |                                                                                         ^ E501
2835 |         else:
2836 |             # when rest call to resmgr failed
     |

hamgr/hamgr/providers/nova.py:2840:89: E501 Line too long (92 > 88)
     |
2838 |                 error = 'no settings found for hosts from resgmr: %s' % (str(host_ids))
2839 |             # when all hosts have no nfs , or only some hosts have nfs
2840 |             if len(without_nfs) > 0 or len(with_nfs) <= 0 or len(with_nfs) != len(host_ids):
     |                                                                                         ^^^^ E501
2841 |                 ids_with_nfs = [] if len(with_nfs) <= 0 else [x['host'] for x in with_nfs]
2842 |                 ids_without_nfs = [x['host'] for x in without_nfs]
     |

hamgr/hamgr/providers/nova.py:2841:89: E501 Line too long (90 > 88)
     |
2839 |             # when all hosts have no nfs , or only some hosts have nfs
2840 |             if len(without_nfs) > 0 or len(with_nfs) <= 0 or len(with_nfs) != len(host_ids):
2841 |                 ids_with_nfs = [] if len(with_nfs) <= 0 else [x['host'] for x in with_nfs]
     |                                                                                         ^^ E501
2842 |                 ids_without_nfs = [x['host'] for x in without_nfs]
2843 |                 error = 'hosts %s have nfs mounted but hosts %s do not' % (str(ids_with_nfs), str(ids_without_nfs))
     |

hamgr/hamgr/providers/nova.py:2843:89: E501 Line too long (115 > 88)
     |
2841 |                 ids_with_nfs = [] if len(with_nfs) <= 0 else [x['host'] for x in with_nfs]
2842 |                 ids_without_nfs = [x['host'] for x in without_nfs]
2843 |                 error = 'hosts %s have nfs mounted but hosts %s do not' % (str(ids_with_nfs), str(ids_without_nfs))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2844 |             # when not all hosts with nfs that matches nova instances_path
2845 |             path_matched_nfs = [x for x in with_nfs if len(x['nova_instances_path_matched_nfs']) > 0]
     |

hamgr/hamgr/providers/nova.py:2845:89: E501 Line too long (101 > 88)
     |
2843 |                 error = 'hosts %s have nfs mounted but hosts %s do not' % (str(ids_with_nfs), str(ids_without_nfs))
2844 |             # when not all hosts with nfs that matches nova instances_path
2845 |             path_matched_nfs = [x for x in with_nfs if len(x['nova_instances_path_matched_nfs']) > 0]
     |                                                                                         ^^^^^^^^^^^^^ E501
2846 |             if len(host_ids) != len(path_matched_nfs):
2847 |                 ids_with_matched_path = [x['host'] for x in path_matched_nfs]
     |

hamgr/hamgr/providers/nova.py:2848:89: E501 Line too long (99 > 88)
     |
2846 |             if len(host_ids) != len(path_matched_nfs):
2847 |                 ids_with_matched_path = [x['host'] for x in path_matched_nfs]
2848 |                 error = 'only hosts %s from %s have nfs setting matches instances_path %s : %s' % \
     |                                                                                         ^^^^^^^^^^^ E501
2849 |                         (str(ids_with_matched_path), str(host_ids), str(instances_path), str(path_matched_nfs))
2850 |         if error:
     |

hamgr/hamgr/providers/nova.py:2849:89: E501 Line too long (111 > 88)
     |
2847 |                 ids_with_matched_path = [x['host'] for x in path_matched_nfs]
2848 |                 error = 'only hosts %s from %s have nfs setting matches instances_path %s : %s' % \
2849 |                         (str(ids_with_matched_path), str(host_ids), str(instances_path), str(path_matched_nfs))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
2850 |         if error:
2851 |             LOG.debug(error)
     |

hamgr/hamgr/providers/nova.py:2857:89: E501 Line too long (110 > 88)
     |
2855 |         common_nfs_set = with_nfs[0]['nova_instances_path_matched_nfs']
2856 |         for item in with_nfs:
2857 |             common_nfs_set = self._get_common_nfs_set(common_nfs_set, item['nova_instances_path_matched_nfs'])
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
2858 |
2859 |         # when no common mounted nfs on all hosts
     |

hamgr/hamgr/providers/nova.py:2865:89: E501 Line too long (92 > 88)
     |
2863 |             raise ha_exceptions.NoCommonSharedNfsException(error)
2864 |
2865 |         LOG.debug('mounted nfs set of all hosts %s: %s', str(host_ids), str(common_nfs_set))
     |                                                                                         ^^^^ E501
2866 |         common_configs['shared_nfs'] = list(common_nfs_set)
2867 |         LOG.debug('common configs for hosts in availability_zone %s : %s', str(availability_zone), str(common_configs))
     |

hamgr/hamgr/providers/nova.py:2867:89: E501 Line too long (119 > 88)
     |
2865 |         LOG.debug('mounted nfs set of all hosts %s: %s', str(host_ids), str(common_nfs_set))
2866 |         common_configs['shared_nfs'] = list(common_nfs_set)
2867 |         LOG.debug('common configs for hosts in availability_zone %s : %s', str(availability_zone), str(common_configs))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2868 |         return common_configs
     |

hamgr/hamgr/providers/nova.py:2884:9: F841 Local variable `controller` is assigned to but never used
     |
2882 |     def refresh_consul_status(self):
2883 |         report = {}
2884 |         controller = get_rebalance_controller(self._config)
     |         ^^^^^^^^^^ F841
2885 |         # send the cmd to all active clusters
2886 |         active_clusters = db_api.get_all_active_clusters()
     |
     = help: Remove assignment to unused variable `controller`

hamgr/hamgr/providers/nova.py:2895:89: E501 Line too long (98 > 88)
     |
2893 |             LOG.info('refresh consul status for cluster %s', str(cluster_name))
2894 |             status = self._get_latest_consul_status(cluster_name)
2895 |             LOG.info('refreshed consul report for cluster %s: %s', str(cluster_name), str(status))
     |                                                                                         ^^^^^^^^^^ E501
2896 |             if status:
2897 |                 report[cluster_name] = status
     |

hamgr/hamgr/providers/nova.py:2907:89: E501 Line too long (94 > 88)
     |
2905 |             active_clusters = db_api.get_all_active_clusters()
2906 |             if id:
2907 |                 active_clusters = [cluster for cluster in active_clusters if cluster.id == id]
     |                                                                                         ^^^^^^ E501
2908 |
2909 |             self._token = self._get_v3_token()
     |

hamgr/hamgr/providers/nova.py:2946:89: E501 Line too long (95 > 88)
     |
2944 |         # 1 availability_zone needs to be existed, if not, throw AggregateNotFound
2945 |         availability_zone = self._get_availability_zone(nova_client, availability_zone)
2946 |         LOG.debug('found host availability_zone %s : %s', cluster_name, str(availability_zone))
     |                                                                                         ^^^^^^^ E501
2947 |         # 2 cluster need to be enabled, if not, throw ClusterNotFound
2948 |         cluster = db_api.get_cluster(str(availability_zone),
     |

hamgr/hamgr/providers/nova.py:2952:89: E501 Line too long (104 > 88)
     |
2950 |                                       raise_exception=True)
2951 |         if cluster.status != constants.HA_STATE_ENABLED:
2952 |             LOG.warning('Ignoring set_consul_agent_role as cluster %s status is not enabled currently.',
     |                                                                                         ^^^^^^^^^^^^^^^^ E501
2953 |                         cluster_name)
2954 |             return
     |

hamgr/hamgr/providers/nova.py:2985:89: E501 Line too long (102 > 88)
     |
2983 |             elif real_role == 'node':
2984 |                 current_role = constants.CONSUL_ROLE_CLIENT
2985 |             LOG.debug('agent role for host %s from latest consul status is %s', host_id, current_role)
     |                                                                                         ^^^^^^^^^^^^^^ E501
2986 |         if not current_role:
2987 |             LOG.debug('try to get agent role from resmgr when unable to get agent role from latest consul status')
     |

hamgr/hamgr/providers/nova.py:2987:89: E501 Line too long (114 > 88)
     |
2985 |             LOG.debug('agent role for host %s from latest consul status is %s', host_id, current_role)
2986 |         if not current_role:
2987 |             LOG.debug('try to get agent role from resmgr when unable to get agent role from latest consul status')
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2988 |             role_settings = self._resmgr_client.get_role_settings(host_id,
2989 |                                                                   slave_role,
     |

hamgr/hamgr/providers/nova.py:2992:89: E501 Line too long (97 > 88)
     |
2990 |                                                                   self._token['id'])
2991 |             if 'bootstrap_expect' not in role_settings:
2992 |                 raise ha_exceptions.RoleSettingsNotFound(host_id, slave_role, 'bootstrap_expect')
     |                                                                                         ^^^^^^^^^ E501
2993 |             LOG.debug('get current agent role for host %s by checking resmgr settings : %s', str(host_id), str(role_settings))
2994 |             if role_settings['bootstrap_expect'] == self._consul_bootstrap_expect:
     |

hamgr/hamgr/providers/nova.py:2993:89: E501 Line too long (126 > 88)
     |
2991 |             if 'bootstrap_expect' not in role_settings:
2992 |                 raise ha_exceptions.RoleSettingsNotFound(host_id, slave_role, 'bootstrap_expect')
2993 |             LOG.debug('get current agent role for host %s by checking resmgr settings : %s', str(host_id), str(role_settings))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
2994 |             if role_settings['bootstrap_expect'] == self._consul_bootstrap_expect:
2995 |                 current_role = constants.CONSUL_ROLE_SERVER
     |

hamgr/hamgr/providers/nova.py:2998:89: E501 Line too long (89 > 88)
     |
2996 |             else:
2997 |                 current_role = constants.CONSUL_ROLE_CLIENT
2998 |         LOG.debug('consul agent on host %s is current in role %s', host_id, current_role)
     |                                                                                         ^ E501
2999 |         if agent_role == current_role:
3000 |             LOG.debug('consul agent on host %s is already in %s role : %s',
     |

hamgr/hamgr/providers/nova.py:3015:89: E501 Line too long (114 > 88)
     |
3013 |                                       }]
3014 |                                       )
3015 |         LOG.info('reported consul agent role change for host %s from %s to %s', host_id, current_role, agent_role)
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
     |

hamgr/hamgr/providers/nova.py:3022:89: E501 Line too long (95 > 88)
     |
3020 |         host_ids = []
3021 |         headers = {"X-AUTH-TOKEN": self._token['id']}
3022 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-aggregates'
     |                                                                                         ^^^^^^^ E501
3023 |         request_sent=False
3024 |         if time.time() - VMHA_OS_AGGREGATES["last_check"] > VMHA_HOST_CACHE_INVALIDATION or VMHA_OS_AGGREGATES["response"]=={}:
     |

hamgr/hamgr/providers/nova.py:3024:89: E501 Line too long (127 > 88)
     |
3022 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-aggregates'
3023 |         request_sent=False
3024 |         if time.time() - VMHA_OS_AGGREGATES["last_check"] > VMHA_HOST_CACHE_INVALIDATION or VMHA_OS_AGGREGATES["response"]=={}:
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
3025 |             LOG.debug("internal %s cache looks like %s", time.time(), VMHA_OS_AGGREGATES)
3026 |             request_sent=True
     |

hamgr/hamgr/providers/nova.py:3025:89: E501 Line too long (89 > 88)
     |
3023 |         request_sent=False
3024 |         if time.time() - VMHA_OS_AGGREGATES["last_check"] > VMHA_HOST_CACHE_INVALIDATION or VMHA_OS_AGGREGATES["response"]=={}:
3025 |             LOG.debug("internal %s cache looks like %s", time.time(), VMHA_OS_AGGREGATES)
     |                                                                                         ^ E501
3026 |             request_sent=True
3027 |             try:
     |

hamgr/hamgr/providers/nova.py:3044:81: E711 Comparison to `None` should be `cond is not None`
     |
3042 |             data=VMHA_OS_AGGREGATES["response"]
3043 |         if 'aggregates' in data:
3044 |             filtered_aggregates = list(filter(lambda x: x["availability_zone"]!=None and host_id in x["hosts"], data['aggregates']))
     |                                                                                 ^^^^ E711
3045 |             host_ids = filtered_aggregates[0]['hosts'] if filtered_aggregates else []
3046 |         return host_ids
     |
     = help: Replace with `cond is not None`

hamgr/hamgr/providers/nova.py:3044:89: E501 Line too long (132 > 88)
     |
3042 |             data=VMHA_OS_AGGREGATES["response"]
3043 |         if 'aggregates' in data:
3044 |             filtered_aggregates = list(filter(lambda x: x["availability_zone"]!=None and host_id in x["hosts"], data['aggregates']))
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
3045 |             host_ids = filtered_aggregates[0]['hosts'] if filtered_aggregates else []
3046 |         return host_ids
     |

hamgr/hamgr/providers/nova.py:3053:89: E501 Line too long (103 > 88)
     |
3051 |         headers = {"X-AUTH-TOKEN": self._token['id']}
3052 |         # We dont know whats the hypervisor id so be brute force it
3053 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-hypervisors/detail'
     |                                                                                         ^^^^^^^^^^^^^^^ E501
3054 |         request_sent=False
3055 |         if time.time() - VMHA_NOVA_DETAILS["last_check"] > VMHA_HOST_CACHE_INVALIDATION or VMHA_NOVA_DETAILS["response"]=={}:
     |

hamgr/hamgr/providers/nova.py:3055:89: E501 Line too long (125 > 88)
     |
3053 |         url = 'http://nova-api.' + self._du_name + '.svc.cluster.local:8774/v2.1/os-hypervisors/detail'
3054 |         request_sent=False
3055 |         if time.time() - VMHA_NOVA_DETAILS["last_check"] > VMHA_HOST_CACHE_INVALIDATION or VMHA_NOVA_DETAILS["response"]=={}:
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
3056 |             LOG.debug("internal %s cache looks like %s", time.time(), VMHA_NOVA_DETAILS)
3057 |             request_sent=True
     |

hamgr/hamgr/providers/nova.py:3076:89: E501 Line too long (110 > 88)
     |
3074 |         if 'hypervisors' in data:
3075 |             if len(data['hypervisors']) > 0:
3076 |                 ip = list(filter(lambda x:x['service']['host'] == host_id, data['hypervisors']))[0]['host_ip']
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
3077 |         return ip
     |

hamgr/hamgr/providers/nova.py:3089:89: E501 Line too long (109 > 88)
     |
3087 |         self._hypervisor_details=""
3088 |         for host in filter(lambda x: x!=host_id,host_ids):
3089 |             # Make this as such only one request is used and then we parse it and get ips for different hosts
     |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
3090 |             ip_map[host]=self.get_ip_from_host_id(host)
3091 |             if not ip_map[host]:
     |

hamgr/hamgr/providers/nova.py:3101:89: E501 Line too long (95 > 88)
     |
3099 |             picking_list = list(ip_map.keys())
3100 |             list_len = len(picking_list)-1
3101 |             ind1, ind2, ind3 = randint(0, list_len), randint(0, list_len), randint(0, list_len)
     |                                                                                         ^^^^^^^ E501
3102 |             final_map={
3103 |                 picking_list[ind1]: ip_map[picking_list[ind1]],
     |

hamgr/hamgr/providers/nova.py:3122:89: E501 Line too long (103 > 88)
     |
3120 |     def check_vmha_enabled_on_resmgr(self,cluster_name):
3121 |         headers = {"X-AUTH-TOKEN": self._token['id']}
3122 |         url = 'http://resmgr.' + self._du_name + '.svc.cluster.local:18083/v2/clusters/' + cluster_name
     |                                                                                         ^^^^^^^^^^^^^^^ E501
3123 |         try:
3124 |             response = requests.get(url, headers=headers,timeout=NOVA_REQ_TIMEOUT)
     |

hamgr/hamgr/providers/nova.py:3131:29: F841 [*] Local variable `e` is assigned to but never used
     |
3129 |             body = response.json()
3130 |             LOG.debug("response from resmgr %s", body)
3131 |         except Exception as e:
     |                             ^ F841
3132 |             LOG.warning("unable to unpack reponse from resmgr")
3133 |             return False
     |
     = help: Remove assignment to unused variable `e`

hamgr/hamgr/providers/provider.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from abc import ABCMeta
16 | | from abc import abstractmethod
   | |______________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/rebalance.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import datetime
17 | | import traceback
18 | | import time
19 | | from shared.exceptions import ha_exceptions
20 | | from shared.rpc.rpc_manager import RpcManager
21 | | from shared.messages import message_types
22 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
23 |
24 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/rebalance.py:18:8: F401 [*] `time` imported but unused
   |
16 | import datetime
17 | import traceback
18 | import time
   |        ^^^^ F401
19 | from shared.exceptions import ha_exceptions
20 | from shared.rpc.rpc_manager import RpcManager
   |
   = help: Remove unused import: `time`

hamgr/hamgr/rebalance.py:160:89: E501 Line too long (105 > 88)
    |
158 |                 'unable to get result as the rebalancer manager is None')
159 |             return None
160 |         self.rpc_manager.send_rpc_message(request, message_type=message_types.MSG_ROLE_REBALANCE_REQUEST)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
161 |         # in asynchronous mode, need to wait till response arrive or timed out
162 |         resp = self._wait_for_response_or_timeout(self._received_role_rebalance_responses,
    |

hamgr/hamgr/rebalance.py:162:89: E501 Line too long (90 > 88)
    |
160 |         self.rpc_manager.send_rpc_message(request, message_type=message_types.MSG_ROLE_REBALANCE_REQUEST)
161 |         # in asynchronous mode, need to wait till response arrive or timed out
162 |         resp = self._wait_for_response_or_timeout(self._received_role_rebalance_responses,
    |                                                                                         ^^ E501
163 |                                                   req_id,
164 |                                                   timeout_seconds=180)
    |

hamgr/hamgr/rebalance.py:168:89: E501 Line too long (94 > 88)
    |
166 |         return resp
167 |
168 |     def _wait_for_response_or_timeout(self, receive_buffer, request_id, timeout_seconds = 60):
    |                                                                                         ^^^^^^ E501
169 |         time_start = datetime.datetime.utcnow()
170 |         time_delta = datetime.timedelta(seconds=timeout_seconds)
    |

hamgr/hamgr/rebalance.py:208:89: E501 Line too long (89 > 88)
    |
206 |                         pass
207 |
208 |         LOG.debug('response found for request id %s : %s', str(request_id), str(payload))
    |                                                                                         ^ E501
209 |         return payload
    |

hamgr/hamgr/rebalance.py:215:89: E501 Line too long (89 > 88)
    |
213 |         if not self.rpc_manager:
214 |             LOG.warning(
215 |                 'unable to ask for consul cluster status, as rebalancer manager is null')
    |                                                                                         ^ E501
216 |             return {}
217 |         LOG.debug('send consul refresh request begin at %s : %s',
    |

hamgr/hamgr/rebalance.py:221:89: E501 Line too long (117 > 88)
    |
219 |         self.rpc_manager.send_rpc_message(request,
220 |                                           message_type=message_types.MSG_CONSUL_REFRESH_REQUEST)
221 |         resp = self._wait_for_response_or_timeout(self._received_status_responses, request.id(), timeout_seconds=180)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
222 |         LOG.debug('consul refresh response received at %s : %s',
223 |                   str(datetime.datetime.utcnow()), str(resp))
    |

hamgr/hamgr/resmgr_client.py:1:1: I001 [*] Import block is un-sorted or un-formatted
  |
1 | / import requests
2 | | import logging
3 | | from shared.constants import LOGGER_PREFIX
  | |__________________________________________^ I001
4 |
5 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
  |
  = help: Organize imports

hamgr/hamgr/server.py:22:1: I001 [*] Import block is un-sorted or un-formatted
   |
20 |   # point of application to avoid thread deadlock problem.
21 |
22 | / import argparse
23 | | import logging
24 | |
25 | | from eventlet import listen
26 | | from eventlet import wsgi
27 | | from hamgr.logger import setup_root_logger
28 | | from paste.deploy import loadapp
29 | |
30 | | from hamgr import periodic_task
31 | | from hamgr import provider_factory
32 | | from shared.constants import LOGGER_PREFIX
33 | |
34 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
35 |
36 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/server.py:44:89: E501 Line too long (103 > 88)
   |
42 |     parser.add_argument('--config-file', dest='config_file',
43 |                         default='/etc/pf9/hamgr/hamgr.conf')
44 |     parser.add_argument('--paste-ini', dest='paste_file', default='/etc/pf9/hamgr/hamgr-api-paste.ini')
   |                                                                                         ^^^^^^^^^^^^^^^ E501
45 |     return parser.parse_args()
   |

hamgr/hamgr/server.py:59:89: E501 Line too long (99 > 88)
   |
57 |         provider = provider_factory.ha_provider()
58 |         #LOG.debug('add task process_consul_encryption_configuration')
59 |         #periodic_task.add_task(provider.process_consul_encryption_configuration, 60, run_now=True)
   |                                                                                         ^^^^^^^^^^^ E501
60 |         LOG.debug('add task process_availability_zone_changes')
61 |         periodic_task.add_task(provider.process_availability_zone_changes, 60, run_now=True)
   |

hamgr/hamgr/server.py:61:89: E501 Line too long (92 > 88)
   |
59 |         #periodic_task.add_task(provider.process_consul_encryption_configuration, 60, run_now=True)
60 |         LOG.debug('add task process_availability_zone_changes')
61 |         periodic_task.add_task(provider.process_availability_zone_changes, 60, run_now=True)
   |                                                                                         ^^^^ E501
62 |         # dedicated task to handle host events
63 |         LOG.debug('add task process_host_events')
   |

hamgr/hamgr/server.py:67:89: E501 Line too long (98 > 88)
   |
65 |         # task to handle consul role rebalance
66 |         #LOG.debug('add task process_consul_role_rebalance_requests')
67 |         #periodic_task.add_task(provider.process_consul_role_rebalance_requests, 60, run_now=True)
   |                                                                                         ^^^^^^^^^^ E501
68 |         # background thread for handling HA enable/disable request
69 |         LOG.debug('add task process_ha_enable_disable_requests')
   |

hamgr/hamgr/server.py:70:89: E501 Line too long (92 > 88)
   |
68 |         # background thread for handling HA enable/disable request
69 |         LOG.debug('add task process_ha_enable_disable_requests')
70 |         periodic_task.add_task(provider.process_ha_enable_disable_requests, 5, run_now=True)
   |                                                                                         ^^^^ E501
71 |         # task to verify queue is not present for unauthed host
72 |         LOG.debug("add task process_queue_for_unauthed_hosts")
   |

hamgr/hamgr/server.py:81:89: E501 Line too long (109 > 88)
   |
79 |             cinder_provider = provider_factory.cinder_provider()
80 |             if cinder_provider:
81 |                 LOG.debug('Successfully initialized cinder provider, adding task process_cinder_host_events')
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
82 |                 periodic_task.add_task(cinder_provider.process_cinder_host_events, 60, run_now=True)
83 |             else:
   |

hamgr/hamgr/server.py:82:89: E501 Line too long (100 > 88)
   |
80 |             if cinder_provider:
81 |                 LOG.debug('Successfully initialized cinder provider, adding task process_cinder_host_events')
82 |                 periodic_task.add_task(cinder_provider.process_cinder_host_events, 60, run_now=True)
   |                                                                                         ^^^^^^^^^^^^ E501
83 |             else:
84 |                 LOG.error('Failed to initialize cinder provider, cinder HA will not be available')
   |

hamgr/hamgr/server.py:84:89: E501 Line too long (98 > 88)
   |
82 |                 periodic_task.add_task(cinder_provider.process_cinder_host_events, 60, run_now=True)
83 |             else:
84 |                 LOG.error('Failed to initialize cinder provider, cinder HA will not be available')
   |                                                                                         ^^^^^^^^^^ E501
85 |         except Exception as e:
86 |             LOG.exception('Error initializing cinder provider: %s', str(e))
   |

hamgr/hamgr/tests/test_db_api.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | |
17 | | from hamgr.db import api as db_api
18 | | from shared import constants
19 | |
20 | | import mock
21 | |
22 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/tests/test_db_api.py:20:8: F401 [*] `mock` imported but unused
   |
18 | from shared import constants
19 |
20 | import mock
   |        ^^^^ F401
21 |
22 | from six.moves.configparser import ConfigParser
   |
   = help: Remove unused import: `mock`

hamgr/hamgr/tests/test_key_helper.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 | # limitations under the License.
14 |
15 | import unittest
   | ^^^^^^^^^^^^^^^ I001
16 |
17 | class KeyHelperTest(unittest.TestCase):
   |
   = help: Organize imports

hamgr/hamgr/tests/test_key_helper.py:115:89: E501 Line too long (95 > 88)
    |
113 |             self.assertTrue(seed == sc['pwd'])
114 |             key = _get_key(name, seed)
115 |             self.assertTrue(key == sc['expect'], 'key = %s, expect = %s' % (key, sc['expect']))
    |                                                                                         ^^^^^^^ E501
    |

hamgr/hamgr/tests/test_logger.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | | import glob
17 | | import os
18 | | from hamgr import logger
19 | |
20 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
21 |
22 |   LOG = None
   |
   = help: Organize imports

hamgr/hamgr/tests/test_masakari.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | |
17 | | import datetime
18 | |
19 | | from hamgr.common import masakari
20 | |
21 | | import mock
   | |___________^ I001
   |
   = help: Organize imports

hamgr/hamgr/tests/test_masakari.py:61:89: E501 Line too long (89 > 88)
   |
59 |     @mock.patch('hamgr.common.masakari.get_failover_segment')
60 |     @mock.patch('hamgr.common.utils.get_token')
61 |     def test_get_nodes_in_segment(self, mock_token, mock_get_failover_segment, mock_get):
   |                                                                                         ^ E501
62 |         json = {"hosts": []}
63 |         mock_resp = mock.Mock()
   |

hamgr/hamgr/tests/test_masakari.py:68:89: E501 Line too long (108 > 88)
   |
66 |         mock_resp.json = lambda *args: dict(json)
67 |         mock_get.return_value = mock_resp
68 |         mock_get_failover_segment.return_value = {"name": "fake-segments", "uuid": "fake-uuid", "hosts": []}
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
69 |         nodes = masakari.get_nodes_in_segment(mock_token, "fake-segments")
70 |         assert nodes is not None
   |

hamgr/hamgr/tests/test_masakari.py:76:89: E501 Line too long (111 > 88)
   |
74 |     @mock.patch("hamgr.common.masakari.get_failover_segment")
75 |     @mock.patch('hamgr.common.utils.get_token')
76 |     def test_create_failover_segment(self, mock_token, mock_get_failover_segment, mock_delete_failover_segment,
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
77 |                                      mock_post):
78 |         mock_get_failover_segment.return_value = None
   |

hamgr/hamgr/tests/test_masakari.py:80:89: E501 Line too long (98 > 88)
   |
78 |         mock_get_failover_segment.return_value = None
79 |         mock_delete_failover_segment.return_value = None
80 |         masakari.create_failover_segment(mock_token, "fake-segment", [{"name": "fake-host-name"}])
   |                                                                                         ^^^^^^^^^^ E501
81 |
82 |     @mock.patch("requests.delete")
   |

hamgr/hamgr/tests/test_masakari.py:86:89: E501 Line too long (108 > 88)
   |
84 |     @mock.patch("hamgr.common.masakari.get_failover_segment")
85 |     @mock.patch("hamgr.common.utils.get_token")
86 |     def test_delete_failover_segment(self, mock_token, mock_get_failover_segment, mock_get_nodes_in_segment,
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
87 |                                      mock_delete):
88 |         mock_get_nodes_in_segment.return_value = [{"failover_segment_id": "fake-segment", "uuid": "fake-uuid"}]
   |

hamgr/hamgr/tests/test_masakari.py:88:89: E501 Line too long (111 > 88)
   |
86 |     def test_delete_failover_segment(self, mock_token, mock_get_failover_segment, mock_get_nodes_in_segment,
87 |                                      mock_delete):
88 |         mock_get_nodes_in_segment.return_value = [{"failover_segment_id": "fake-segment", "uuid": "fake-uuid"}]
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
89 |         mock_get_failover_segment.return_value = {"uuid": "fake-uuid"}
90 |         mock_resp = mock.Mock()
   |

hamgr/hamgr/tests/test_masakari.py:103:89: E501 Line too long (119 > 88)
    |
101 |         mock_resp.raise_for_status = lambda *args: None
102 |         mock_post.return_value = mock_resp
103 |         masakari.create_notification(mock_token, "host-down", "fake-host-id", str(datetime.datetime.now().isoformat()),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
104 |                                      {})
    |

hamgr/hamgr/tests/test_notification.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | | import logging
   | |______________^ I001
17 |
18 |   logging.basicConfig(level=logging.DEBUG)
   |
   = help: Organize imports

hamgr/hamgr/tests/test_notification.py:23:89: E501 Line too long (95 > 88)
   |
21 | handler = logging.StreamHandler()
22 | handler.setLevel(logging.DEBUG)
23 | handler.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
   |                                                                                         ^^^^^^^ E501
24 | logger.addHandler(handler)
   |

hamgr/hamgr/tests/test_notification.py:26:1: E402 Module level import not at top of file
   |
24 | logger.addHandler(handler)
25 |
26 | from hamgr.notification import NotificationManager
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
27 | from shared.messages.cluster_event import ClusterEvent
   |

hamgr/hamgr/tests/test_notification.py:26:1: I001 [*] Import block is un-sorted or un-formatted
   |
24 |   logger.addHandler(handler)
25 |
26 | / from hamgr.notification import NotificationManager
27 | | from shared.messages.cluster_event import ClusterEvent
28 | |
29 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/tests/test_notification.py:27:1: E402 Module level import not at top of file
   |
26 | from hamgr.notification import NotificationManager
27 | from shared.messages.cluster_event import ClusterEvent
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
28 |
29 | from six.moves.configparser import ConfigParser
   |

hamgr/hamgr/tests/test_notification.py:29:1: E402 Module level import not at top of file
   |
27 | from shared.messages.cluster_event import ClusterEvent
28 |
29 | from six.moves.configparser import ConfigParser
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
   |

hamgr/hamgr/tests/test_nova.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | |
17 | | from hamgr.db import api as db_api
18 | | from shared.exceptions import ha_exceptions as exceptions
19 | | from hamgr.providers.nova import get_provider
20 | | from shared import constants
21 | |
22 | | import mock
23 | |
24 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
   |
   = help: Organize imports

hamgr/hamgr/tests/test_nova.py:137:89: E501 Line too long (95 > 88)
    |
135 |             'fake_role_1': {},
136 |             'fake_role_2': {},
137 |             'pf9-ostackhost-neutron': {"consul_ip": "192.178.1.1", "cluster_ip": "192.178.1.1"}
    |                                                                                         ^^^^^^^ E501
138 |         }
139 |         segments_info = {
    |

hamgr/hamgr/tests/test_nova.py:179:60: E703 [*] Statement ends with an unnecessary semicolon
    |
177 |     def _repeat_it(self):
178 |         self._provider.put("fake1", "enable")
179 |         self._provider.process_ha_enable_disable_requests();
    |                                                            ^ E703
180 |
181 |     @mock.patch('hamgr.common.utils.get_token')
    |
    = help: Remove unnecessary semicolon

hamgr/hamgr/tests/test_nova.py:215:60: E703 [*] Statement ends with an unnecessary semicolon
    |
213 |         self._enable_aggregate(mock_del, mock_put, mock_get, mock_post,
214 |                                mock_token, aggregate_id="fake")
215 |         self._provider.process_ha_enable_disable_requests();
    |                                                            ^ E703
216 |         # Create 2nd aggregate with hosts from first cluster
217 |         self.assertRaises(exceptions.HostPartOfCluster, self._repeat_it)
    |
    = help: Remove unnecessary semicolon

hamgr/hamgr/wsgi.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import json
17 | | from datetime import datetime, timedelta
18 | | from flask import jsonify
19 | | from flask import request
20 | | import requests
21 | | import time
22 | | from hamgr import app
23 | | from hamgr.context import error_handler
24 | | from shared.exceptions import ha_exceptions as exceptions
25 | | import shared.constants as constants
26 | | from hamgr import provider_factory
27 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
28 |
29 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

hamgr/hamgr/wsgi.py:20:8: F401 [*] `requests` imported but unused
   |
18 | from flask import jsonify
19 | from flask import request
20 | import requests
   |        ^^^^^^^^ F401
21 | import time
22 | from hamgr import app
   |
   = help: Remove unused import: `requests`

hamgr/hamgr/wsgi.py:200:89: E501 Line too long (100 > 88)
    |
198 |     results = []
199 |     staled = False
200 |     LOG.debug('latest consul status for availability zone %s : %s', availability_zone, str(records))
    |                                                                                         ^^^^^^^^^^^^ E501
201 |     for record in records:
202 |         if record is None:
    |

hamgr/hamgr/wsgi.py:223:89: E501 Line too long (89 > 88)
    |
221 |         leader = record.leader
222 |         # need to remove the prefix u int string json , otherwise loads will fail
223 |         members = json.loads(str(record.members).replace('u\'', '\'').replace('\'','\"'))
    |                                                                                         ^ E501
224 |         for host_id in availability_zone_host_ids:
225 |             matches = [x for x in members if x['Name'] == host_id]
    |

hamgr/hamgr/wsgi.py:244:89: E501 Line too long (92 > 88)
    |
242 |             if host_role == "server":
243 |                 # only server role will have port 8300 in Tags
244 |                 is_leader = (leader == ('%s:%s' % (member['Addr'], member['Tags']['port'])))
    |                                                                                         ^^^^ E501
245 |
246 |             result = {
    |

hamgr/hamgr/wsgi.py:256:89: E501 Line too long (94 > 88)
    |
254 |             }
255 |             results.append(result)
256 |             staled = staled | ((datetime.utcnow() - record.lastUpdate) > timedelta(minutes=5))
    |                                                                                         ^^^^^^ E501
257 |     # when no db records or they are old than 5 minutes, then use RPC to get real time status
258 |     # don't write back to db because it will blow away the db (tons of calls every 6 minutes)
    |

hamgr/hamgr/wsgi.py:257:89: E501 Line too long (93 > 88)
    |
255 |             results.append(result)
256 |             staled = staled | ((datetime.utcnow() - record.lastUpdate) > timedelta(minutes=5))
257 |     # when no db records or they are old than 5 minutes, then use RPC to get real time status
    |                                                                                         ^^^^^ E501
258 |     # don't write back to db because it will blow away the db (tons of calls every 6 minutes)
259 |     # will generate lots of db records
    |

hamgr/hamgr/wsgi.py:258:89: E501 Line too long (93 > 88)
    |
256 |             staled = staled | ((datetime.utcnow() - record.lastUpdate) > timedelta(minutes=5))
257 |     # when no db records or they are old than 5 minutes, then use RPC to get real time status
258 |     # don't write back to db because it will blow away the db (tons of calls every 6 minutes)
    |                                                                                         ^^^^^ E501
259 |     # will generate lots of db records
260 |     if len([x for x in results if x]) <= 0 or staled:
    |

hamgr/hamgr/wsgi.py:261:89: E501 Line too long (104 > 88)
    |
259 |     # will generate lots of db records
260 |     if len([x for x in results if x]) <= 0 or staled:
261 |         LOG.info('no consul status records found in db or they staled, now get real time status by RPC')
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
262 |         realtime_status = ha_provider.refresh_consul_status()
263 |         target_availability_zone = None
    |

hamgr/hamgr/wsgi.py:275:21: F841 Local variable `target_aggregate` is assigned to but never used
    |
274 |                 if availability_zone and availability_zone == agg_id:
275 |                     target_aggregate = aggregate
    |                     ^^^^^^^^^^^^^^^^ F841
276 |                 aggregate_name = aggregate.name
277 |                 aggregate_zone = aggregate.availability_zone
    |
    = help: Remove assignment to unused variable `target_aggregate`

hamgr/hamgr/wsgi.py:276:17: F841 Local variable `aggregate_name` is assigned to but never used
    |
274 |                 if availability_zone and availability_zone == agg_id:
275 |                     target_aggregate = aggregate
276 |                 aggregate_name = aggregate.name
    |                 ^^^^^^^^^^^^^^ F841
277 |                 aggregate_zone = aggregate.availability_zone
278 |                 for member in realtime_status[agg_id]['members']:
    |
    = help: Remove assignment to unused variable `aggregate_name`

hamgr/hamgr/wsgi.py:277:17: F841 Local variable `aggregate_zone` is assigned to but never used
    |
275 |                     target_aggregate = aggregate
276 |                 aggregate_name = aggregate.name
277 |                 aggregate_zone = aggregate.availability_zone
    |                 ^^^^^^^^^^^^^^ F841
278 |                 for member in realtime_status[agg_id]['members']:
279 |                     host_id = member['Name']
    |
    = help: Remove assignment to unused variable `aggregate_zone`

hamgr/hamgr/wsgi.py:281:89: E501 Line too long (91 > 88)
    |
279 |                     host_id = member['Name']
280 |                     host_status = 'up' if member['Status'] == 1 else 'down'
281 |                     host_role = 'server' if member['Tags']['role'] == 'consul' else 'agent'
    |                                                                                         ^^^ E501
282 |                     is_leader = False
283 |                     if host_role == "server":
    |

hamgr/hamgr/wsgi.py:285:89: E501 Line too long (127 > 88)
    |
283 |                     if host_role == "server":
284 |                         # only server role will have port 8300 in Tags
285 |                         is_leader = (realtime_status[agg_id]['leader'] == ('%s:%s' % (member['Addr'], member['Tags']['port'])))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
286 |                     # convert the data to output schema
287 |                     results.append({'availabilityZoneName': availability_zone,
    |

hamgr/hamgr/wsgi.py:293:89: E501 Line too long (90 > 88)
    |
291 |                                     'isLeader': is_leader,
292 |                                     'lastUpdate': datetime.strftime(datetime.utcnow(),
293 |                                                                     '%Y-%m-%d %H:%M:%S')})
    |                                                                                         ^^ E501
294 |         else:
295 |             LOG.info('real time consul status not found')
    |

hamgr/hamgr/wsgi.py:297:89: E501 Line too long (109 > 88)
    |
295 |             LOG.info('real time consul status not found')
296 |         if availability_zone and target_availability_zone:
297 |             results = [x for x in results if x['availabilityZoneName'] == str(target_availability_zone.name)]
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
298 |
299 |     return jsonify(results)
    |

hamgr/hamgr/wsgi.py:352:89: E501 Line too long (96 > 88)
    |
352 | @app.route('/v1/consul/<availability_zone>/agent/<uuid:host_uuid>/role/<role>', methods=['PUT'])
    |                                                                                         ^^^^^^^^ E501
353 | @error_handler
354 | def set_consul_role(availability_zone, host_uuid, role):
    |

hamgr/hamgr/wsgi.py:397:89: E501 Line too long (92 > 88)
    |
396 |     Args:
397 |         host_id (str): The host_id of the host which wants to get the list of its neighbours
    |                                                                                         ^^^^ E501
398 |     """
399 |     nova_provider = provider_factory.ha_provider()
    |

hamgr/hamgr/wsgi.py:402:89: E501 Line too long (118 > 88)
    |
400 |     nova_provider._token = nova_provider._get_v3_token()
401 |     
402 |     # Using this as a simple cleanup job for VMHA CACHE. This does not correspond to the functionality of the endpoint
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
403 |     # but I kinda find it would be easier to do here
404 |     try:
    |

hamgr/hamgr/wsgi.py:410:5: E722 Do not use bare `except`
    |
408 |                 # Asserting if the ip of that host doesn't exist then host doesn't exist
409 |                 VMHA_CACHE.pop(host, None)
410 |     except:
    |     ^^^^^^ E722
411 |         pass
    |

hamgr/hamgr/wsgi.py:429:89: E501 Line too long (101 > 88)
    |
427 |     LOG.debug(f"Body of request for hoststatus {body}")
428 |     if len(body)==0:
429 |         return jsonify(dict(success=False, error="host not found in body")), 412, CONTENT_TYPE_HEADER
    |                                                                                         ^^^^^^^^^^^^^ E501
430 |     
431 |     # Use nova provider
    |

hamgr/hamgr/wsgi.py:448:89: E501 Line too long (92 > 88)
    |
446 | …     if VMHA_TABLE[host].count(True)-VMHA_TABLE[host].count(False) <= 0:
447 | …         if host in VMHA_CACHE:
448 | …             if time.time() - VMHA_CACHE[host] > MAX_FAILED_TIME and VMHA_CACHE[host]!=0:
    |                                                                                       ^^^^ E501
449 | …                 LOG.info(f"Triggering migration of VMs on host {host} after being failed for {time.time() - VMHA_CACHE[host]} secon…
450 | …                 event = MockEvent(
    |

hamgr/hamgr/wsgi.py:449:89: E501 Line too long (139 > 88)
    |
447 | …
448 | …> MAX_FAILED_TIME and VMHA_CACHE[host]!=0:
449 | …n of VMs on host {host} after being failed for {time.time() - VMHA_CACHE[host]} seconds")
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
450 | …
451 | …
    |

hamgr/hamgr/wsgi.py:460:29: E711 Comparison to `None` should be `cond is None`
    |
458 |                     ret = nova_provider._report_event_to_masakari(event)
459 |                     LOG.info(f"Return from masakari func {ret}")
460 |                     if ret==None:
    |                             ^^^^ E711
461 |                         return jsonify(dict(success=False, error="unable to send masakari notification")), 500, CONTENT_TYPE_HEADER
462 |                     # The host is processed. Escape the check above
    |
    = help: Replace with `cond is None`

hamgr/hamgr/wsgi.py:461:89: E501 Line too long (131 > 88)
    |
459 |                     LOG.info(f"Return from masakari func {ret}")
460 |                     if ret==None:
461 |                         return jsonify(dict(success=False, error="unable to send masakari notification")), 500, CONTENT_TYPE_HEADER
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
462 |                     # The host is processed. Escape the check above
463 |                     VMHA_CACHE[host] = 0
    |

hamgr/setup.py:19:12: F401 `multiprocessing` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
18 | try:
19 |     import multiprocessing
   |            ^^^^^^^^^^^^^^^ F401
20 | except ImportError:
21 |     pass
   |
   = help: Remove unused import: `multiprocessing`

host/ha/hostapp/manager.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import json
16 | | import os
17 | | import io
18 | | import logging
19 | | import shlex
20 | | from datetime import datetime
21 | | from datetime import timedelta
22 | | from subprocess import call
23 | | from time import sleep
24 | | from base64 import b64decode
25 | | from shutil import rmtree
26 | | from ha.utils import consul_helper
27 | | from ha.utils import report
28 | | from oslo_config import cfg
29 | | from shared import constants
30 | | from shared.rpc.rpc_manager import RpcManager
31 | | from shared.messages.rebalance_response import ConsulRoleRebalanceResponse
32 | | from shared.messages.consul_response import ConsulRefreshResponse
33 | | from shared.messages import message_types
34 | | from shared.exceptions import ha_exceptions
35 | | from shared.constants import LOGGER_PREFIX
36 | |
37 | | from six import iteritems
38 | | from six.moves.configparser import ConfigParser
   | |_______________________________________________^ I001
39 |
40 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

host/ha/hostapp/manager.py:17:8: F401 [*] `io` imported but unused
   |
15 | import json
16 | import os
17 | import io
   |        ^^ F401
18 | import logging
19 | import shlex
   |
   = help: Remove unused import: `io`

host/ha/hostapp/manager.py:82:89: E501 Line too long (107 > 88)
   |
80 |                         'being that specified value.'),
81 |         cfg.StrOpt('cluster_name', default='', help='the name of consul cluster'),
82 |         cfg.StrOpt('encrypt', default='', help='the encrypt key for encryption of Consul network traffic'),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
83 |         cfg.StrOpt('verify_incoming', default='false', help='whether to verify consul incoming traffice'),
84 |         cfg.StrOpt('verify_outgoing', default='false', help='whether to verify consul outgoing traffice'),
   |

host/ha/hostapp/manager.py:83:89: E501 Line too long (106 > 88)
   |
81 |         cfg.StrOpt('cluster_name', default='', help='the name of consul cluster'),
82 |         cfg.StrOpt('encrypt', default='', help='the encrypt key for encryption of Consul network traffic'),
83 |         cfg.StrOpt('verify_incoming', default='false', help='whether to verify consul incoming traffice'),
   |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
84 |         cfg.StrOpt('verify_outgoing', default='false', help='whether to verify consul outgoing traffice'),
85 |         cfg.StrOpt('verify_server_hostname', default='false', help='whether to verify consul server name'),
   |

host/ha/hostapp/manager.py:84:89: E501 Line too long (106 > 88)
   |
82 |         cfg.StrOpt('encrypt', default='', help='the encrypt key for encryption of Consul network traffic'),
83 |         cfg.StrOpt('verify_incoming', default='false', help='whether to verify consul incoming traffice'),
84 |         cfg.StrOpt('verify_outgoing', default='false', help='whether to verify consul outgoing traffice'),
   |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
85 |         cfg.StrOpt('verify_server_hostname', default='false', help='whether to verify consul server name'),
86 |         cfg.StrOpt('ca_file_content', default='', help='base64 encoded consul CA cert content'),
   |

host/ha/hostapp/manager.py:85:89: E501 Line too long (107 > 88)
   |
83 |         cfg.StrOpt('verify_incoming', default='false', help='whether to verify consul incoming traffice'),
84 |         cfg.StrOpt('verify_outgoing', default='false', help='whether to verify consul outgoing traffice'),
85 |         cfg.StrOpt('verify_server_hostname', default='false', help='whether to verify consul server name'),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
86 |         cfg.StrOpt('ca_file_content', default='', help='base64 encoded consul CA cert content'),
87 |         cfg.StrOpt('cert_file_content', default='', help='base64 encoded consul server cert content'),
   |

host/ha/hostapp/manager.py:86:89: E501 Line too long (96 > 88)
   |
84 |         cfg.StrOpt('verify_outgoing', default='false', help='whether to verify consul outgoing traffice'),
85 |         cfg.StrOpt('verify_server_hostname', default='false', help='whether to verify consul server name'),
86 |         cfg.StrOpt('ca_file_content', default='', help='base64 encoded consul CA cert content'),
   |                                                                                         ^^^^^^^^ E501
87 |         cfg.StrOpt('cert_file_content', default='', help='base64 encoded consul server cert content'),
88 |         cfg.StrOpt('key_file_content', default='', help='base64 encoded consul server key content'),
   |

host/ha/hostapp/manager.py:87:89: E501 Line too long (102 > 88)
   |
85 |         cfg.StrOpt('verify_server_hostname', default='false', help='whether to verify consul server name'),
86 |         cfg.StrOpt('ca_file_content', default='', help='base64 encoded consul CA cert content'),
87 |         cfg.StrOpt('cert_file_content', default='', help='base64 encoded consul server cert content'),
   |                                                                                         ^^^^^^^^^^^^^^ E501
88 |         cfg.StrOpt('key_file_content', default='', help='base64 encoded consul server key content'),
89 |         cfg.StrOpt('consul_log_level', default='info', help='log level of consul agent'),
   |

host/ha/hostapp/manager.py:88:89: E501 Line too long (100 > 88)
   |
86 |         cfg.StrOpt('ca_file_content', default='', help='base64 encoded consul CA cert content'),
87 |         cfg.StrOpt('cert_file_content', default='', help='base64 encoded consul server cert content'),
88 |         cfg.StrOpt('key_file_content', default='', help='base64 encoded consul server key content'),
   |                                                                                         ^^^^^^^^^^^^ E501
89 |         cfg.StrOpt('consul_log_level', default='info', help='log level of consul agent'),
90 |         cfg.StrOpt('cluster_details', default='', help='the hosts and their ips in expected consul cluster')
   |

host/ha/hostapp/manager.py:89:89: E501 Line too long (89 > 88)
   |
87 |         cfg.StrOpt('cert_file_content', default='', help='base64 encoded consul server cert content'),
88 |         cfg.StrOpt('key_file_content', default='', help='base64 encoded consul server key content'),
89 |         cfg.StrOpt('consul_log_level', default='info', help='log level of consul agent'),
   |                                                                                         ^ E501
90 |         cfg.StrOpt('cluster_details', default='', help='the hosts and their ips in expected consul cluster')
91 |     ]
   |

host/ha/hostapp/manager.py:90:89: E501 Line too long (108 > 88)
   |
88 |         cfg.StrOpt('key_file_content', default='', help='base64 encoded consul server key content'),
89 |         cfg.StrOpt('consul_log_level', default='info', help='log level of consul agent'),
90 |         cfg.StrOpt('cluster_details', default='', help='the hosts and their ips in expected consul cluster')
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
91 |     ]
   |

host/ha/hostapp/manager.py:101:89: E501 Line too long (117 > 88)
    |
 99 |     CONF.register_opts(consul_opts, consul_grp)
100 |
101 |     role_balance_grp = cfg.OptGroup(name='consul_role_rebalance', title='group of options for consul_role_rebalance')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
102 |     role_balance_opts = [
103 |         cfg.StrOpt('role_rebalance_enabled', default='True', help='whether the auto rebalance is enabled'),
    |

host/ha/hostapp/manager.py:103:89: E501 Line too long (107 > 88)
    |
101 |     role_balance_grp = cfg.OptGroup(name='consul_role_rebalance', title='group of options for consul_role_rebalance')
102 |     role_balance_opts = [
103 |         cfg.StrOpt('role_rebalance_enabled', default='True', help='whether the auto rebalance is enabled'),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
104 |         cfg.StrOpt('amqp_host', default='localhost', help='the RPC host fqdn or ip'),
105 |         cfg.StrOpt('amqp_port', default='5672', help='the RPC host port'),
    |

host/ha/hostapp/manager.py:106:89: E501 Line too long (89 > 88)
    |
104 |         cfg.StrOpt('amqp_host', default='localhost', help='the RPC host fqdn or ip'),
105 |         cfg.StrOpt('amqp_port', default='5672', help='the RPC host port'),
106 |         cfg.StrOpt('amqp_user', default='', help='the user name for accessing RPC host'),
    |                                                                                         ^ E501
107 |         cfg.StrOpt('amqp_password', default='', help='the password for accessing RPC host'),
108 |         cfg.StrOpt('amqp_virtualhost', default='/', help='the RPC virtual host path'),
    |

host/ha/hostapp/manager.py:107:89: E501 Line too long (92 > 88)
    |
105 |         cfg.StrOpt('amqp_port', default='5672', help='the RPC host port'),
106 |         cfg.StrOpt('amqp_user', default='', help='the user name for accessing RPC host'),
107 |         cfg.StrOpt('amqp_password', default='', help='the password for accessing RPC host'),
    |                                                                                         ^^^^ E501
108 |         cfg.StrOpt('amqp_virtualhost', default='/', help='the RPC virtual host path'),
109 |         cfg.StrOpt('amqp_exchange_name', default='consul-role-rebalance-exchange', help='the RPC exchange name'),
    |

host/ha/hostapp/manager.py:109:89: E501 Line too long (113 > 88)
    |
107 |         cfg.StrOpt('amqp_password', default='', help='the password for accessing RPC host'),
108 |         cfg.StrOpt('amqp_virtualhost', default='/', help='the RPC virtual host path'),
109 |         cfg.StrOpt('amqp_exchange_name', default='consul-role-rebalance-exchange', help='the RPC exchange name'),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
110 |         cfg.StrOpt('amqp_exchange_type', default='topic', help='the RPC exchange type'),
111 |         cfg.StrOpt('amqp_routingkey_sending', default='receiving', help='the RPC message routing key for sending to du'),
    |

host/ha/hostapp/manager.py:111:89: E501 Line too long (121 > 88)
    |
109 |         cfg.StrOpt('amqp_exchange_name', default='consul-role-rebalance-exchange', help='the RPC exchange name'),
110 |         cfg.StrOpt('amqp_exchange_type', default='topic', help='the RPC exchange type'),
111 |         cfg.StrOpt('amqp_routingkey_sending', default='receiving', help='the RPC message routing key for sending to du'),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
112 |         cfg.StrOpt('amqp_routingkey_receiving', default='sending', help='the RPC message routing key for receiving from du')
113 |     ]
    |

host/ha/hostapp/manager.py:112:89: E501 Line too long (124 > 88)
    |
110 |         cfg.StrOpt('amqp_exchange_type', default='topic', help='the RPC exchange type'),
111 |         cfg.StrOpt('amqp_routingkey_sending', default='receiving', help='the RPC message routing key for sending to du'),
112 |         cfg.StrOpt('amqp_routingkey_receiving', default='sending', help='the RPC message routing key for receiving from du')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
113 |     ]
    |

host/ha/hostapp/manager.py:136:89: E501 Line too long (99 > 88)
    |
134 | def add_consul_secure_settings(conf):
135 |     conf['encrypt'] = CONF.consul.encrypt
136 |     conf['verify_incoming'] = True if str(CONF.consul.verify_incoming).lower() == 'true' else False
    |                                                                                         ^^^^^^^^^^^ E501
137 |     conf['verify_outgoing'] = True if str(CONF.consul.verify_outgoing).lower() == 'true' else False
138 |     conf['verify_server_hostname'] = True if str(CONF.consul.verify_server_hostname).lower() == 'true' else False
    |

host/ha/hostapp/manager.py:137:89: E501 Line too long (99 > 88)
    |
135 |     conf['encrypt'] = CONF.consul.encrypt
136 |     conf['verify_incoming'] = True if str(CONF.consul.verify_incoming).lower() == 'true' else False
137 |     conf['verify_outgoing'] = True if str(CONF.consul.verify_outgoing).lower() == 'true' else False
    |                                                                                         ^^^^^^^^^^^ E501
138 |     conf['verify_server_hostname'] = True if str(CONF.consul.verify_server_hostname).lower() == 'true' else False
139 |     if CONF.consul.ca_file_content:
    |

host/ha/hostapp/manager.py:138:89: E501 Line too long (113 > 88)
    |
136 |     conf['verify_incoming'] = True if str(CONF.consul.verify_incoming).lower() == 'true' else False
137 |     conf['verify_outgoing'] = True if str(CONF.consul.verify_outgoing).lower() == 'true' else False
138 |     conf['verify_server_hostname'] = True if str(CONF.consul.verify_server_hostname).lower() == 'true' else False
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
139 |     if CONF.consul.ca_file_content:
140 |         content = b64decode(CONF.consul.ca_file_content)
    |

host/ha/hostapp/manager.py:200:89: E501 Line too long (90 > 88)
    |
198 |             svr_file = PF9_CONSUL_CONF_DIR + 'conf.d/server.json'
199 |             if os.path.exists(svr_file):
200 |                 LOG.debug('remove server role file %s , which should not exist', svr_file)
    |                                                                                         ^^ E501
201 |                 os.remove(svr_file)
202 |         else:
    |

host/ha/hostapp/manager.py:229:89: E501 Line too long (90 > 88)
    |
227 |             clt_file = PF9_CONSUL_CONF_DIR + 'conf.d/client.json'
228 |             if os.path.exists(clt_file):
229 |                 LOG.debug('remove client role file %s , which should not exist', clt_file)
    |                                                                                         ^^ E501
230 |                 os.remove(clt_file)
231 |         LOG.debug('consul config file %s is now generated', cfg_file)
    |

host/ha/hostapp/manager.py:255:89: E501 Line too long (95 > 88)
    |
253 |         while service_start_retry > 0:
254 |             retcode = run_cmd('sudo service pf9-consul status')
255 |             LOG.debug('retcode of command "sudo service pf9-consul status" : %s', str(retcode))
    |                                                                                         ^^^^^^^ E501
256 |             if retcode == 0:
257 |                 LOG.warning('Consul service was already running. now stop it before start')
    |

host/ha/hostapp/manager.py:257:89: E501 Line too long (91 > 88)
    |
255 |             LOG.debug('retcode of command "sudo service pf9-consul status" : %s', str(retcode))
256 |             if retcode == 0:
257 |                 LOG.warning('Consul service was already running. now stop it before start')
    |                                                                                         ^^^ E501
258 |                 retcode = run_cmd('sudo service pf9-consul stop')
259 |                 LOG.debug('retcode of command "sudo service pf9-consul stop" : %s', str(retcode))
    |

host/ha/hostapp/manager.py:259:89: E501 Line too long (97 > 88)
    |
257 |                 LOG.warning('Consul service was already running. now stop it before start')
258 |                 retcode = run_cmd('sudo service pf9-consul stop')
259 |                 LOG.debug('retcode of command "sudo service pf9-consul stop" : %s', str(retcode))
    |                                                                                         ^^^^^^^^^ E501
260 |                 sleep(5)
    |

host/ha/hostapp/manager.py:266:89: E501 Line too long (103 > 88)
    |
264 |             pids = []
265 |             try:
266 |                 pidtxt = os.popen("ps -ef | grep consul | grep -v grep | awk \'{ print $2 }\'").read();
    |                                                                                         ^^^^^^^^^^^^^^^ E501
267 |                 LOG.debug('output of finding consul process id : %s', str(pidtxt))
268 |                 if pidtxt:
    |

host/ha/hostapp/manager.py:266:103: E703 [*] Statement ends with an unnecessary semicolon
    |
264 |             pids = []
265 |             try:
266 |                 pidtxt = os.popen("ps -ef | grep consul | grep -v grep | awk \'{ print $2 }\'").read();
    |                                                                                                       ^ E703
267 |                 LOG.debug('output of finding consul process id : %s', str(pidtxt))
268 |                 if pidtxt:
    |
    = help: Remove unnecessary semicolon

host/ha/hostapp/manager.py:279:89: E501 Line too long (94 > 88)
    |
277 |                     LOG.debug('kill consul process %s', str(pid))
278 |                     retcode = run_cmd('kill -9 %s' % str(pid))
279 |                     LOG.debug('consul process %s is killed ? %s', str(pid), str(retcode == 0))
    |                                                                                         ^^^^^^ E501
280 |
281 |             # the 'raft' and 'serf' folder have consul cached data, which
    |

host/ha/hostapp/manager.py:285:89: E501 Line too long (92 > 88)
    |
283 |             # them before restart the consul service
284 |             clean_consul_cache()
285 |             # when failed to start consul, check whether needs to repairs node-id or keyring
    |                                                                                         ^^^^ E501
286 |             # those are the two files messed up by consul itself
287 |             repair_consul_wiped_files_if_needed()
    |

host/ha/hostapp/manager.py:291:89: E501 Line too long (96 > 88)
    |
289 |             LOG.debug('start pf9-consul service using restart command')
290 |             retcode = run_cmd('sudo service pf9-consul restart')
291 |             LOG.debug('retcode of command "sudo service pf9-consul restart" : %s', str(retcode))
    |                                                                                         ^^^^^^^^ E501
292 |
293 |             # Sleep 3s to allow consul to fail in case the bootstrap server
    |

host/ha/hostapp/manager.py:324:5: E722 Do not use bare `except`
    |
322 |                 LOG.debug('remove consul cache folder %s', folder_path)
323 |                 rmtree(folder_path, ignore_errors=True)
324 |     except:
    |     ^^^^^^ E722
325 |         LOG.exception('unhandled exception when removing folder %s', folder_path)
    |

host/ha/hostapp/manager.py:342:22: E703 [*] Statement ends with an unnecessary semicolon
    |
340 |                 succeeded = True
341 |                 LOG.debug('command is succeeded : %s', str(cmd))
342 |                 break;
    |                      ^ E703
343 |         except Exception as e:
344 |             LOG.debug("command '%s' failed with exception : %s", str(cmd), str(e))
    |
    = help: Remove unnecessary semicolon

host/ha/hostapp/manager.py:367:89: E501 Line too long (96 > 88)
    |
365 |                                        **kwargs)
366 |     LOG.info('sending consul role rebalance response : %s', str(resp))
367 |     rebalance_mgr.send_rpc_message(resp, message_type=message_types.MSG_ROLE_REBALANCE_RESPONSE)
    |                                                                                         ^^^^^^^^ E501
368 |
369 |     # remove cached request file if needed
    |

host/ha/hostapp/manager.py:388:5: E722 Do not use bare `except`
    |
386 |             obj['status'] = new_status
387 |             json.dump(obj, fp)
388 |     except:
    |     ^^^^^^ E722
389 |         LOG.exception('unhandled exception when update status for cached request')
    |

host/ha/hostapp/manager.py:439:89: E501 Line too long (95 > 88)
    |
437 |         return True
438 |     else:
439 |         msg = 'unknown status in cached request %s : %s' % (cached_status, str(cached_request))
    |                                                                                         ^^^^^^^ E501
440 |         LOG.info("rebalance: removing request_file %s, as %s", request_file, msg)
441 |         os.remove(request_file)
    |

host/ha/hostapp/manager.py:459:89: E501 Line too long (90 > 88)
    |
457 |                                               current_host_id,
458 |                                               constants.RPC_TASK_STATE_FINISHED,
459 |                                               'already in expected role %s' % target_role,
    |                                                                                         ^^ E501
460 |                                               request_file)
461 |         return True
    |

host/ha/hostapp/manager.py:463:89: E501 Line too long (92 > 88)
    |
461 |         return True
462 |
463 |     LOG.info('rebalance: consul role needs to be switched to: %s, its role in cluster : %s',
    |                                                                                         ^^^^ E501
464 |              target_role, str(host_role))
    |

host/ha/hostapp/manager.py:537:89: E501 Line too long (89 > 88)
    |
536 |     # finally send response with finished status
537 |     msg = 'Successfully switched consul role from %s to %s' % (current_role, target_role)
    |                                                                                         ^ E501
538 |     LOG.info('%s',msg)
539 |     _update_request_status(request_file, 'done')
    |

host/ha/hostapp/manager.py:582:89: E501 Line too long (104 > 88)
    |
580 |                                          report='',
581 |                                          message='not a consul refresh request')
582 |             rebalance_mgr.send_rpc_message(resp, message_type=message_types.MSG_CONSUL_REFRESH_RESPONSE)
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
583 |             return
    |

host/ha/hostapp/manager.py:591:89: E501 Line too long (92 > 88)
    |
589 |             data = json.dumps({'request': request,
590 |                                'processed': False,
591 |                                'timestamp': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
    |                                                                                         ^^^^ E501
592 |                                'createdBy': hostid
593 |                                })
    |

host/ha/hostapp/manager.py:595:89: E501 Line too long (90 > 88)
    |
593 |                                })
594 |             global_consul_mgr.kv_update(key, data)
595 |             LOG.info('consul refresh request %s is stored in kv store : %s', req_id, data)
    |                                                                                         ^^ E501
596 |         else:
597 |             LOG.debug('consul refresh request %s already exist in kv store : %s', req_id, str(existing))
    |

host/ha/hostapp/manager.py:597:89: E501 Line too long (104 > 88)
    |
595 |             LOG.info('consul refresh request %s is stored in kv store : %s', req_id, data)
596 |         else:
597 |             LOG.debug('consul refresh request %s already exist in kv store : %s', req_id, str(existing))
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
598 |
599 |         # only leader can act on the request
    |

host/ha/hostapp/manager.py:602:89: E501 Line too long (135 > 88)
    |
600 | …er_leader()
601 | …
602 | …sponse for consul refresh request. leader %s', str(global_consul_mgr.cluster_leader()))
    |                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
603 | …
    |

host/ha/hostapp/manager.py:615:89: E501 Line too long (90 > 88)
    |
613 |                 value = json.loads(kv['Value'])
614 |                 if not value['processed']:
615 |                     timestamp = datetime.strptime(value['timestamp'], '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^ E501
616 |                     if (datetime.utcnow() - timestamp) < timedelta(seconds=120):
617 |                         valid_requests.append(value['request'])
    |

host/ha/hostapp/manager.py:619:89: E501 Line too long (98 > 88)
    |
617 |                         valid_requests.append(value['request'])
618 |                     else:
619 |                         LOG.debug('delete stabled processed consul refresh request from kv store')
    |                                                                                         ^^^^^^^^^^ E501
620 |                         global_consul_mgr.kv_delete(key)
621 |                 else:
    |

host/ha/hostapp/manager.py:622:89: E501 Line too long (94 > 88)
    |
620 |                         global_consul_mgr.kv_delete(key)
621 |                 else:
622 |                     LOG.debug('delete already processed consul refresh request from kv store')
    |                                                                                         ^^^^^^ E501
623 |                     global_consul_mgr.kv_delete(key)
    |

host/ha/hostapp/manager.py:629:89: E501 Line too long (92 > 88)
    |
628 |         for req in valid_requests:
629 |             LOG.debug('i am leader, now response for consul refresh request : %s', str(req))
    |                                                                                         ^^^^ E501
630 |             req_id = req['id']
631 |             req_type = req['type']
    |

host/ha/hostapp/manager.py:640:89: E501 Line too long (108 > 88)
    |
638 |                                              report=json.dumps(report),
639 |                                              message='')
640 |                 rebalance_mgr.send_rpc_message(resp, message_type=message_types.MSG_CONSUL_REFRESH_RESPONSE)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
641 |                 LOG.debug('consul refresh response is sent at %s : %s', str(datetime.utcnow()), str(resp))
642 |             else:
    |

host/ha/hostapp/manager.py:641:89: E501 Line too long (106 > 88)
    |
639 |                                              message='')
640 |                 rebalance_mgr.send_rpc_message(resp, message_type=message_types.MSG_CONSUL_REFRESH_RESPONSE)
641 |                 LOG.debug('consul refresh response is sent at %s : %s', str(datetime.utcnow()), str(resp))
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
642 |             else:
643 |                 LOG.warning('not a valid consul refresh request message: %s', str(req_type))
    |

host/ha/hostapp/manager.py:643:89: E501 Line too long (92 > 88)
    |
641 |                 LOG.debug('consul refresh response is sent at %s : %s', str(datetime.utcnow()), str(resp))
642 |             else:
643 |                 LOG.warning('not a valid consul refresh request message: %s', str(req_type))
    |                                                                                         ^^^^ E501
644 |             key = key_prefix + req_id
645 |             LOG.info('deleting consul refresh request %s from kv store', key)
    |

host/ha/hostapp/manager.py:648:89: E501 Line too long (93 > 88)
    |
646 |             global_consul_mgr.kv_delete(key)
647 |     except Exception as e:
648 |         LOG.exception('unhandled exception when process consul refresh request : %s', str(e))
    |                                                                                         ^^^^^ E501
649 |
650 | def on_consul_role_rebalance_request(role_rebalance_request):
    |

host/ha/hostapp/manager.py:657:89: E501 Line too long (95 > 88)
    |
656 |     cluster = CONF.consul.cluster_name
657 |     LOG.info('handle consul role rebalance request received : %s', str(role_rebalance_request))
    |                                                                                         ^^^^^^^ E501
658 |     if not role_rebalance_request:
659 |         LOG.warning('ignore empty consul role rebalance request')
    |

host/ha/hostapp/manager.py:663:89: E501 Line too long (97 > 88)
    |
661 |     msg_type = role_rebalance_request['type']
662 |     if msg_type != message_types.MSG_ROLE_REBALANCE_REQUEST:
663 |         LOG.warning('ignore non consul role rebalance request : %s', str(role_rebalance_request))
    |                                                                                         ^^^^^^^^^ E501
664 |         return
665 |     if str(role_rebalance_request['cluster']) != str(cluster):
    |

host/ha/hostapp/manager.py:666:89: E501 Line too long (107 > 88)
    |
664 |         return
665 |     if str(role_rebalance_request['cluster']) != str(cluster):
666 |         LOG.warning('ignore consul role rebalance request not for cluster %s but for %s: %s', str(cluster),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
667 |                  str(role_rebalance_request['cluster']), str(role_rebalance_request))
668 |         return
    |

host/ha/hostapp/manager.py:670:89: E501 Line too long (113 > 88)
    |
668 |         return
669 |     if role_rebalance_request['host_id'] != global_hostid:
670 |         LOG.warning('ignore consul role rebalance request not for me %s but for host %s: %s', str(global_hostid),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^ E501
671 |                  role_rebalance_request['host_id'], str(role_rebalance_request))
672 |         return
    |

host/ha/hostapp/manager.py:683:89: E501 Line too long (93 > 88)
    |
681 |     # when receives the request. the file will be deleted if the rpc message
682 |     # is processed, or retry failed, or the file is staled
683 |     request_file = os.path.join(PF9_CONSUL_DATA_DIR, 'req-%s' % role_rebalance_request['id'])
    |                                                                                         ^^^^^ E501
684 |     try:
685 |         data = {'created': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
    |

host/ha/hostapp/manager.py:697:89: E501 Line too long (96 > 88)
    |
695 |         with open(request_file, 'w') as fp:
696 |             fp.write(json.dumps(data))
697 |             LOG.info("cached rebalance request received '%s' to file '%s' for processing later",
    |                                                                                         ^^^^^^^^ E501
698 |                       str(role_rebalance_request), request_file)
699 |     except:
    |

host/ha/hostapp/manager.py:699:5: E722 Do not use bare `except`
    |
697 |             LOG.info("cached rebalance request received '%s' to file '%s' for processing later",
698 |                       str(role_rebalance_request), request_file)
699 |     except:
    |     ^^^^^^ E722
700 |         LOG.exception('unhandled exception in on_consul_role_rebalance_request')
    |

host/ha/hostapp/manager.py:716:89: E501 Line too long (109 > 88)
    |
714 |         return
715 |     if str(status_request['cluster']) != str(cluster):
716 |         LOG.warning('ignore consul refresh request which is not for cluster %s but for %s: %s', str(cluster),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
717 |                  str(status_request['cluster']), str(status_request))
718 |         return
    |

host/ha/hostapp/manager.py:720:89: E501 Line too long (103 > 88)
    |
718 |         return
719 |
720 |     LOG.info('received consul refresh request at %s : %s', str(datetime.utcnow()), str(status_request))
    |                                                                                         ^^^^^^^^^^^^^^^ E501
721 |     handle_consul_refresh_request(global_rpc_mgr, global_hostid, cluster=cluster, request=status_request)
    |

host/ha/hostapp/manager.py:721:89: E501 Line too long (105 > 88)
    |
720 |     LOG.info('received consul refresh request at %s : %s', str(datetime.utcnow()), str(status_request))
721 |     handle_consul_refresh_request(global_rpc_mgr, global_hostid, cluster=cluster, request=status_request)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
722 |
723 | def repair_consul_wiped_files_if_needed():
    |

host/ha/hostapp/manager.py:725:89: E501 Line too long (112 > 88)
    |
723 | def repair_consul_wiped_files_if_needed():
724 |     try:
725 |         # node-id should be created by consul itself, but observed that during power off then on scenario consul
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
726 |         # might wipe out its node-id, which cause it fails to start. in this case , need to manually create a node
727 |         # id for it, then restart consul will fix it
    |

host/ha/hostapp/manager.py:726:89: E501 Line too long (114 > 88)
    |
724 |     try:
725 |         # node-id should be created by consul itself, but observed that during power off then on scenario consul
726 |         # might wipe out its node-id, which cause it fails to start. in this case , need to manually create a node
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
727 |         # id for it, then restart consul will fix it
728 |         nodeid_file = os.path.join(PF9_CONSUL_DATA_DIR, 'node-id')
    |

host/ha/hostapp/manager.py:729:89: E501 Line too long (96 > 88)
    |
727 |         # id for it, then restart consul will fix it
728 |         nodeid_file = os.path.join(PF9_CONSUL_DATA_DIR, 'node-id')
729 |         # set to the host id when consul wiped its id, and assume CONF.host alwasy has the value
    |                                                                                         ^^^^^^^^ E501
730 |         nodeid = CONF.host
731 |         if not os.path.exists(nodeid_file):
    |

host/ha/hostapp/manager.py:736:89: E501 Line too long (100 > 88)
    |
734 |             # so assume it is there
735 |             with open(nodeid_file, 'w') as fp:
736 |                 LOG.debug('detected there is no consul node-id file, now create with id %s', nodeid)
    |                                                                                         ^^^^^^^^^^^^ E501
737 |                 fp.write(nodeid)
738 |         else:
    |

host/ha/hostapp/manager.py:745:89: E501 Line too long (90 > 88)
    |
743 |             if not nodeid_old:
744 |                 with open(nodeid_file, 'w') as fp:
745 |                     LOG.debug('detected consul node-id is empty, now write id %s', nodeid)
    |                                                                                         ^^ E501
746 |                     fp.write(nodeid)
747 |             else:
    |

host/ha/hostapp/manager.py:749:89: E501 Line too long (110 > 88)
    |
747 |             else:
748 |                 LOG.debug('skip node-id, as it is not empty : %s', str(nodeid_old))
749 |         # when node-id was wiped out, the same time the keyring were also wiped not (not sure why). so need to
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
750 |         # clean the serf folder, otherwise will get:
751 |         # "Failed to configure keyring: unexpected end of JSON input"
    |

host/ha/hostapp/manager.py:810:89: E501 Line too long (104 > 88)
    |
808 |             # reconcile settings and restart service. refresh does not
809 |             # make sense, by return False to stop refreshing
810 |             LOG.debug('found mismatch , but will not refesh, file %s,  CONF.consul.bootstrap_expect %s',
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
811 |                       str(file_name), str(CONF.consul.bootstrap_expect))
812 |             return False
    |

host/ha/hostapp/manager.py:841:89: E501 Line too long (107 > 88)
    |
840 |     if not os.path.exists(cfg_file):
841 |         LOG.debug('file %s not exist (bootstrap_expect : %s)', cfg_file, str(CONF.consul.bootstrap_expect))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
842 |         return True
    |

host/ha/hostapp/manager.py:846:89: E501 Line too long (91 > 88)
    |
844 |     with open(cfg_file, 'r') as fptr:
845 |         settings_consul = json.load(fptr)
846 |     LOG.debug('found settings of consul used from %s : %s', cfg_file, str(settings_consul))
    |                                                                                         ^^^ E501
847 |
848 |     # check whether settings in source do not exist or not match in consul settings
    |

host/ha/hostapp/manager.py:849:89: E501 Line too long (98 > 88)
    |
848 |     # check whether settings in source do not exist or not match in consul settings
849 |     if str(settings_source['advertise_addr']) != str(settings_consul.get('advertise_addr', None)):
    |                                                                                         ^^^^^^^^^^ E501
850 |         LOG.debug('detected changes in advertise_addr, source : %s , consul cfg : %s',
851 |                  settings_source['advertise_addr'],
    |

host/ha/hostapp/manager.py:859:89: E501 Line too long (90 > 88)
    |
857 |                  settings_consul.get('bind_addr', None))
858 |         return True
859 |     if str(settings_source['datacenter']) != str(settings_consul.get('datacenter', None)):
    |                                                                                         ^^ E501
860 |         LOG.debug('detected changes in datacenter, source : %s , consul cfg : %s',
861 |                  settings_source['datacenter'],
    |

host/ha/hostapp/manager.py:878:45: E712 Avoid equality comparisons to `False`; use `not os.path.exists(file_path):` for false checks
    |
876 |         content_key = item[1]
877 |
878 |         if settings_source[content_key] and os.path.exists(file_path) == False:
    |                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E712
879 |             LOG.debug('detected changes in file %s, source content: %s , consul cfg exists ?: %s',
880 |                      file_path,
    |
    = help: Replace with `not os.path.exists(file_path)`

host/ha/hostapp/manager.py:879:89: E501 Line too long (98 > 88)
    |
878 |         if settings_source[content_key] and os.path.exists(file_path) == False:
879 |             LOG.debug('detected changes in file %s, source content: %s , consul cfg exists ?: %s',
    |                                                                                         ^^^^^^^^^^ E501
880 |                      file_path,
881 |                      settings_source[content_key],
    |

host/ha/hostapp/manager.py:890:89: E501 Line too long (104 > 88)
    |
889 |         if file_content.encode() != b64decode(settings_source[content_key]):
890 |             LOG.info('detected changes in content in %s, source content: %s , consul cfg  content : %s',
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
891 |                      file_path,
892 |                      b64decode(settings_source[content_key]),
    |

host/ha/hostapp/manager.py:897:89: E501 Line too long (95 > 88)
    |
896 |     # consul log level
897 |     if str(settings_source['consul_log_level']) != str(settings_consul.get('log_level', None)):
    |                                                                                         ^^^^^^^ E501
898 |         LOG.debug('detected changes in consul_log_level, source : %s , consul cfg : %s',
899 |                  settings_source['consul_log_level'],
    |

host/ha/hostapp/manager.py:929:89: E501 Line too long (124 > 88)
    |
927 |             amqp_exchange = CONF.consul_role_rebalance.amqp_exchange_name
928 |             amqp_exchange_type = CONF.consul_role_rebalance.amqp_exchange_type
929 |             # queue name needs to be unique in order to get broadcast message from rabbitmq exchange in 'fanout' or 'direct'
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
930 |             # exchange type.
931 |             amqp_queue_for_receiving = 'queue-receiving-for-host-%s' % global_hostid
    |

host/ha/hostapp/manager.py:933:89: E501 Line too long (92 > 88)
    |
931 | …     amqp_queue_for_receiving = 'queue-receiving-for-host-%s' % global_hostid
932 | …     amqp_routingkey_sending = CONF.consul_role_rebalance.amqp_routingkey_sending
933 | …     amqp_routingkey_receiving = CONF.consul_role_rebalance.amqp_routingkey_receiving
    |                                                                                   ^^^^ E501
934 | …     parameters = 'host: %s, port: %s, user: %s, password: %s, exchange: %s, type: %s, queue: %s, send routing: %s, receiving routin…
935 | …         amqp_host, amqp_port, amqp_user, amqp_passwd, amqp_exchange, amqp_exchange_type,
    |

host/ha/hostapp/manager.py:934:89: E501 Line too long (149 > 88)
    |
932 | …rebalance.amqp_routingkey_sending
933 | …e_rebalance.amqp_routingkey_receiving
934 | … password: %s, exchange: %s, type: %s, queue: %s, send routing: %s, receiving routing: %s' % (
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
935 | …asswd, amqp_exchange, amqp_exchange_type,
936 | …ey_sending, amqp_routingkey_receiving
    |

host/ha/hostapp/manager.py:935:89: E501 Line too long (96 > 88)
    |
933 | …     amqp_routingkey_receiving = CONF.consul_role_rebalance.amqp_routingkey_receiving
934 | …     parameters = 'host: %s, port: %s, user: %s, password: %s, exchange: %s, type: %s, queue: %s, send routing: %s, receiving routin…
935 | …         amqp_host, amqp_port, amqp_user, amqp_passwd, amqp_exchange, amqp_exchange_type,
    |                                                                                   ^^^^^^^^ E501
936 | …         amqp_queue_for_receiving, amqp_routingkey_sending, amqp_routingkey_receiving
937 | …     )
    |

host/ha/hostapp/manager.py:936:89: E501 Line too long (92 > 88)
    |
934 | …     parameters = 'host: %s, port: %s, user: %s, password: %s, exchange: %s, type: %s, queue: %s, send routing: %s, receiving routin…
935 | …         amqp_host, amqp_port, amqp_user, amqp_passwd, amqp_exchange, amqp_exchange_type,
936 | …         amqp_queue_for_receiving, amqp_routingkey_sending, amqp_routingkey_receiving
    |                                                                                   ^^^^ E501
937 | …     )
938 | …     msg = 'create consul role rebalance RPC manager with : %s' % parameters
    |

host/ha/hostapp/manager.py:954:89: E501 Line too long (117 > 88)
    |
952 |             LOG.info('consul role rebalance RPC manager is created')
953 |
954 |             # to get better performance , rather than polling message from rabbitmq (which causes too much CPU usage)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
955 |             # redesign it to be event based by invoke callbacks once the driver received messages
956 |             # so here register the callbacks to handle the received messages
    |

host/ha/hostapp/manager.py:955:89: E501 Line too long (97 > 88)
    |
954 |             # to get better performance , rather than polling message from rabbitmq (which causes too much CPU usage)
955 |             # redesign it to be event based by invoke callbacks once the driver received messages
    |                                                                                         ^^^^^^^^^ E501
956 |             # so here register the callbacks to handle the received messages
957 |             global_rpc_mgr.subscribe_message(message_types.MSG_ROLE_REBALANCE_REQUEST, on_consul_role_rebalance_request)
    |

host/ha/hostapp/manager.py:957:89: E501 Line too long (120 > 88)
    |
955 |             # redesign it to be event based by invoke callbacks once the driver received messages
956 |             # so here register the callbacks to handle the received messages
957 |             global_rpc_mgr.subscribe_message(message_types.MSG_ROLE_REBALANCE_REQUEST, on_consul_role_rebalance_request)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
958 |             global_rpc_mgr.subscribe_message(message_types.MSG_CONSUL_REFRESH_REQUEST, on_consul_status_request)
959 |     except Exception:
    |

host/ha/hostapp/manager.py:958:89: E501 Line too long (112 > 88)
    |
956 |             # so here register the callbacks to handle the received messages
957 |             global_rpc_mgr.subscribe_message(message_types.MSG_ROLE_REBALANCE_REQUEST, on_consul_role_rebalance_request)
958 |             global_rpc_mgr.subscribe_message(message_types.MSG_CONSUL_REFRESH_REQUEST, on_consul_status_request)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
959 |     except Exception:
960 |         LOG.exception('unhandled exception when starting RPC manager')
    |

host/ha/hostapp/manager.py:975:89: E501 Line too long (98 > 88)
    |
973 |         LOG.debug('no cached requests, will check later')
974 |         return
975 |     LOG.info('handling cached rebalance requests under %s : %s ', PF9_CONSUL_DATA_DIR, str(files))
    |                                                                                         ^^^^^^^^^^ E501
976 |     # ideally there should be only one such file. but if there more , usually
977 |     # the latest file is the last request, we should only handle the latest one
    |

host/ha/hostapp/manager.py:992:89: E501 Line too long (111 > 88)
    |
990 |                         })
991 |     # sort them, latest on top
992 |     ordered = sorted(objects, key=lambda obj: datetime.strptime(obj['time'],'%Y-%m-%d %H:%M:%S'), reverse=True)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
993 |     LOG.debug('all cached requests : %s', str(ordered))
994 |     # remove old ones except the first (the latest)
    |

host/ha/hostapp/manager.py:1033:5: E722 Do not use bare `except`
     |
1031 |                                                                global_join_ips,
1032 |                                                                request_file)
1033 |     except:
     |     ^^^^^^ E722
1034 |         LOG.exception('unhandled exception from switch_to_new_consul_role')
1035 |     LOG.info('cached rebalance request completed successfully ? %s', str(global_skip_config_refresh))
     |

host/ha/hostapp/manager.py:1035:89: E501 Line too long (101 > 88)
     |
1033 |     except:
1034 |         LOG.exception('unhandled exception from switch_to_new_consul_role')
1035 |     LOG.info('cached rebalance request completed successfully ? %s', str(global_skip_config_refresh))
     |                                                                                         ^^^^^^^^^^^^^ E501
     |

host/ha/hostapp/manager.py:1065:89: E501 Line too long (102 > 88)
     |
1063 |         raise ha_exceptions.ConfigException('cluster_details is none')
1064 |     if len(cluster_details) != len(ips_to_join):
1065 |         raise ha_exceptions.ConfigException('num of hosts in join_ips does not match cluster_details')
     |                                                                                         ^^^^^^^^^^^^^^ E501
1066 |     if not set(ips_to_join).issubset(set([x['addr'] for x in cluster_details])):
1067 |         raise ha_exceptions.ConfigException('hosts in join_ips do not match cluster_details')
     |

host/ha/hostapp/manager.py:1067:89: E501 Line too long (93 > 88)
     |
1065 |         raise ha_exceptions.ConfigException('num of hosts in join_ips does not match cluster_details')
1066 |     if not set(ips_to_join).issubset(set([x['addr'] for x in cluster_details])):
1067 |         raise ha_exceptions.ConfigException('hosts in join_ips do not match cluster_details')
     |                                                                                         ^^^^^ E501
1068 |
1069 |     global_consul_mgr = consul_helper.consul_status(global_hostid, ips_to_join, cluster_details)
     |

host/ha/hostapp/manager.py:1069:89: E501 Line too long (96 > 88)
     |
1067 |         raise ha_exceptions.ConfigException('hosts in join_ips do not match cluster_details')
1068 |
1069 |     global_consul_mgr = consul_helper.consul_status(global_hostid, ips_to_join, cluster_details)
     |                                                                                         ^^^^^^^^ E501
1070 |     reporter = report.HaManagerReporter()
     |

host/ha/hostapp/manager.py:1119:89: E501 Line too long (107 > 88)
     |
1118 |                 if not cluster_configured:
1119 |                     # refresh the config file and restart consul, in case there is no leader or join failed
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
1120 |                     # this happens when consul settings are updated through resmgr after consul had started
1121 |                     # so need to re-config the settings and re-start consul
     |

host/ha/hostapp/manager.py:1120:89: E501 Line too long (107 > 88)
     |
1118 |                 if not cluster_configured:
1119 |                     # refresh the config file and restart consul, in case there is no leader or join failed
1120 |                     # this happens when consul settings are updated through resmgr after consul had started
     |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
1121 |                     # so need to re-config the settings and re-start consul
1122 |                     generate_consul_conf(CONF.consul.bootstrap_expect > 0)
     |

host/ha/hostapp/manager.py:1132:89: E501 Line too long (89 > 88)
     |
1130 |                         sleep(sleep_time)
1131 |                         continue
1132 |                     LOG.info('trying to join consul cluster members %s', global_join_ips)
     |                                                                                         ^ E501
1133 |                     retcode = run_cmd('consul join {ip}'.format(ip=global_join_ips))
1134 |                     leader = None
     |

host/ha/hostapp/manager.py:1141:89: E501 Line too long (89 > 88)
     |
1139 |                             cluster_configured = True
1140 |                             global_consul_mgr.log_kvstore()
1141 |                             LOG.info('joined consul cluster with leader %s', str(leader))
     |                                                                                         ^ E501
1142 |                     if not leader or retcode != 0:
1143 |                         cluster_configured = False
     |

host/ha/hostapp/manager.py:1144:89: E501 Line too long (99 > 88)
     |
1142 |                     if not leader or retcode != 0:
1143 |                         cluster_configured = False
1144 |                         LOG.error('joining consul cluster failed, retcode %s, leader %s. Retrying',
     |                                                                                         ^^^^^^^^^^^ E501
1145 |                                  str(retcode), str(leader))
     |

host/ha/hostapp/manager.py:1158:89: E501 Line too long (102 > 88)
     |
1156 |                     cluster_stat = global_consul_mgr.get_cluster_status()
1157 |                     if cluster_stat:
1158 |                         LOG.info('i am leader %s, found changes : %s', str(leader), str(cluster_stat))
     |                                                                                         ^^^^^^^^^^^^^^ E501
1159 |                         LOG.debug('cluster_stat: %s', cluster_stat)
1160 |                         if reporter.report_status(cluster_stat):
     |

host/ha/hostapp/manager.py:1168:89: E501 Line too long (98 > 88)
     |
1166 |                             LOG.error('reporting consul status to hamgr failed')
1167 |                     else:
1168 |                         LOG.debug('i am leader %s, but no changes to report for now', str(leader))
     |                                                                                         ^^^^^^^^^^ E501
1169 |                     global_consul_mgr.log_kvstore()
1170 |                     global_consul_mgr.cleanup_consul_kv_store()
     |

host/ha/hostapp/pf9_ha.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import argparse
16 | | from glob import glob
17 | |
18 | | from ha.hostapp import manager
19 | | from oslo_config import cfg
20 | |
21 | | from ha.utils.log import setup_root_logger
   | |__________________________________________^ I001
22 |
23 |   CONF_DIR = '/etc/vm-ha-helper'
   |
   = help: Organize imports

host/ha/tests/test_consul_status.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | | import uuid
17 | | import mock
18 | | import time
19 | | import json
20 | | import sys
   | |__________^ I001
21 |
22 |   g_consul_member_ids = [
   |
   = help: Organize imports

host/ha/tests/test_consul_status.py:250:89: E501 Line too long (102 > 88)
    |
248 |         my_module = importlib.import_module('ha.utils.consul_helper')
249 |         my_class = getattr(my_module, 'consul_status')
250 |         self._consul_helper = my_class(g_host_id, g_join_ips.strip(' ').split(' '), g_cluster_details)
    |                                                                                         ^^^^^^^^^^^^^^ E501
251 |         self._consul_helper.leader = True
    |

host/ha/tests/test_consul_status.py:288:89: E501 Line too long (98 > 88)
    |
286 |         g_logger('checking report for host %s with status %s', xid, host_status)
287 |         status = self._consul_helper.get_cluster_status()
288 |         msg = 'status %s for host %s is reported ? %s' % (str(host_status), str(xid), str(status))
    |                                                                                         ^^^^^^^^^^ E501
289 |         g_logger('%s', msg)
290 |         self.assertIsNotNone(status, msg)
    |

host/ha/tests/test_consul_status.py:373:89: E501 Line too long (103 > 88)
    |
371 |         # make second host down then up
372 |         host_index = 1
373 |         g_logger('verify host down then up for host : %s',g_consul_cache[host_index]["Value"].decode())
    |                                                                                         ^^^^^^^^^^^^^^^ E501
374 |         self._assert_host_down_then_up(host_index)
    |

host/ha/tests/test_consul_status.py:383:89: E501 Line too long (98 > 88)
    |
381 |         while host_index < 4:
382 |             # simulate host down then up, for all hosts, one by one
383 |             g_logger('verify host %s down then up ', g_consul_cache[host_index]["Value"].decode())
    |                                                                                         ^^^^^^^^^^ E501
384 |             self._assert_host_down_then_up(host_index)
    |

host/ha/tests/test_manager.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import os
16 | | import sys
17 | | import unittest
18 | | import uuid
19 | | import mock
20 | | import time
21 | | import json
22 | | import shutil
23 | | import logging
24 | | from oslo_config import cfg
   | |___________________________^ I001
25 |
26 |   LOG = logging.getLogger(__name__)
   |
   = help: Organize imports

host/ha/tests/test_manager.py:18:8: F401 [*] `uuid` imported but unused
   |
16 | import sys
17 | import unittest
18 | import uuid
   |        ^^^^ F401
19 | import mock
20 | import time
   |
   = help: Remove unused import: `uuid`

host/ha/tests/test_manager.py:20:8: F401 [*] `time` imported but unused
   |
18 | import uuid
19 | import mock
20 | import time
   |        ^^^^ F401
21 | import json
22 | import shutil
   |
   = help: Remove unused import: `time`

host/ha/tests/test_manager.py:21:8: F401 [*] `json` imported but unused
   |
19 | import mock
20 | import time
21 | import json
   |        ^^^^ F401
22 | import shutil
23 | import logging
   |
   = help: Remove unused import: `json`

host/ha/tests/test_manager.py:45:89: E501 Line too long (390 > 88)
   |
44 | …
45 | …0.86.25,10.80.86.40,10.80.86.34,10.80.86.43,10.80.86.44,10.80.86.42,10.80.86.45,10.80.86.22,10.80.86.37,10.80.86.48,10.80.86.41,10.80.86.29,10.80.86.23,10.80.86.49,10.80.86.39,10.80.86.52,10.80.86.28,10.80.86.32,10.80.86.33,10.80.86.35,10.80.86.38,10.80.86.21,10.80.86.26,10.80.86.50,10.80.86.30,10.80.86.24
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
46 | …
47 | …
   |

host/ha/tests/test_manager.py:49:89: E501 Line too long (2259 > 88)
   |
47 | …
48 | …
49 | …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
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
50 | …
51 | …DRUFBd0RRWUpLb1pJaHZjTkFRRUZCUUF3RURFT01Bd0dBMVVFQXd3RlpXSnoKWTI4d0hoY05NVGt3TlRFMU1UTXdORFUzV2hjTk5EWXdPVEk1TVRNd05EVTNXakFqTVE0d0RBWURWUVFEREFWbApZbk5qYnpFUk1BOEdBMVVFQ2d3SWMyVnlkbWxqWlhNd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUJEd0F3CmdnRUtBb0lCQVFDZmdJOHdaMGQzcW5TUXVBOW1HUzBiM1FhWGk1Nzh1WFRJV2lac1VNMzVJZHYxTFpORlNKdkYKanlwOXJsU040UFY0RUpvVUl2MFVEVCt3cU9lYUg3ejdsVlVXbFFWUVlMNk4yTVc3ZXY0ZWFxVVpSWEc4aEVYcgpLNmhUaUpraGVVU1JuWVFKMHRLdFJGZXJGbnpOdmxONDAyTkRSNWVUWGZaak4rdnU3THNkODZ2aUNnTkZucTl1CmZ6ZEpkUEFad2w1QVpNYk1qdXkrVXRMdmlIblQ5K3VvTWQydmY3VisxUTZsWWZzS3RyeXNCOWVFb05vQ2dYamcKNy9jU0FZWW9ERzVYVFlJaGZMTExpYmZSbFY1V3U2d2lxRGFIWGwyWlM5cGo1Qk81R0dEZ0t1eVpucjk4OG0rbQpneG1aa0hzeTE4aWs2cEV6a080WHJ1a0M0UWpYSjc5WkFnTUJBQUdqTHpBdE1Ba0dBMVVkRXdRQ01BQXdDd1lEClZSMFBCQVFEQWdVZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TUJNQTBHQ1NxR1NJYjNEUUVCQlFVQUE0SUIKQVFBU2k2eWR2eVVrVmFxRlp5RUZONlJWSjZPNXgza2xiYlJCT0twditPYzJhWjVwakhiSzFJbFk2STYxaHljOApwakJjL0ljTmFma256VnVjUmxLMlFGZGw0VzF2Rks4azJma1kyOFd1QXVXWmp6YzZqWHMrenZYRVM1NTAxMzlkCjg1NXczNXpBekNIV1IzNzBQNUVLdktNS0Y1OStZRUNaaWtUM3R3dTFydUZXa2FGZ0FwREhKM1V6YWZ6WGVIdGkKbzlGMHNYWXA0YnVJVkZkaGR5ajBoS1ZCMnFJUDRBNXdpcEsrdDViQ0xtcTUwTjljVVpuTjdlcVdFRCtLZzl0WAoyWkMrVFVRN0FQQlZvYjBsMm54NXdOU21mYWZINy9KeDdMeWU0azJIK1BtVDUrVThJOTAyVWFpTi9zVUlGRDNlClczU1dBNVNWVm9jS1l5ZEVzR25oQyt6bwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
   |

host/ha/tests/test_manager.py:51:89: E501 Line too long (1428 > 88)
   |
49 | …bjRDUE1HZEhkNnAwa0xnUFpoa3RHOTBHbDR1ZS9MbDB5Rm9tYkZETitTSGI5UzJUClJVaWJ4WThxZmE1VWplRDFlQkNhRkNMOUZBMC9zS2pubWgrOCs1VlZGcFVGVUdDK2pkakZ1M3IrSG1xbEdVVngKdklSRjZ5dW9VNGlaSVhsRWtaMkVDZExTclVSWHF4Wjh6YjVUZU5OalEwZVhrMTMyWXpmcjd1eTdIZk9yNGdvRApSWjZ2Ym44M1NYVHdHY0plUUdUR3pJN3N2bExTNzRoNTAvZnJxREhkcjMrMWZ0VU9wV0g3Q3JhOHJBZlhoS0RhCkFvRjQ0Ty8zRWdHR0tBeHVWMDJDSVh5eXk0bTMwWlZlVnJ1c0lxZzJoMTVkbVV2YVkrUVR1UmhnNENyc21aNi8KZlBKdnBvTVptWkI3TXRmSXBPcVJNNUR1RjY3cEF1RUkxeWUvV1FJREFRQUJBb0lCQVFDWitQL0JLU0liaWNmbQo0RmUxSnI2ZDlEcmwxbG1PKy9TWmFEVkpRS1BsU09OT0JrWHhqd3NZcG9ETlBKblJNSVdsOXRqV2NZUS9kQjYwCmlnaXhoc3ZuVFp3TEphWXdsb084NkxMUXJnVmNGWFQxTlUxN1AzRkRlU3lRSHdBOENSWEJQLzV6Z1RueEcxVksKQ25aR0l1SHZkSmlSSFM1Y2kwdExNbk9tZkk2UmROOWFSUGJJcFFyYURieUhzYk5hZFVOclJISFFMREpaMHVyUApFeVZ5b3ZTcDBOMnpOQTRJYWJ6YThVampVa25aTHZPOFRPV3duYzFSR0RmcDB0elpuMS83WmFmL1hCYzB3amFTClVVZ2pMd2V3LzMwYktsUEhLSnZvdDZKeXJXeFozVGNicDNpUnlwVUJHeG5kbWVyMk1CQ2k2NXVtZDZTaUgwNWIKc0pIWVExMWxBb0dCQU5JNHBlb3g5VElSS2loOUhrM0N2Rm84Z1RWaWNGMkxqcFhHM2Y2VitkVCs3T2U1RmZHNApveENlQmhrd29FQUVvZDBTT3dLSzFjMVZ1d3htOGJOcTcvYjFzdlVYVGhsNXpCcVJRSkE3VDZLZktCNC9oMWNXCmxxMGJIOGhqVnNmODV4cHFCSkhSM3c5dkhabFp5dEhONllFNmFsdUdkYmEzTmdDKzZkNDE4Q3NEQW9HQkFNSTgKY0VEYTdtWXJlU3FJOXJkbHFrbG01UDMzZW8vV2FycDRVaWNtTnIzd2I4TWtnLzBzOEs1aEdkcEVNSXl3S3ZrVwpFelJsaWxmMzU2Yy84Y3k1UkNHbVRFNklxNW1tMXg4em1nYTRLMlFvbDNSbmE3L3A4NjJzWk…
50 | …
51 | …DRUFBd0RRWUpLb1pJaHZjTkFRRUZCUUF3RURFT01Bd0dBMVVFQXd3RlpXSnoKWTI4d0hoY05NVGt3TlRFMU1UTXdORFUzV2hjTk5EWXdPVEk1TVRNd05EVTNXakFqTVE0d0RBWURWUVFEREFWbApZbk5qYnpFUk1BOEdBMVVFQ2d3SWMyVnlkbWxqWlhNd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUJEd0F3CmdnRUtBb0lCQVFDZmdJOHdaMGQzcW5TUXVBOW1HUzBiM1FhWGk1Nzh1WFRJV2lac1VNMzVJZHYxTFpORlNKdkYKanlwOXJsU040UFY0RUpvVUl2MFVEVCt3cU9lYUg3ejdsVlVXbFFWUVlMNk4yTVc3ZXY0ZWFxVVpSWEc4aEVYcgpLNmhUaUpraGVVU1JuWVFKMHRLdFJGZXJGbnpOdmxONDAyTkRSNWVUWGZaak4rdnU3THNkODZ2aUNnTkZucTl1CmZ6ZEpkUEFad2w1QVpNYk1qdXkrVXRMdmlIblQ5K3VvTWQydmY3VisxUTZsWWZzS3RyeXNCOWVFb05vQ2dYamcKNy9jU0FZWW9ERzVYVFlJaGZMTExpYmZSbFY1V3U2d2lxRGFIWGwyWlM5cGo1Qk81R0dEZ0t1eVpucjk4OG0rbQpneG1aa0hzeTE4aWs2cEV6a080WHJ1a0M0UWpYSjc5WkFnTUJBQUdqTHpBdE1Ba0dBMVVkRXdRQ01BQXdDd1lEClZSMFBCQVFEQWdVZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TUJNQTBHQ1NxR1NJYjNEUUVCQlFVQUE0SUIKQVFBU2k2eWR2eVVrVmFxRlp5RUZONlJWSjZPNXgza2xiYlJCT0twditPYzJhWjVwakhiSzFJbFk2STYxaHljOApwakJjL0ljTmFma256VnVjUmxLMlFGZGw0VzF2Rks4azJma1kyOFd1QXVXWmp6YzZqWHMrenZYRVM1NTAxMzlkCjg1NXczNXpBekNIV1IzNzBQNUVLdktNS0Y1OStZRUNaaWtUM3R3dTFydUZXa2FGZ0FwREhKM1V6YWZ6WGVIdGkKbzlGMHNYWXA0YnVJVkZkaGR5ajBoS1ZCMnFJUDRBNXdpcEsrdDViQ0xtcTUwTjljVVpuTjdlcVdFRCtLZzl0WAoyWkMrVFVRN0FQQlZvYjBsMm54NXdOU21mYWZINy9KeDdMeWU0azJIK1BtVDUrVThJOTAyVWFpTi9zVUlGRDNlClczU1dBNVNWVm9jS1l5ZEVzR25oQyt6bwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
52 | …
53 | …UxhY3QzaHpKamZNTUEwR0NTcUdTSWIzRFFFQkJRVUFNQkF4RGpBTUJnTlYKQkFNTUJXVmljMk52TUI0WERURTVNRFV4TlRFek1EUTFNMW9YRFRRMk1Ea3lPVEV6TURRMU0xb3dFREVPTUF3RwpBMVVFQXd3RlpXSnpZMjh3Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRQzJhZHBFCktsbnZuUVNzQVVSUUYxc1NpcGtTaEl3TXd3cHoxUmJVOWhUd25KWUxzN2hPZ0gveGZnbmg3c3FvV0tZSjNCVEoKd2RXVk5ONFZrK1V3OGlPMVQrSzFBZG54cUlGTFo3eEd1ZHZkb0hRQ1d2emhIVE56c205L1gzQW1OSTNHSmNDagp3RUJSNE1JVUxYSFNZNzFWRkZSTkpLWGw2OHR4eS9JQUttQm5hME5WeWNRUksvZ0R4dHAvZ0ozKzNac1I5QmsxCk8wNHBOajNUOThhRVBPRFp0bG9YMkFpN0hNY3poeTQwOVgvSUlQVTFVRXc2b3dYQ05PRlY3YjJwMU51emR1TzcKQU1YN3h5UjR4L3k3YThlQk1hRmduY2l6eTB6aWt1aENCZmg1V21QdXQ0ZnZkQVN2b1owZGhqUFVVdzRNWkFuSQpJUjdmc3oyeEc1YngxUWwzQWdNQkFBR2pIVEFiTUF3R0ExVWRFd1FGTUFNQkFmOHdDd1lEVlIwUEJBUURBZ0VHCk1BMEdDU3FHU0liM0RRRUJCUVVBQTRJQkFRQjB0MGVMS3A0Uk05aWFBTWJHRG5HTVlvVjZ0SnhKYWlrNXY4YUsKQkJpTFA1RExua2NWeVhIalIyeEY5VXo3TWVtei9HeTFXM24rNlRRemJxNGhJVEIwSkdpQTYrbUR6bm5qZjRoSwpqU2szK1ZrZjhQSmZWYnNZRXlEbzJSQ3ZMc3Q1bHRSVGN4SVF6eExtY1dBbFpjRVhDWTc2clFOejRqRnA0SE5XCjdYRW1Kd2pyTWhIcUF6a0MxWFhMb0tReUVhMmJsWW9WeUZhaE1KTVJOaWlLeGNpZ0Y1dVpuaTVkZFZjQlJuWVQKNTcxOGV3L1EwQ0IrUG9GSWpnL2hLdEpLS05RSWtxZ2lKVmlzbVl4MXdxNXVVMEJnTmx4YnZCN3ZWNXZzNlpYNQptUzZmcnByaXAzWjExcms1SFpvS3NVM0h6UUhNeWVNU3E5aGd4aTMwbWlzVmc0MHEKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
   |

host/ha/tests/test_manager.py:53:89: E501 Line too long (1370 > 88)
   |
51 | …DRUFBd0RRWUpLb1pJaHZjTkFRRUZCUUF3RURFT01Bd0dBMVVFQXd3RlpXSnoKWTI4d0hoY05NVGt3TlRFMU1UTXdORFUzV2hjTk5EWXdPVEk1TVRNd05EVTNXakFqTVE0d0RBWURWUVFEREFWbApZbk5qYnpFUk1BOEdBMVVFQ2d3SWMyVnlkbWxqWlhNd2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUJEd0F3CmdnRUtBb0lCQVFDZmdJOHdaMGQzcW5TUXVBOW1HUzBiM1FhWGk1Nzh1WFRJV2lac1VNMzVJZHYxTFpORlNKdkYKanlwOXJsU040UFY0RUpvVUl2MFVEVCt3cU9lYUg3ejdsVlVXbFFWUVlMNk4yTVc3ZXY0ZWFxVVpSWEc4aEVYcgpLNmhUaUpraGVVU1JuWVFKMHRLdFJGZXJGbnpOdmxONDAyTkRSNWVUWGZaak4rdnU3THNkODZ2aUNnTkZucTl1CmZ6ZEpkUEFad2w1QVpNYk1qdXkrVXRMdmlIblQ5K3VvTWQydmY3VisxUTZsWWZzS3RyeXNCOWVFb05vQ2dYamcKNy9jU0FZWW9ERzVYVFlJaGZMTExpYmZSbFY1V3U2d2lxRGFIWGwyWlM5cGo1Qk81R0dEZ0t1eVpucjk4OG0rbQpneG1aa0hzeTE4aWs2cEV6a080WHJ1a0M0UWpYSjc5WkFnTUJBQUdqTHpBdE1Ba0dBMVVkRXdRQ01BQXdDd1lEClZSMFBCQVFEQWdVZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TUJNQTBHQ1NxR1NJYjNEUUVCQlFVQUE0SUIKQVFBU2k2eWR2eVVrVmFxRlp5RUZONlJWSjZPNXgza2xiYlJCT0twditPYzJhWjVwakhiSzFJbFk2STYxaHljOApwakJjL0ljTmFma256VnVjUmxLMlFGZGw0VzF2Rks4azJma1kyOFd1QXVXWmp6YzZqWHMrenZYRVM1NTAxMzlkCjg1NXczNXpBekNIV1IzNzBQNUVLdktNS0Y1OStZRUNaaWtUM3R3dTFydUZXa2FGZ0FwREhKM1V6YWZ6WGVIdGkKbzlGMHNYWXA0YnVJVkZkaGR5ajBoS1ZCMnFJUDRBNXdpcEsrdDViQ0xtcTUwTjljVVpuTjdlcVdFRCtLZzl0WAoyWkMrVFVRN0FQQlZvYjBsMm54NXdOU21mYWZINy9KeDdMeWU0azJIK1BtVDUrVThJOTAyVWFpTi9zVUlGRDNlClczU1dBNVNWVm9jS1l…
52 | …
53 | …UxhY3QzaHpKamZNTUEwR0NTcUdTSWIzRFFFQkJRVUFNQkF4RGpBTUJnTlYKQkFNTUJXVmljMk52TUI0WERURTVNRFV4TlRFek1EUTFNMW9YRFRRMk1Ea3lPVEV6TURRMU0xb3dFREVPTUF3RwpBMVVFQXd3RlpXSnpZMjh3Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRQzJhZHBFCktsbnZuUVNzQVVSUUYxc1NpcGtTaEl3TXd3cHoxUmJVOWhUd25KWUxzN2hPZ0gveGZnbmg3c3FvV0tZSjNCVEoKd2RXVk5ONFZrK1V3OGlPMVQrSzFBZG54cUlGTFo3eEd1ZHZkb0hRQ1d2emhIVE56c205L1gzQW1OSTNHSmNDagp3RUJSNE1JVUxYSFNZNzFWRkZSTkpLWGw2OHR4eS9JQUttQm5hME5WeWNRUksvZ0R4dHAvZ0ozKzNac1I5QmsxCk8wNHBOajNUOThhRVBPRFp0bG9YMkFpN0hNY3poeTQwOVgvSUlQVTFVRXc2b3dYQ05PRlY3YjJwMU51emR1TzcKQU1YN3h5UjR4L3k3YThlQk1hRmduY2l6eTB6aWt1aENCZmg1V21QdXQ0ZnZkQVN2b1owZGhqUFVVdzRNWkFuSQpJUjdmc3oyeEc1YngxUWwzQWdNQkFBR2pIVEFiTUF3R0ExVWRFd1FGTUFNQkFmOHdDd1lEVlIwUEJBUURBZ0VHCk1BMEdDU3FHU0liM0RRRUJCUVVBQTRJQkFRQjB0MGVMS3A0Uk05aWFBTWJHRG5HTVlvVjZ0SnhKYWlrNXY4YUsKQkJpTFA1RExua2NWeVhIalIyeEY5VXo3TWVtei9HeTFXM24rNlRRemJxNGhJVEIwSkdpQTYrbUR6bm5qZjRoSwpqU2szK1ZrZjhQSmZWYnNZRXlEbzJSQ3ZMc3Q1bHRSVGN4SVF6eExtY1dBbFpjRVhDWTc2clFOejRqRnA0SE5XCjdYRW1Kd2pyTWhIcUF6a0MxWFhMb0tReUVhMmJsWW9WeUZhaE1KTVJOaWlLeGNpZ0Y1dVpuaTVkZFZjQlJuWVQKNTcxOGV3L1EwQ0IrUG9GSWpnL2hLdEpLS05RSWtxZ2lKVmlzbVl4MXdxNXVVMEJnTmx4YnZCN3ZWNXZzNlpYNQptUzZmcnByaXAzWjExcms1SFpvS3NVM0h6UUhNeWVNU3E5aGd4aTMwbWlzVmc0MHEKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
   |       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
54 | …
55 | …
   |

host/ha/utils/consul_helper.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import json
16 | | import logging
17 | | import os
18 | | import re
19 | | from datetime import datetime
20 | | from datetime import timedelta
21 | | from uuid import uuid4
22 | |
23 | | import consul
24 | | from netifaces import AF_INET
25 | | from netifaces import gateways
26 | | from netifaces import ifaddresses
27 | | from oslo_config import cfg
28 | |
29 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
30 |
31 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

host/ha/utils/consul_helper.py:156:9: E722 Do not use bare `except`
    |
154 |             c_obj = obj['consul']
155 |             return cls(e_obj, c_obj)
156 |         except:
    |         ^^^^^^ E722
157 |             LOG.exception('failed to parse json string : %s ', str(string))
158 |         return None
    |

host/ha/utils/consul_helper.py:261:89: E501 Line too long (107 > 88)
    |
260 |         for member in members:
261 |             LOG.debug('member name %s addr %s status %s', str(member.get('Name')), str(member.get('Addr')),
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
262 |                       str(member.get('Status')))
263 |             if member.get('Status', 4) == 1:
    |

host/ha/utils/consul_helper.py:270:89: E501 Line too long (112 > 88)
    |
268 |                 event_type = 2
269 |
270 |             node_info = {"Name": member.get("Name"), "Addr": member.get("Addr"), "Status": member.get("Status")}
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
271 |             members_info.append(node_info)
    |

host/ha/utils/consul_helper.py:278:89: E501 Line too long (100 > 88)
    |
276 |                 # without the host id does not work hence skip this host.
277 |                 # LOG.warning('host %s is not registered in kv store', key)
278 |                 msg = 'ignore host %s with ip %s, which is not expected to be in consul cluster' % \
    |                                                                                         ^^^^^^^^^^^^ E501
279 |                       (str(member.get('Name')), str(member.get('Addr')))
280 |                 LOG.warning(msg)
    |

host/ha/utils/consul_helper.py:310:89: E501 Line too long (112 > 88)
    |
308 |         LOG.info('latest cluster members info : %s', str(members_info))
309 |         if len(self.hosts_ips) != len(members_info):
310 |             LOG.warning('num of consul members is not equal to num of expected hosts : %s', str(self.hosts_ips))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
311 |         LOG.debug('latest cluster status report from consul members : %s', str(cluster_report))
312 |         return cluster_report
    |

host/ha/utils/consul_helper.py:311:89: E501 Line too long (95 > 88)
    |
309 |         if len(self.hosts_ips) != len(members_info):
310 |             LOG.warning('num of consul members is not equal to num of expected hosts : %s', str(self.hosts_ips))
311 |         LOG.debug('latest cluster status report from consul members : %s', str(cluster_report))
    |                                                                                         ^^^^^^^ E501
312 |         return cluster_report
    |

host/ha/utils/consul_helper.py:321:89: E501 Line too long (91 > 88)
    |
319 |                  'cached changes : %s', str(self.changed_clusters))
320 |         for _, change in self.changed_clusters.items():
321 |             detectedAt = datetime.strptime(change.event['detectedAt'], "%Y-%m-%d %H:%M:%S")
    |                                                                                         ^^^ E501
322 |             hostname = change.event['hostName']
323 |             if datetime.utcnow() - detectedAt > report_interval:
    |

host/ha/utils/consul_helper.py:329:89: E501 Line too long (120 > 88)
    |
327 |                 LOG.debug('checking detected change : %s', str(change))
328 |                 if (addr not in current_addrs) or \
329 |                         (addr in current_addrs and current_state[addr].event['eventType'] == change.event['eventType']):
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
330 |                     if addr not in current_state:
331 |                         LOG.warning('host %s was not returned from consul cluster, still try to report event : %s',
    |

host/ha/utils/consul_helper.py:331:89: E501 Line too long (115 > 88)
    |
329 |                         (addr in current_addrs and current_state[addr].event['eventType'] == change.event['eventType']):
330 |                     if addr not in current_state:
331 |                         LOG.warning('host %s was not returned from consul cluster, still try to report event : %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
332 |                                  hostname, str(current_state))
333 |                     if change.event['reported']:
    |

host/ha/utils/consul_helper.py:336:89: E501 Line too long (108 > 88)
    |
334 |                         staled = False
335 |                         if change.event['reportedAt']:
336 |                             reported_at = datetime.strptime(change.event['reportedAt'], "%Y-%m-%d %H:%M:%S")
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
337 |                             staled = True if datetime.utcnow() - reported_at > self.reap_interval else False
    |

host/ha/utils/consul_helper.py:337:89: E501 Line too long (108 > 88)
    |
335 |                         if change.event['reportedAt']:
336 |                             reported_at = datetime.strptime(change.event['reportedAt'], "%Y-%m-%d %H:%M:%S")
337 |                             staled = True if datetime.utcnow() - reported_at > self.reap_interval else False
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
338 |
339 |                         LOG.debug('ignore detected change of event %s for host %s that has been reported, details : %s'
    |

host/ha/utils/consul_helper.py:339:89: E501 Line too long (119 > 88)
    |
337 |                             staled = True if datetime.utcnow() - reported_at > self.reap_interval else False
338 |
339 |                         LOG.debug('ignore detected change of event %s for host %s that has been reported, details : %s'
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
340 |                                  ' , is report staled ? %s',
341 |                                  str(change.event['eventType']), hostname, str(change), str(staled))
    |

host/ha/utils/consul_helper.py:341:89: E501 Line too long (100 > 88)
    |
339 |                         LOG.debug('ignore detected change of event %s for host %s that has been reported, details : %s'
340 |                                  ' , is report staled ? %s',
341 |                                  str(change.event['eventType']), hostname, str(change), str(staled))
    |                                                                                         ^^^^^^^^^^^^ E501
342 |                         continue
343 |                     reported_cls = change
    |

host/ha/utils/consul_helper.py:356:89: E501 Line too long (95 > 88)
    |
354 |                              str(current_state[addr].event['eventType']))
355 |             else:
356 |                 LOG.debug('change of event %s for host %s has not exceed report grace period. '
    |                                                                                         ^^^^^^^ E501
357 |                          'utcnow : %s , last change : %s, grace period : %s',
358 |                          str(change.event['eventType']), hostname,
    |

host/ha/utils/consul_helper.py:363:89: E501 Line too long (95 > 88)
    |
361 |         if reported_cls:
362 |             LOG.debug('examining change of event %s for host %s for reporting : %s',
363 |                      str(reported_cls.event['eventType']), str(reported_cls.event['hostName']),
    |                                                                                         ^^^^^^^ E501
364 |                      str(reported_cls))
365 |             ignore, data = self.kv_fetch(retval.event['hostName'])
    |

host/ha/utils/consul_helper.py:367:89: E501 Line too long (89 > 88)
    |
365 |             ignore, data = self.kv_fetch(retval.event['hostName'])
366 |             if not data:
367 |                 LOG.debug('change of event %s for host %s has not reported to kv store, '
    |                                                                                         ^ E501
368 |                          'now store it. change : %s ',
369 |                          str(reported_cls.event['eventType']), str(reported_cls.event['hostName']),
    |

host/ha/utils/consul_helper.py:369:89: E501 Line too long (99 > 88)
    |
367 |                 LOG.debug('change of event %s for host %s has not reported to kv store, '
368 |                          'now store it. change : %s ',
369 |                          str(reported_cls.event['eventType']), str(reported_cls.event['hostName']),
    |                                                                                         ^^^^^^^^^^^ E501
370 |                          str(reported_cls))
371 |                 LOG.info('report event %s for host %s to kv store : %s ',
    |

host/ha/utils/consul_helper.py:372:89: E501 Line too long (108 > 88)
    |
370 |                          str(reported_cls))
371 |                 LOG.info('report event %s for host %s to kv store : %s ',
372 |                          str(retval.event['eventType']), retval.event['hostName'], json.dumps(reported_cls))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
373 |                 self.kv_update(retval.event['hostName'], json.dumps(reported_cls))
374 |             else:
    |

host/ha/utils/consul_helper.py:377:89: E501 Line too long (99 > 88)
    |
375 |                 LOG.info('change of event %s for host %s already exist in kv store, '
376 |                          'change : %s, report : %s',
377 |                          str(reported_cls.event['eventType']), str(reported_cls.event['hostName']),
    |                                                                                         ^^^^^^^^^^^ E501
378 |                          json.dumps(reported_cls), str(data))
379 |                 # two scenarios when report exist in kv store:
    |

host/ha/utils/consul_helper.py:388:89: E501 Line too long (89 > 88)
    |
386 |                 cls_obj = report_object.from_str(data_obj)
387 |                 if retval.event['eventType'] == 1:
388 |                     LOG.debug('founded change for host %s is host up, and existed in kv '
    |                                                                                         ^ E501
389 |                              'store. still report host up', cls_obj.event['hostName'])
390 |                     # node become alive from down, need to report
    |

host/ha/utils/consul_helper.py:394:89: E501 Line too long (93 > 88)
    |
392 |                 if cls_obj.event['eventType'] == 2:
393 |                     if cls_obj.event.get('reported'):
394 |                         LOG.debug('founded change for host %s is host down, and exist in kv '
    |                                                                                         ^^^^^ E501
395 |                                  'store, and already reported, so no need '
396 |                                  'to report again', cls_obj.event['hostName'])
    |

host/ha/utils/consul_helper.py:406:89: E501 Line too long (89 > 88)
    |
404 |         if retval:
405 |             LOG.debug('change to be reported to hamgr for event %s for host %s : %s',
406 |                      str(retval['event']['eventType']), str(retval['event']['hostName']),
    |                                                                                         ^ E501
407 |                      str(retval))
408 |         return retval
    |

host/ha/utils/consul_helper.py:429:89: E501 Line too long (90 > 88)
    |
428 |         self.last_status = self.current_status
429 |         LOG.info('detected status change for reporting to hamgr for event %s for host %s',
    |                                                                                         ^^ E501
430 |                  str(report_change['event']['eventType']), str(report_change['event']['hostName']))
431 |         return report_change
    |

host/ha/utils/consul_helper.py:430:89: E501 Line too long (99 > 88)
    |
428 |         self.last_status = self.current_status
429 |         LOG.info('detected status change for reporting to hamgr for event %s for host %s',
430 |                  str(report_change['event']['eventType']), str(report_change['event']['hostName']))
    |                                                                                         ^^^^^^^^^^^ E501
431 |         return report_change
    |

host/ha/utils/consul_helper.py:499:89: E501 Line too long (146 > 88)
    |
497 | …
498 | …
499 | …v_list), str(self.changed_clusters), str(self.last_status), str(self._get_consul_members()))
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
500 | …
501 | …
    |

host/ha/utils/consul_helper.py:518:89: E501 Line too long (101 > 88)
    |
517 |         if len(unexpected_adds):
518 |             LOG.warning('hosts are unexpected but joined current cluster : %s', str(unexpected_adds))
    |                                                                                         ^^^^^^^^^^^^^ E501
519 |         if len(missing_adds):
520 |             LOG.warning('hosts are expected but miss fromm current cluster : %s', str(missing_adds))
    |

host/ha/utils/consul_helper.py:520:89: E501 Line too long (100 > 88)
    |
518 |             LOG.warning('hosts are unexpected but joined current cluster : %s', str(unexpected_adds))
519 |         if len(missing_adds):
520 |             LOG.warning('hosts are expected but miss fromm current cluster : %s', str(missing_adds))
    |                                                                                         ^^^^^^^^^^^^ E501
521 |
522 |         LOG.debug("cache is refreshed by using reports from kv store : %s ",
    |

host/ha/utils/consul_helper.py:537:89: E501 Line too long (91 > 88)
    |
535 |         # according to https://www.consul.io/docs/faq.html
536 |         # Q: Are failed or left nodes ever removed?
537 |         # To prevent an accumulation of dead nodes (nodes in either failed or left states),
    |                                                                                         ^^^ E501
538 |         # Consul will automatically remove dead nodes out of the catalog.
539 |         # This process is called reaping. This is currently done on a configurable
    |

host/ha/utils/consul_helper.py:541:89: E501 Line too long (90 > 88)
    |
539 |         # This process is called reaping. This is currently done on a configurable
540 |         # interval of 72 hours. Reaping is similar to leaving, causing all associated
541 |         # services to be deregistered. Changing the reap interval for aesthetic reasons to
    |                                                                                         ^^ E501
542 |         # trim the number of failed or left nodes is not advised (nodes in the failed or
543 |         # left state do not cause any additional burden on Consul).
    |

host/ha/utils/consul_helper.py:545:89: E501 Line too long (98 > 88)
    |
543 |         # left state do not cause any additional burden on Consul).
544 |         #
545 |         # 'consul members' command does not return all the 'failed' or 'left' members, this caused
    |                                                                                         ^^^^^^^^^^ E501
546 |         # the problem where the host-down event for those 'failed' or 'left' nodes are not processed.
547 |         # so rather than just iterator over what consul returned, we always iterator over the number
    |

host/ha/utils/consul_helper.py:546:89: E501 Line too long (101 > 88)
    |
544 |         #
545 |         # 'consul members' command does not return all the 'failed' or 'left' members, this caused
546 |         # the problem where the host-down event for those 'failed' or 'left' nodes are not processed.
    |                                                                                         ^^^^^^^^^^^^^ E501
547 |         # so rather than just iterator over what consul returned, we always iterator over the number
548 |         # of join ips, because that's the desired num of members in consul
    |

host/ha/utils/consul_helper.py:547:89: E501 Line too long (100 > 88)
    |
545 |         # 'consul members' command does not return all the 'failed' or 'left' members, this caused
546 |         # the problem where the host-down event for those 'failed' or 'left' nodes are not processed.
547 |         # so rather than just iterator over what consul returned, we always iterator over the number
    |                                                                                         ^^^^^^^^^^^^ E501
548 |         # of join ips, because that's the desired num of members in consul
549 |         for addr in self.hosts_ips:
    |

host/ha/utils/consul_helper.py:578:89: E501 Line too long (97 > 88)
    |
576 |                     data.event['reported'] = False
577 |                     data.event['reportedBy'] = str(get_ip_address())
578 |                     LOG.debug('cloned and modified event found from last status : %s', str(data))
    |                                                                                         ^^^^^^^^^ E501
579 |                 else:
580 |                     host_name = matched[0]
    |

host/ha/utils/consul_helper.py:594:89: E501 Line too long (126 > 88)
    |
592 |                     consul_obj = {}
593 |                     data = report_object(event_obj, consul_obj)
594 |                     LOG.debug('host-down event created without consul info for host not returned from consul : %s', str(data))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
595 |
596 |                 # add back to current_status
    |

host/ha/utils/consul_helper.py:597:89: E501 Line too long (117 > 88)
    |
596 |                 # add back to current_status
597 |                 LOG.debug('made-up host down event for host %s which not returned from consul : %s', addr, str(data))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
598 |                 current_status[addr] = data
    |

host/ha/utils/consul_helper.py:605:89: E501 Line too long (96 > 88)
    |
603 |             if addr not in self.last_status.keys():
604 |                 self.last_status[addr] = data
605 |                 LOG.debug('cache node found from consul members in last_status : %s', str(data))
    |                                                                                         ^^^^^^^^ E501
606 |
607 |             LOG.debug('checking whether need to update kv store for event %s for host %s',
    |

host/ha/utils/consul_helper.py:607:89: E501 Line too long (90 > 88)
    |
605 |                 LOG.debug('cache node found from consul members in last_status : %s', str(data))
606 |
607 |             LOG.debug('checking whether need to update kv store for event %s for host %s',
    |                                                                                         ^^ E501
608 |                      str(data.event['eventType']), str(data.event['hostName']))
609 |             status_has_changed = (self.last_status[addr].event['eventType'] != data.event['eventType'])
    |

host/ha/utils/consul_helper.py:609:89: E501 Line too long (103 > 88)
    |
607 |             LOG.debug('checking whether need to update kv store for event %s for host %s',
608 |                      str(data.event['eventType']), str(data.event['hostName']))
609 |             status_has_changed = (self.last_status[addr].event['eventType'] != data.event['eventType'])
    |                                                                                         ^^^^^^^^^^^^^^^ E501
610 |             if status_has_changed:
611 |                 data.event['detectedAt'] = datetime.strftime(datetime.utcnow(),
    |

host/ha/utils/consul_helper.py:622:89: E501 Line too long (90 > 88)
    |
620 |                     hostName = data.event['hostName']
621 |                     _, kv_data = self.kv_fetch(hostName)
622 |                     LOG.debug('host %s status is down, check if report exist in kv store',
    |                                                                                         ^^ E501
623 |                              hostName)
624 |                     # if report exist, check whether reported
    |

host/ha/utils/consul_helper.py:626:89: E501 Line too long (105 > 88)
    |
624 |                     # if report exist, check whether reported
625 |                     if kv_data:
626 |                         LOG.debug('checking whether existing data for host %s has already reported : %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
627 |                                   hostName, str(kv_data))
628 |                         existing_cls = report_object.from_str(kv_data['Value'].decode())
    |

host/ha/utils/consul_helper.py:631:89: E501 Line too long (95 > 88)
    |
629 |                         if existing_cls.event['reported']:
630 |                             reported_before = True
631 |                             reported_time = datetime.strptime(existing_cls.event['reportedAt'],
    |                                                                                         ^^^^^^^ E501
632 |                                                               "%Y-%m-%d %H:%M:%S")
633 |                             if datetime.utcnow() - reported_time > self.reap_interval:
    |

host/ha/utils/consul_helper.py:636:89: E501 Line too long (93 > 88)
    |
634 | …                         reported_but_staled = True
635 | …                         self.kv_delete(hostName)
636 | …                     LOG.debug('host %s status is down, and report exist in kv store.'
    |                                                                                   ^^^^^ E501
637 | …                              ' report : %s , reported time : %s , is it staled ? %s',
638 | …                              hostName, str(kv_data), str(reported_time), str(reported_but_staled))
    |

host/ha/utils/consul_helper.py:637:89: E501 Line too long (93 > 88)
    |
635 | …                         self.kv_delete(hostName)
636 | …                     LOG.debug('host %s status is down, and report exist in kv store.'
637 | …                              ' report : %s , reported time : %s , is it staled ? %s',
    |                                                                                   ^^^^^ E501
638 | …                              hostName, str(kv_data), str(reported_time), str(reported_but_staled))
639 | …                     #
    |

host/ha/utils/consul_helper.py:638:89: E501 Line too long (106 > 88)
    |
636 |                             LOG.debug('host %s status is down, and report exist in kv store.'
637 |                                      ' report : %s , reported time : %s , is it staled ? %s',
638 |                                      hostName, str(kv_data), str(reported_time), str(reported_but_staled))
    |                                                                                         ^^^^^^^^^^^^^^^^^^ E501
639 |                             #
640 |                     else:
    |

host/ha/utils/consul_helper.py:641:89: E501 Line too long (97 > 88)
    |
639 |                             #
640 |                     else:
641 |                         LOG.debug('host %s status is down, no report exist in kv store or cache',
    |                                                                                         ^^^^^^^^^ E501
642 |                                  hostName)
643 |                     # when host down, and not reported
    |

host/ha/utils/consul_helper.py:646:89: E501 Line too long (102 > 88)
    |
644 |                     if not reported_before or reported_but_staled:
645 |                         LOG.debug('cache event %s for host %s : %s',
646 |                                  str(data.event['eventType']), str(data.event['hostName']), str(data))
    |                                                                                         ^^^^^^^^^^^^^^ E501
647 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
648 |                         self.changed_clusters[data.event['hostName']] = data
    |

host/ha/utils/consul_helper.py:647:89: E501 Line too long (108 > 88)
    |
645 |                         LOG.debug('cache event %s for host %s : %s',
646 |                                  str(data.event['eventType']), str(data.event['hostName']), str(data))
647 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
648 |                         self.changed_clusters[data.event['hostName']] = data
    |

host/ha/utils/consul_helper.py:651:89: E501 Line too long (96 > 88)
    |
650 |                 else:
651 |                     LOG.debug('there was cache record for host %s with event %s, reported ? %s',
    |                                                                                         ^^^^^^^^ E501
652 |                              cached_item.event['hostName'],
653 |                              str(cached_item.event['eventType']), str(cached_item.event['reported']))
    |

host/ha/utils/consul_helper.py:653:89: E501 Line too long (101 > 88)
    |
651 |                     LOG.debug('there was cache record for host %s with event %s, reported ? %s',
652 |                              cached_item.event['hostName'],
653 |                              str(cached_item.event['eventType']), str(cached_item.event['reported']))
    |                                                                                         ^^^^^^^^^^^^^ E501
654 |                     # check whether the event in cache is the same
655 |                     if data.event['eventType'] != cached_item.event['eventType']:
    |

host/ha/utils/consul_helper.py:656:89: E501 Line too long (107 > 88)
    |
654 |                     # check whether the event in cache is the same
655 |                     if data.event['eventType'] != cached_item.event['eventType']:
656 |                         LOG.debug('current event %s , which is different than cached event %s for host %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
657 |                                  str(data.event['eventType']),
658 |                                  str(cached_item.event['eventType']),
    |

host/ha/utils/consul_helper.py:667:89: E501 Line too long (108 > 88)
    |
665 |                             self.kv_delete(data.event['hostName'])
666 |                         LOG.debug('replace old cache with new event : %s', str(data))
667 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
668 |                         self.changed_clusters[data.event['hostName']] = data
    |

host/ha/utils/consul_helper.py:684:89: E501 Line too long (103 > 88)
    |
682 |                 if not cached_item:
683 |                     if status_has_changed:
684 |                         LOG.debug('cache event %s for host %s, as its status changed and not in cache',
    |                                                                                         ^^^^^^^^^^^^^^^ E501
685 |                                   str(data.event['eventType']), str(data.event['hostName']))
686 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |

host/ha/utils/consul_helper.py:685:89: E501 Line too long (92 > 88)
    |
683 |                     if status_has_changed:
684 |                         LOG.debug('cache event %s for host %s, as its status changed and not in cache',
685 |                                   str(data.event['eventType']), str(data.event['hostName']))
    |                                                                                         ^^^^ E501
686 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
687 |                         self.changed_clusters[data.event['hostName']] = data
    |

host/ha/utils/consul_helper.py:686:89: E501 Line too long (108 > 88)
    |
684 |                         LOG.debug('cache event %s for host %s, as its status changed and not in cache',
685 |                                   str(data.event['eventType']), str(data.event['hostName']))
686 |                         data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
687 |                         self.changed_clusters[data.event['hostName']] = data
688 |                     else:
    |

host/ha/utils/consul_helper.py:689:89: E501 Line too long (101 > 88)
    |
687 |                         self.changed_clusters[data.event['hostName']] = data
688 |                     else:
689 |                         LOG.debug('no need to cache event %s for host %s, as status has not changed',
    |                                                                                         ^^^^^^^^^^^^^ E501
690 |                                   str(data.event['eventType']), str(data.event['hostName']))
691 |                 else:
    |

host/ha/utils/consul_helper.py:690:89: E501 Line too long (92 > 88)
    |
688 |                     else:
689 |                         LOG.debug('no need to cache event %s for host %s, as status has not changed',
690 |                                   str(data.event['eventType']), str(data.event['hostName']))
    |                                                                                         ^^^^ E501
691 |                 else:
692 |                     # should be only one report in cache for each host
    |

host/ha/utils/consul_helper.py:698:89: E501 Line too long (89 > 88)
    |
696 |                     if reported:
697 |                         # no need to cache reported change
698 |                         LOG.debug('remove cached and reported status with event %s : %s',
    |                                                                                         ^ E501
699 |                                  str(eventType), str(cached_item))
700 |                         self.changed_clusters.pop(hostName)
    |

host/ha/utils/consul_helper.py:716:89: E501 Line too long (116 > 88)
    |
714 |                         # add new state into cache if evenType is different
715 |                         if eventType != data.event['eventType']:
716 |                             LOG.debug('cache the new event %s, has changed since last cached and reported event %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
717 |                                      str(data.event['eventType']), str(eventType))
718 |                             data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |

host/ha/utils/consul_helper.py:718:89: E501 Line too long (112 > 88)
    |
716 |                             LOG.debug('cache the new event %s, has changed since last cached and reported event %s',
717 |                                      str(data.event['eventType']), str(eventType))
718 |                             data.event['detectedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
719 |                             self.changed_clusters[hostName] = data
720 |                         else:
    |

host/ha/utils/consul_helper.py:721:89: E501 Line too long (116 > 88)
    |
719 |                             self.changed_clusters[hostName] = data
720 |                         else:
721 |                             LOG.debug('not cache current event %s, has not changed since last status with event %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
722 |                                      str(data.event['eventType']), str(eventType))
723 |                     else:
    |

host/ha/utils/consul_helper.py:724:89: E501 Line too long (91 > 88)
    |
722 |                                      str(data.event['eventType']), str(eventType))
723 |                     else:
724 |                         LOG.debug('host %s status up, but previous report in kv store has '
    |                                                                                         ^^^ E501
725 |                                  'not been reported yet. report : %s',
726 |                                  hostName, str(cached_item))
    |

host/ha/utils/consul_helper.py:731:89: E501 Line too long (119 > 88)
    |
729 | …     # after the report process is completed
730 | …     self.current_status = current_status
731 | …     LOG.info("cache is updated with info from kv store and latest consul status : %s ", str(self.changed_clusters))
    |                                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
732 | …     LOG.debug(fresh_msg, 'after', self.kv_print(kv_list), str(self.changed_clusters), str(self.last_status), str(self._get_consul_m…
    |

host/ha/utils/consul_helper.py:732:89: E501 Line too long (145 > 88)
    |
730 | …
731 | …store and latest consul status : %s ", str(self.changed_clusters))
732 | …v_list), str(self.changed_clusters), str(self.last_status), str(self._get_consul_members()))
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
733 | …
734 | …
    |

host/ha/utils/consul_helper.py:759:89: E501 Line too long (100 > 88)
    |
757 |             self.cc.kv.put(key, value)
758 |         except Exception as e:
759 |             LOG.warning('error when update key %s with value %s : %s', str(key), str(value), str(e))
    |                                                                                         ^^^^^^^^^^^^ E501
760 |
761 |     def kv_delete(self, key):
    |

host/ha/utils/consul_helper.py:793:89: E501 Line too long (101 > 88)
    |
791 |         # mark this event as reported and store to kv store
792 |         LOG.debug('mark report of event %s for host %s as reported in kv store',
793 |                  str(cluster_status['event']['eventType']), str(cluster_status['event']['hostName']))
    |                                                                                         ^^^^^^^^^^^^^ E501
794 |         old_status['event']['reported'] = True
795 |         old_status['event']['reportedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |

host/ha/utils/consul_helper.py:795:89: E501 Line too long (101 > 88)
    |
793 |                  str(cluster_status['event']['eventType']), str(cluster_status['event']['hostName']))
794 |         old_status['event']['reported'] = True
795 |         old_status['event']['reportedAt'] = datetime.strftime(datetime.utcnow(), '%Y-%m-%d %H:%M:%S')
    |                                                                                         ^^^^^^^^^^^^^ E501
796 |         self.kv_update(cluster_status.event['hostName'], json.dumps(old_status))
    |

host/ha/utils/consul_helper.py:798:89: E501 Line too long (89 > 88)
    |
796 |         self.kv_update(cluster_status.event['hostName'], json.dumps(old_status))
797 |
798 |         LOG.info('change of event %s for host %s is now marked as done in kv store : %s',
    |                                                                                         ^ E501
799 |                  str(cluster_status['event']['eventType']), str(cluster_status.event['hostName']),
800 |                  str(self.kv_fetch(str(cluster_status.event['hostName']))))
    |

host/ha/utils/consul_helper.py:799:89: E501 Line too long (98 > 88)
    |
798 |         LOG.info('change of event %s for host %s is now marked as done in kv store : %s',
799 |                  str(cluster_status['event']['eventType']), str(cluster_status.event['hostName']),
    |                                                                                         ^^^^^^^^^^ E501
800 |                  str(self.kv_fetch(str(cluster_status.event['hostName']))))
    |

host/ha/utils/consul_helper.py:823:89: E501 Line too long (111 > 88)
    |
821 |                 howold = utcnow - report_time
822 |                 staled = True if howold > self.reap_interval else False
823 |                 LOG.debug('is report for event id %s type %s for host %s staled ? %s , reported at %s, now %s',
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^ E501
824 |                          report_uuid, str(eventType), str(hostname), str(staled), str(report_time), str(utcnow))
825 |                 if staled:
    |

host/ha/utils/consul_helper.py:824:89: E501 Line too long (112 > 88)
    |
822 |                 staled = True if howold > self.reap_interval else False
823 |                 LOG.debug('is report for event id %s type %s for host %s staled ? %s , reported at %s, now %s',
824 |                          report_uuid, str(eventType), str(hostname), str(staled), str(report_time), str(utcnow))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^ E501
825 |                 if staled:
826 |                     LOG.debug('remove stale record for host %s from kv store, key : %s, event id %s, '
    |

host/ha/utils/consul_helper.py:826:89: E501 Line too long (102 > 88)
    |
824 |                          report_uuid, str(eventType), str(hostname), str(staled), str(report_time), str(utcnow))
825 |                 if staled:
826 |                     LOG.debug('remove stale record for host %s from kv store, key : %s, event id %s, '
    |                                                                                         ^^^^^^^^^^^^^^ E501
827 |                              'report time: %s, utcnow : %s', hostname,
828 |                              key, report_uuid, report_time_str, str(datetime.utcnow()))
    |

host/ha/utils/log.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import logging.config
17 | | import logging.handlers
18 | | from oslo_config import cfg
19 | | from shared.constants import ROOT_LOGGER
   | |________________________________________^ I001
20 |
21 |   CONF = cfg.CONF
   |
   = help: Organize imports

host/ha/utils/log.py:27:89: E501 Line too long (101 > 88)
   |
25 |     cfg.StrOpt('file', default='/var/log/pf9/pf9-ha.log',
26 |                help='log file location'),
27 |     cfg.StrOpt('max_bytes', default='10485760', help='max size in bytes of log file when to rotate'),
   |                                                                                         ^^^^^^^^^^^^^ E501
28 |     cfg.StrOpt('backup_count', default='5', help='num of log files to rotate')
29 | ]
   |

host/ha/utils/report.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import json
16 | | import time
17 | |
18 | | import logging
19 | | from oslo_config import cfg
20 | | from keystoneclient.v3 import client as v3client
21 | | from keystoneclient.v3.tokens import TokenManager
22 | | from keystoneauth1.identity import v3
23 | | from keystoneauth1 import session
24 | | import requests
25 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
26 |
27 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

host/ha/utils/report.py:130:89: E501 Line too long (101 > 88)
    |
129 |             host_url = '/'.join([self.hamgr_url, data.event['hostName']])
130 |             LOG.info('reporting to HA manager for host %s: %s', data.event['hostName'], str(payload))
    |                                                                                         ^^^^^^^^^^^^^ E501
131 |             resp = requests.post(host_url, data=payload, headers=headers,
132 |                                  verify=CONF.keystone_authtoken.insecure)
    |

host/ha/utils/report.py:134:89: E501 Line too long (123 > 88)
    |
132 |                                  verify=CONF.keystone_authtoken.insecure)
133 |             if resp.status_code != requests.codes.ok:
134 |                 LOG.error('report to HA manager for host %s failed, returned %d', data.event['hostName'], resp.status_code)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
135 |                 return False
136 |             else:
    |

host/ha/utils/report.py:137:89: E501 Line too long (107 > 88)
    |
135 |                 return False
136 |             else:
137 |                 LOG.info('Status reported successfully to HA manager for host %s ', data.event['hostName'])
    |                                                                                         ^^^^^^^^^^^^^^^^^^^ E501
138 |                 return resp.json().get('success', False)
139 |         except Exception:
    |

host/ha/utils/report.py:140:89: E501 Line too long (110 > 88)
    |
138 |                 return resp.json().get('success', False)
139 |         except Exception:
140 |             LOG.error('Status report to HA manager for host %s failed', data.event['hostName'], exc_info=True)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^ E501
141 |             return False
    |

host/setup.py:19:12: F401 `multiprocessing` imported but unused; consider using `importlib.util.find_spec` to test for availability
   |
18 | try:
19 |     import multiprocessing
   |            ^^^^^^^^^^^^^^^ F401
20 | except ImportError:
21 |     pass
   |
   = help: Remove unused import: `multiprocessing`

setup.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 | # limitations under the License.
14 |
15 | import setuptools
   | ^^^^^^^^^^^^^^^^^ I001
   |
   = help: Organize imports

shared/exceptions/ha_exceptions.py:97:89: E501 Line too long (98 > 88)
   |
95 | class RoleSettingsNotFound(Exception):
96 |     def __init__(self, host, role, settings):
97 |         message = 'Settings for Role %s for Host %s does not exist : %s ' % (role, host, settings)
   |                                                                                         ^^^^^^^^^^ E501
98 |         super(RoleSettingsNotFound, self).__init__(message)
   |

shared/messages/consul_request.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | from shared.messages import message_types as message_types
17 | | from shared.messages.message_base import MessageBase
18 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
19 |
20 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/messages/consul_request.py:27:89: E501 Line too long (97 > 88)
   |
25 |         self._cluster = cluster
26 |         self._command = cmd
27 |         super(ConsulRefreshRequest, self).__init__(type=message_types.MSG_CONSUL_REFRESH_REQUEST,
   |                                                                                         ^^^^^^^^^ E501
28 |                                                    cluster=self._cluster,
29 |                                                    command=cmd,
   |

shared/messages/consul_response.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from shared.messages.message_base import MessageBase
16 | | from shared.messages import message_types as message_types
   | |__________________________________________________________^ I001
   |
   = help: Organize imports

shared/messages/consul_response.py:26:89: E501 Line too long (99 > 88)
   |
24 |         self._report = report
25 |         self._message = message
26 |         super(ConsulRefreshResponse, self).__init__(type=message_types.MSG_CONSUL_REFRESH_RESPONSE,
   |                                                                                         ^^^^^^^^^^^ E501
27 |                                                     cluster=self._cluster,
28 |                                                     req_id=self._req_id,
   |

shared/messages/message_base.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from datetime import datetime
16 | | import uuid
17 | | import logging
18 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
19 |
20 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/messages/message_schemas.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from shared.messages import message_types as message_types
16 | | from shared.messages.cluster_event import ClusterEvent
17 | | from shared.messages.rebalance_request import ConsulRoleRebalanceRequest
18 | | from shared.messages.rebalance_response import ConsulRoleRebalanceResponse
19 | | from shared.messages.consul_request import ConsulRefreshRequest
20 | | from shared.messages.consul_response import ConsulRefreshResponse
   | |_________________________________________________________________^ I001
21 |
22 |   MSG_CATEGORY_REQUEST = 'request'
   |
   = help: Organize imports

shared/messages/message_schemas.py:26:89: E501 Line too long (93 > 88)
   |
25 | MSG_SCHEMAS = [
26 |     # +------------------------+--------------------+---------------------+-----------------+
   |                                                                                         ^^^^^ E501
27 |     # | message_type           | message_category   |  message_class      |   not_used      |
28 |     # +------------------------+--------------------+---------------------+-----------------+
   |

shared/messages/message_schemas.py:27:89: E501 Line too long (93 > 88)
   |
25 | MSG_SCHEMAS = [
26 |     # +------------------------+--------------------+---------------------+-----------------+
27 |     # | message_type           | message_category   |  message_class      |   not_used      |
   |                                                                                         ^^^^^ E501
28 |     # +------------------------+--------------------+---------------------+-----------------+
29 |     (message_types.MSG_CLUSTER_EVENT,            MSG_CATEGORY_REQUEST,   ClusterEvent,                 None),
   |

shared/messages/message_schemas.py:28:89: E501 Line too long (93 > 88)
   |
26 |     # +------------------------+--------------------+---------------------+-----------------+
27 |     # | message_type           | message_category   |  message_class      |   not_used      |
28 |     # +------------------------+--------------------+---------------------+-----------------+
   |                                                                                         ^^^^^ E501
29 |     (message_types.MSG_CLUSTER_EVENT,            MSG_CATEGORY_REQUEST,   ClusterEvent,                 None),
30 |     (message_types.MSG_ROLE_REBALANCE_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRoleRebalanceRequest,   None),
   |

shared/messages/message_schemas.py:29:89: E501 Line too long (109 > 88)
   |
27 |     # | message_type           | message_category   |  message_class      |   not_used      |
28 |     # +------------------------+--------------------+---------------------+-----------------+
29 |     (message_types.MSG_CLUSTER_EVENT,            MSG_CATEGORY_REQUEST,   ClusterEvent,                 None),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
30 |     (message_types.MSG_ROLE_REBALANCE_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRoleRebalanceRequest,   None),
31 |     (message_types.MSG_ROLE_REBALANCE_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRoleRebalanceResponse,  None),
   |

shared/messages/message_schemas.py:30:89: E501 Line too long (109 > 88)
   |
28 |     # +------------------------+--------------------+---------------------+-----------------+
29 |     (message_types.MSG_CLUSTER_EVENT,            MSG_CATEGORY_REQUEST,   ClusterEvent,                 None),
30 |     (message_types.MSG_ROLE_REBALANCE_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRoleRebalanceRequest,   None),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
31 |     (message_types.MSG_ROLE_REBALANCE_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRoleRebalanceResponse,  None),
32 |     (message_types.MSG_CONSUL_REFRESH_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRefreshRequest,         None),
   |

shared/messages/message_schemas.py:31:89: E501 Line too long (109 > 88)
   |
29 |     (message_types.MSG_CLUSTER_EVENT,            MSG_CATEGORY_REQUEST,   ClusterEvent,                 None),
30 |     (message_types.MSG_ROLE_REBALANCE_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRoleRebalanceRequest,   None),
31 |     (message_types.MSG_ROLE_REBALANCE_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRoleRebalanceResponse,  None),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
32 |     (message_types.MSG_CONSUL_REFRESH_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRefreshRequest,         None),
33 |     (message_types.MSG_CONSUL_REFRESH_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRefreshResponse,        None)
   |

shared/messages/message_schemas.py:32:89: E501 Line too long (109 > 88)
   |
30 |     (message_types.MSG_ROLE_REBALANCE_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRoleRebalanceRequest,   None),
31 |     (message_types.MSG_ROLE_REBALANCE_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRoleRebalanceResponse,  None),
32 |     (message_types.MSG_CONSUL_REFRESH_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRefreshRequest,         None),
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^^ E501
33 |     (message_types.MSG_CONSUL_REFRESH_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRefreshResponse,        None)
34 | ]
   |

shared/messages/message_schemas.py:33:89: E501 Line too long (108 > 88)
   |
31 |     (message_types.MSG_ROLE_REBALANCE_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRoleRebalanceResponse,  None),
32 |     (message_types.MSG_CONSUL_REFRESH_REQUEST,   MSG_CATEGORY_REQUEST,   ConsulRefreshRequest,         None),
33 |     (message_types.MSG_CONSUL_REFRESH_RESPONSE,  MSG_CATEGORY_RESPONSE,  ConsulRefreshResponse,        None)
   |                                                                                         ^^^^^^^^^^^^^^^^^^^^ E501
34 | ]
   |

shared/messages/rebalance_request.py:25:89: E501 Line too long (103 > 88)
   |
23 |         self._old_role = old_role
24 |         self._new_role = new_role
25 |         super(ConsulRoleRebalanceRequest, self).__init__(type=message_types.MSG_ROLE_REBALANCE_REQUEST,
   |                                                                                         ^^^^^^^^^^^^^^^ E501
26 |                                                          cluster = self._cluster,
27 |                                                          host_id=self._host_id,
   |

shared/messages/rebalance_response.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / from shared.messages.message_base import MessageBase
16 | | from shared.messages import message_types as message_types
   | |__________________________________________________________^ I001
   |
   = help: Organize imports

shared/messages/rebalance_response.py:26:89: E501 Line too long (105 > 88)
   |
24 |         self._status = status
25 |         self._message = message
26 |         super(ConsulRoleRebalanceResponse, self).__init__(type=message_types.MSG_ROLE_REBALANCE_RESPONSE,
   |                                                                                         ^^^^^^^^^^^^^^^^^ E501
27 |                                                           cluster=self._cluster,
28 |                                                           req_id=self._req_id,
   |

shared/rpc/rpc_channel.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import pika
17 | | import threading
18 | | import datetime
19 | | import time
20 | | import re
21 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
22 |
23 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/rpc/rpc_channel.py:77:89: E501 Line too long (95 > 88)
   |
76 |     def _open_connection(self):
77 |         LOG.debug('create RPC pika connecting to amqp://password:%s@%s:%s/ for %s', self._user,
   |                                                                                         ^^^^^^^ E501
78 |                   self._host, str(self._port), self._application)
79 |         return pika.SelectConnection(self._connection_parameters,
   |

shared/rpc/rpc_channel.py:100:89: E501 Line too long (100 > 88)
    |
 98 |         LOG.debug('RPC pika connection was closed for %s', self._application)
 99 |         if self._closing:
100 |             LOG.debug('stop RPC pika ioloop for %s since connection was closed.', self._application)
    |                                                                                         ^^^^^^^^^^^^ E501
101 |             self._connection.ioloop.stop()
102 |         else:
    |

shared/rpc/rpc_channel.py:104:89: E501 Line too long (90 > 88)
    |
102 |         else:
103 |             time.sleep(5)
104 |             LOG.debug('RPC pika connection for %s was closed, will reopen. error : %s %s',
    |                                                                                         ^^ E501
105 |                 self._application, reply_code, reply_text)
106 |             self.close_channel()
    |

shared/rpc/rpc_channel.py:137:89: E501 Line too long (157 > 88)
    |
135 | …
136 | …
137 | …_delete' for exchange.*in vhost.*:.*received '(?P<local>\w+)' but current is '(?P<remote>\w+)'.*")
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
138 | …
139 | …
    |

shared/rpc/rpc_channel.py:152:89: E501 Line too long (101 > 88)
    |
150 |                     return
151 |         if not self._closing:
152 |             LOG.debug('close RPC pika connection for %s since channel was closed', self._application)
    |                                                                                         ^^^^^^^^^^^^^ E501
153 |             self._connection.close()
154 |         else:
    |

shared/rpc/rpc_channel.py:155:89: E501 Line too long (95 > 88)
    |
153 |             self._connection.close()
154 |         else:
155 |             LOG.debug('RPC pika connection for %s already closed when channel was closed ? %s',
    |                                                                                         ^^^^^^^ E501
156 |                       self._application, str(self._connection.is_closed))
    |

shared/rpc/rpc_channel.py:167:89: E501 Line too long (104 > 88)
    |
166 |     def _setup_exchange(self):
167 |         LOG.debug('RPC pika channel is declaring exchange %s for %s', self._exchange, self._application)
    |                                                                                         ^^^^^^^^^^^^^^^^ E501
168 |         try:
169 |             self._channel.exchange_declare(self._on_exchange_declare_ok,
    |

shared/rpc/rpc_channel.py:174:89: E501 Line too long (95 > 88)
    |
172 |                                            auto_delete=self._exchange_auto_delete)
173 |         except Exception:
174 |             LOG.exception('unhandled exchange declaration exception for %s', self._application)
    |                                                                                         ^^^^^^^ E501
175 |
176 |     def _on_exchange_declare_ok(self, unused_frame):
    |

shared/rpc/rpc_channel.py:183:89: E501 Line too long (105 > 88)
    |
181 |                 self._connection_ready_callback()
182 |         except Exception:
183 |             LOG.exception('unhandled exception from connection_ready_callback for %s', self._application)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
184 |         self._connection_ready = True
    |

shared/rpc/rpc_channel.py:198:89: E501 Line too long (105 > 88)
    |
196 |                 self._connection.ioloop.start()
197 |             except Exception :
198 |                 LOG.exception('unhandled RPC pika connection ioloop exception for %s', self._application)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
199 |                 LOG.debug('restart RPC pika connection for %s in %s seconds', self._application, str(interval_seconds))
200 |                 self._connection.ioloop.stop()
    |

shared/rpc/rpc_channel.py:199:89: E501 Line too long (119 > 88)
    |
197 |             except Exception :
198 |                 LOG.exception('unhandled RPC pika connection ioloop exception for %s', self._application)
199 |                 LOG.debug('restart RPC pika connection for %s in %s seconds', self._application, str(interval_seconds))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
200 |                 self._connection.ioloop.stop()
201 |                 self._close_connection()
    |

shared/rpc/rpc_channel.py:202:89: E501 Line too long (131 > 88)
    |
200 |                 self._connection.ioloop.stop()
201 |                 self._close_connection()
202 |             LOG.debug('will restart RPC pika connection and ioloop for %s in %s seconds', self._application, str(interval_seconds))
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
203 |             time.sleep(interval_seconds)
204 |         LOG.debug('RPC pika channel IOLoop thread stopped for %s', self._application)
    |

shared/rpc/rpc_channel.py:243:89: E501 Line too long (105 > 88)
    |
241 |                 self._connection_close_callback()
242 |         except Exception:
243 |             LOG.exception('unhandled exception from connection_ready_callback for %s', self._application)
    |                                                                                         ^^^^^^^^^^^^^^^^^ E501
244 |         self.close_channel()
245 |         self._close_connection()
    |

shared/rpc/rpc_consumer.py:16:1: I001 [*] Import block is un-sorted or un-formatted
   |
14 |   # limitations under the License.
15 |
16 | / import logging
17 | | import json
18 | | from datetime import datetime
19 | | from shared.rpc.rpc_channel import RpcChannel
20 | | from shared.constants import LOGGER_PREFIX
21 | |
22 | | from six import iteritems
   | |_________________________^ I001
23 |
24 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/rpc/rpc_manager.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import logging
16 | | import threading
17 | |
18 | | from shared.exceptions import ha_exceptions
19 | | from shared.messages import message_schemas
20 | | from shared.rpc.rpc_consumer import RpcConsumer
21 | | from shared.rpc.rpc_producer import RpcProducer
22 | | from shared.constants import LOGGER_PREFIX
23 | |
24 | | from six.moves.queue import Queue
   | |_________________________________^ I001
25 |
26 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/rpc/rpc_manager.py:169:89: E501 Line too long (90 > 88)
    |
167 |         if payload:
168 |             type = payload['type']
169 |             LOG.info("received rpc message with payload type %s : %s", type, str(payload))
    |                                                                                         ^^ E501
170 |             if type in message_schemas.valid_message_types():
171 |                 self.message_buffers[type].put(message)
    |

shared/rpc/rpc_producer.py:16:1: I001 [*] Import block is un-sorted or un-formatted
   |
14 |   # limitations under the License.
15 |
16 | / import json
17 | | import logging
18 | | from datetime import datetime, timedelta
19 | | import time
20 | | import threading
21 | | from shared.rpc.rpc_channel import RpcChannel
22 | | from shared.constants import LOGGER_PREFIX
   | |__________________________________________^ I001
23 |
24 |   LOG = logging.getLogger(LOGGER_PREFIX + __name__)
   |
   = help: Organize imports

shared/rpc/rpc_producer.py:101:89: E501 Line too long (89 > 88)
    |
 99 |         confirmation_type = method_frame.method.NAME.split('.')[1].lower()
100 |         LOG.debug('producer for %s received %s for delivery tag: %i',
101 |                   self._application, confirmation_type, method_frame.method.delivery_tag)
    |                                                                                         ^ E501
102 |
103 |     def on_connection_ready(self):
    |

shared/rpc/rpc_producer.py:144:89: E501 Line too long (132 > 88)
    |
142 |                     continue
143 |                 all_msgs = str(self._sending_buffer)
144 |                 LOG.debug('size of PRC producer sending buffer for %s : %s , messages : %s', self._application, str(size), all_msgs)
    |                                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E501
145 |                 connection = self._rpc_channel.get_connection()
146 |                 if not connection:
    |

shared/rpc/rpc_producer.py:187:89: E501 Line too long (89 > 88)
    |
185 |                                           routing,
186 |                                           payload)
187 |                     LOG.debug('RPC producer for %s published message (%s:%s) at %s : %s',
    |                                                                                         ^ E501
188 |                               self._application, str(datetime.utcnow()),
189 |                               self._exchange, routing, payload)
    |

shared/tests/test_rpc.py:15:1: I001 [*] Import block is un-sorted or un-formatted
   |
13 |   # limitations under the License.
14 |
15 | / import unittest
16 | | import logging
   | |______________^ I001
17 |
18 |   logging.basicConfig(level=logging.DEBUG)
   |
   = help: Organize imports

shared/tests/test_rpc.py:25:89: E501 Line too long (95 > 88)
   |
23 | handler = logging.StreamHandler()
24 | handler.setLevel(logging.DEBUG)
25 | handler.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
   |                                                                                         ^^^^^^^ E501
26 | logger.addHandler(handler)
   |

shared/tests/test_rpc.py:28:1: E402 Module level import not at top of file
   |
26 | logger.addHandler(handler)
27 |
28 | import time
   | ^^^^^^^^^^^ E402
   |

shared/tests/test_rpc.py:55:9: I001 [*] Import block is un-sorted or un-formatted
   |
54 |       def test_two_channels(self):
55 | /         from shared.rpc.rpc_producer import RpcProducer
56 | |         from shared.rpc.rpc_consumer import RpcConsumer
   | |_______________________________________________________^ I001
57 |           producer = RpcProducer(self._host,
58 |                                  self._port,
   |
   = help: Organize imports

Found 923 errors.
[*] 80 fixable with the `--fix` option (15 hidden fixes can be enabled with the `--unsafe-fixes` option).
